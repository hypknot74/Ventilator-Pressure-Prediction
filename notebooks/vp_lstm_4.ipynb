{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "- PyTorch RNN starter code with W&B  \n",
    "- Pytorch W&B Usage Examples from https://docs.wandb.ai/guides/integrations/pytorch  \n",
    "\n",
    "If this notebook is helpful, feel free to upvote :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/google/deluca-lung/main/assets/2020-10-02%20Ventilator%20diagram.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "EXP_NAME='1005_base_4layer'\n",
    "\n",
    "OUTPUT_DIR = f'./results/{EXP_NAME}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    experiment_name=EXP_NAME\n",
    "    competition='ventilator'\n",
    "    _wandb_kernel='hypknot'\n",
    "    apex=False\n",
    "    print_freq=20\n",
    "    num_workers=4\n",
    "    model_name='rnn'\n",
    "    scheduler='CosineAnnealingLR' # ['linear', 'cosine', 'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    batch_scheduler=False\n",
    "    #num_warmup_steps=100 # ['linear', 'cosine']\n",
    "    #num_cycles=0.5 # 'cosine'\n",
    "    #factor=0.2 # ReduceLROnPlateau\n",
    "    #patience=4 # ReduceLROnPlateau\n",
    "    #eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=50 # CosineAnnealingLR\n",
    "    #T_0=50 # CosineAnnealingWarmRestarts\n",
    "    epochs=30\n",
    "    max_grad_norm=1000\n",
    "    gradient_accumulation_steps=1\n",
    "    hidden_size=1024\n",
    "    hidden2_size=128\n",
    "    lr=5e-3\n",
    "    min_lr=1e-6\n",
    "    weight_decay=1e-6\n",
    "    batch_size=1024\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    cate_seq_cols=['R', 'C']\n",
    "    cont_seq_cols=['time_step', 'u_in', 'u_out'] \\\n",
    "            + ['area', 'u_in_cumsum', 'u_in_lag1', 'u_in_lag2', 'u_in_lag3', 'u_in_lag4',\n",
    "               'u_out_lag1', 'u_out_lag2', 'u_out_lag3', 'u_out_lag4',\n",
    "               'u_in_lag_back1', 'u_in_lag_back2', 'u_in_lag_back3', 'u_in_lag_back4',\n",
    "               'u_out_lag_back1', 'u_out_lag_back2', 'u_out_lag_back3', 'u_out_lag_back4',\n",
    "               'breath_id__u_in__max', 'breath_id__u_out__max',\n",
    "               'u_in_diff1', 'u_in_diff2', 'u_out_diff1', 'u_out_diff2',\n",
    "               'breath_id__u_in__diffmax', 'breath_id__u_in__diffmean',\n",
    "               'u_in_diff3', 'u_in_diff4', 'u_out_diff3', 'u_out_diff4', 'cross', 'cross2']\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if CFG.apex:\n",
    "    from apex import amp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhypknot\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public/runs/197af0mi\" target=\"_blank\">kind-sponge-18</a></strong> to <a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "import wandb\n",
    "\n",
    "# try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "#     wandb.login(key=secret_value_0)\n",
    "#     anony = None\n",
    "# except:\n",
    "#     anony = \"must\"\n",
    "#     print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "anony=None # not for kaggle kernel\n",
    "    \n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "run = wandb.init(project=\"Ventilator-Pressure-Public\", \n",
    "                 # name=CFG.model_name,\n",
    "                 config=class2dict(CFG),\n",
    "                 group=CFG.model_name,\n",
    "                 job_type=\"train\",\n",
    "                 anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_trues, y_preds):\n",
    "    score = mean_absolute_error(y_trues, y_preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080043</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>2.964399</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>3.157395</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>3.170056</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>3.271690</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R  C  time_step      u_in  u_out   pressure\n",
       "0   1          1  1  2   0.000000  0.080043      0   5.837492\n",
       "1   2          1  1  2   0.033652  2.964399      0   5.907794\n",
       "2   3          1  1  2   0.067514  3.157395      0   7.876254\n",
       "3   4          1  1  2   0.101542  3.170056      0  11.742872\n",
       "4   5          1  1  2   0.135756  3.271690      0  12.234987"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>2.141835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>2.750578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>3.101470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>3.307654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R  C  time_step      u_in  u_out\n",
       "0   1          0  0  1   0.000000  0.000000      0\n",
       "1   2          0  0  1   0.031904  2.141835      0\n",
       "2   3          0  0  1   0.063827  2.750578      0\n",
       "3   4          0  0  1   0.095751  3.101470      0\n",
       "4   5          0  0  1   0.127644  3.307654      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pressure\n",
       "0   1         0\n",
       "1   2         0\n",
       "2   3         0\n",
       "3   4         0\n",
       "4   5         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "sub = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "for c in ['u_in']:\n",
    "    train[c] = np.log1p(train[c])\n",
    "    test[c] = np.log1p(test[c])\n",
    "    \n",
    "r_map = {5: 0, 20: 1, 50: 2}\n",
    "c_map = {10: 0, 20: 1, 50: 2}\n",
    "train['R'] = train['R'].map(r_map)\n",
    "test['R'] = test['R'].map(r_map)\n",
    "train['C'] = train['C'].map(c_map)\n",
    "test['C'] = test['C'].map(c_map)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# FE\n",
    "# ====================================================\n",
    "def add_feature(df):\n",
    "#     # breath_time\n",
    "#     df['breath_time'] = df['time_step'] - df['time_step'].shift(1)\n",
    "#     df.loc[df['time_step'] == 0, 'breath_time'] = 0\n",
    "#     # u_in_time\n",
    "#     df['u_in_time'] = df['u_in'] - df['u_in'].shift(1)\n",
    "#     df.loc[df['time_step'] == 0, 'u_in_time'] = 0\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "\n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "\n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "\n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "\n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    return df\n",
    "\n",
    "\n",
    "train = add_feature(train)\n",
    "test = add_feature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    1207200\n",
      "1    1207200\n",
      "2    1207200\n",
      "3    1207200\n",
      "4    1207200\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "Fold = GroupKFold(n_splits=5)\n",
    "groups = train['breath_id'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['pressure'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "print(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.groups = df.groupby('breath_id').groups\n",
    "        self.keys = list(self.groups.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.groups[self.keys[idx]]\n",
    "        df = self.df.iloc[indexes]\n",
    "        cate_seq_x = torch.LongTensor(df[CFG.cate_seq_cols].values)\n",
    "        cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n",
    "        u_out = torch.LongTensor(df['u_out'].values)\n",
    "        label = torch.FloatTensor(df['pressure'].values)\n",
    "        return cate_seq_x, cont_seq_x, u_out, label\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.groups = df.groupby('breath_id').groups\n",
    "        self.keys = list(self.groups.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.groups[self.keys[idx]]\n",
    "        df = self.df.iloc[indexes]\n",
    "        cate_seq_x = torch.LongTensor(df[CFG.cate_seq_cols].values)\n",
    "        cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n",
    "        return cate_seq_x, cont_seq_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.hidden_size = cfg.hidden_size\n",
    "        self.hidden2_size = cfg.hidden2_size\n",
    "        self.r_emb = nn.Embedding(3, 2, padding_idx=0)\n",
    "        self.c_emb = nn.Embedding(3, 2, padding_idx=0)\n",
    "        self.seq_emb = nn.Sequential(\n",
    "            nn.Linear(4 + len(cfg.cont_seq_cols), self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden2_size, num_layers=4, dropout=0.2, batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden2_size * 2, self.hidden2_size * 2),\n",
    "            nn.LayerNorm(self.hidden2_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.),\n",
    "            nn.Linear(self.hidden2_size * 2, 1),\n",
    "        )\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.LSTM):\n",
    "                print(f'init {m}')\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        nn.init.normal_(param.data)\n",
    "            elif isinstance(m, nn.GRU):\n",
    "                print(f\"init {m}\")\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        init.normal_(param.data)\n",
    "\n",
    "    def forward(self, cate_seq_x, cont_seq_x):\n",
    "        bs = cont_seq_x.size(0)\n",
    "        r_emb = self.r_emb(cate_seq_x[:,:,0]).view(bs, 80, -1)\n",
    "        c_emb = self.c_emb(cate_seq_x[:,:,1]).view(bs, 80, -1)\n",
    "        seq_x = torch.cat((r_emb, c_emb, cont_seq_x), 2)\n",
    "        seq_emb = self.seq_emb(seq_x)\n",
    "        lstm_emb, _ = self.lstm(seq_emb)\n",
    "        output = self.head(lstm_emb).view(bs, -1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# helper function\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(train_loader):\n",
    "        loss_mask = u_out == 0\n",
    "        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n",
    "        batch_size = cont_seq_x.size(0)\n",
    "        pred = model(cate_seq_x, cont_seq_x)\n",
    "        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if CFG.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step, len(train_loader),\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   loss=losses,\n",
    "                   grad_norm=grad_norm,\n",
    "                   lr=scheduler.get_lr()[0],\n",
    "                   ))\n",
    "        wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(valid_loader):\n",
    "        loss_mask = u_out == 0\n",
    "        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n",
    "        batch_size = cont_seq_x.size(0)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cate_seq_x, cont_seq_x)\n",
    "        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step, len(valid_loader),\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   loss=losses,\n",
    "                   ))\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for step, (cate_seq_x, cont_seq_x) in tk0:\n",
    "        cate_seq_x, cont_seq_x = cate_seq_x.to(device), cont_seq_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cate_seq_x, cont_seq_x)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    y_true = valid_folds['pressure'].values\n",
    "    non_expiratory_phase_val_idx = valid_folds[valid_folds['u_out'] == 0].index # The expiratory phase is not scored\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds)\n",
    "    valid_dataset = TrainDataset(valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif CFG.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=CFG.num_cycles\n",
    "            )\n",
    "        elif CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if CFG.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_true[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - MAE Score (without expiratory phase): {score:.4f}')\n",
    "        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                   f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f\"fold{fold}_best.pth\")\n",
    "            \n",
    "    preds = torch.load(OUTPUT_DIR+f\"fold{fold}_best.pth\", map_location=torch.device('cpu'))['preds']\n",
    "    valid_folds['preds'] = preds\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare: 1.train 2.test\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df['pressure'].values\n",
    "        non_expiratory_phase_val_idx = result_df[result_df['u_out'] == 0].index # The expiratory phase is not scored\n",
    "        score = get_score(labels[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "        LOGGER.info(f'Score (without expiratory phase): {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    \n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size * 2, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
    "        for fold in CFG.trn_fold:\n",
    "            model = CustomModel(CFG)\n",
    "            path = OUTPUT_DIR+f\"fold{fold}_best.pth\"\n",
    "            state = torch.load(path, map_location=torch.device('cpu'))\n",
    "            model.load_state_dict(state['model'])\n",
    "            predictions = inference_fn(test_loader, model, device)\n",
    "            test[f'fold{fold}'] = predictions\n",
    "            del state, predictions; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        # submission\n",
    "        test['pressure'] = test[[f'fold{fold}' for fold in range(CFG.n_fold)]].mean(1)\n",
    "        test[['id', 'pressure']+[f'fold{fold}' for fold in range(CFG.n_fold)]].to_csv(OUTPUT_DIR+'raw_submission.csv', index=False)\n",
    "        test[['id', 'pressure']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LSTM(1024, 128, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "Epoch: [1][0/58] Elapsed 0m 2s (remain 2m 43s) Loss: 42.6433(42.6433) Grad: 46.7359  LR: 0.005000  \n",
      "Epoch: [1][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 21.8790(24.0718) Grad: 4.6384  LR: 0.005000  \n",
      "Epoch: [1][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 20.9902(22.8356) Grad: 9.6418  LR: 0.005000  \n",
      "Epoch: [1][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 22.0021(22.4418) Grad: 1.9348  LR: 0.005000  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 21.4937(21.4937) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 22.4418  avg_val_loss: 21.4355  time: 41s\n",
      "Epoch 1 - MAE Score (without expiratory phase): 8.8948\n",
      "Epoch 1 - Save Best Score: 8.8948 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 20.5011(21.4355) \n",
      "Epoch: [2][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 20.9943(20.9943) Grad: 2.6904  LR: 0.004990  \n",
      "Epoch: [2][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 20.9049(21.1692) Grad: 1.4174  LR: 0.004990  \n",
      "Epoch: [2][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 12.3143(18.8075) Grad: 7.9597  LR: 0.004990  \n",
      "Epoch: [2][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 10.0227(16.7402) Grad: 6.6963  LR: 0.004990  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 10.0448(10.0448) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 16.7402  avg_val_loss: 10.0184  time: 41s\n",
      "Epoch 2 - MAE Score (without expiratory phase): 4.3575\n",
      "Epoch 2 - Save Best Score: 4.3575 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 9.7019(10.0184) \n",
      "Epoch: [3][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 10.0483(10.0483) Grad: 10.4303  LR: 0.004966  \n",
      "Epoch: [3][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 8.3252(9.2294) Grad: 10.0542  LR: 0.004966  \n",
      "Epoch: [3][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 8.4465(8.8010) Grad: 21.8728  LR: 0.004966  \n",
      "Epoch: [3][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 7.5762(8.4636) Grad: 39.5654  LR: 0.004966  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 6.9865(6.9865) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 8.4636  avg_val_loss: 7.0995  time: 42s\n",
      "Epoch 3 - MAE Score (without expiratory phase): 3.1334\n",
      "Epoch 3 - Save Best Score: 3.1334 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 7.0166(7.0995) \n",
      "Epoch: [4][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 7.1932(7.1932) Grad: 24.7220  LR: 0.004931  \n",
      "Epoch: [4][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 6.1070(6.9748) Grad: 23.3552  LR: 0.004931  \n",
      "Epoch: [4][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 7.3923(6.7152) Grad: 63.1916  LR: 0.004931  \n",
      "Epoch: [4][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 5.6792(6.5227) Grad: 39.7970  LR: 0.004931  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 4.9384(4.9384) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 6.5227  avg_val_loss: 4.9969  time: 42s\n",
      "Epoch 4 - MAE Score (without expiratory phase): 2.1444\n",
      "Epoch 4 - Save Best Score: 2.1444 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 4.9000(4.9969) \n",
      "Epoch: [5][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 5.3575(5.3575) Grad: 18.6788  LR: 0.004887  \n",
      "Epoch: [5][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 5.6421(5.4434) Grad: 41.0320  LR: 0.004887  \n",
      "Epoch: [5][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 4.7546(5.1646) Grad: 42.5814  LR: 0.004887  \n",
      "Epoch: [5][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 4.6221(5.0813) Grad: 43.3282  LR: 0.004887  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 4.0199(4.0199) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 5.0813  avg_val_loss: 4.0223  time: 41s\n",
      "Epoch 5 - MAE Score (without expiratory phase): 1.6856\n",
      "Epoch 5 - Save Best Score: 1.6856 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 3.9648(4.0223) \n",
      "Epoch: [6][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 4.2178(4.2178) Grad: 16.3918  LR: 0.004834  \n",
      "Epoch: [6][20/58] Elapsed 0m 13s (remain 0m 24s) Loss: 5.3486(4.4322) Grad: 70.5362  LR: 0.004834  \n",
      "Epoch: [6][40/58] Elapsed 0m 24s (remain 0m 10s) Loss: 4.2284(4.3896) Grad: 42.2458  LR: 0.004834  \n",
      "Epoch: [6][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 4.6929(4.3179) Grad: 54.2266  LR: 0.004834  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 4.0732(4.0732) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 4.3179  avg_val_loss: 4.1064  time: 42s\n",
      "Epoch 6 - MAE Score (without expiratory phase): 1.7246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 4.1079(4.1064) \n",
      "Epoch: [7][0/58] Elapsed 0m 2s (remain 2m 44s) Loss: 4.3807(4.3807) Grad: 51.5877  LR: 0.004772  \n",
      "Epoch: [7][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 4.2023(4.1590) Grad: 41.9890  LR: 0.004772  \n",
      "Epoch: [7][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.5895(4.1033) Grad: 14.1194  LR: 0.004772  \n",
      "Epoch: [7][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 4.3387(4.0260) Grad: 57.1229  LR: 0.004772  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 3.5670(3.5670) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 4.0260  avg_val_loss: 3.5929  time: 41s\n",
      "Epoch 7 - MAE Score (without expiratory phase): 1.4962\n",
      "Epoch 7 - Save Best Score: 1.4962 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 3.5322(3.5929) \n",
      "Epoch: [8][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 3.8009(3.8009) Grad: 43.8676  LR: 0.004701  \n",
      "Epoch: [8][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 3.4450(3.5851) Grad: 36.9407  LR: 0.004701  \n",
      "Epoch: [8][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.3966(3.6454) Grad: 7.1090  LR: 0.004701  \n",
      "Epoch: [8][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 3.7780(3.6714) Grad: 47.9847  LR: 0.004701  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 3.2246(3.2246) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 3.6714  avg_val_loss: 3.2153  time: 41s\n",
      "Epoch 8 - MAE Score (without expiratory phase): 1.3509\n",
      "Epoch 8 - Save Best Score: 1.3509 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 3.2011(3.2153) \n",
      "Epoch: [9][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 3.4828(3.4828) Grad: 29.7979  LR: 0.004621  \n",
      "Epoch: [9][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 3.2727(3.4864) Grad: 14.1008  LR: 0.004621  \n",
      "Epoch: [9][40/58] Elapsed 0m 24s (remain 0m 10s) Loss: 3.1920(3.3819) Grad: 21.7435  LR: 0.004621  \n",
      "Epoch: [9][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 3.4211(3.3829) Grad: 35.7339  LR: 0.004621  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 2.9394(2.9394) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 3.3829  avg_val_loss: 2.9110  time: 42s\n",
      "Epoch 9 - MAE Score (without expiratory phase): 1.2336\n",
      "Epoch 9 - Save Best Score: 1.2336 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.8582(2.9110) \n",
      "Epoch: [10][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 3.1120(3.1120) Grad: 10.4625  LR: 0.004532  \n",
      "Epoch: [10][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 3.5868(3.2519) Grad: 53.6988  LR: 0.004532  \n",
      "Epoch: [10][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.0953(3.3280) Grad: 3.5914  LR: 0.004532  \n",
      "Epoch: [10][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 3.1730(3.2773) Grad: 32.9526  LR: 0.004532  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 2.8834(2.8834) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 3.2773  avg_val_loss: 2.8310  time: 42s\n",
      "Epoch 10 - MAE Score (without expiratory phase): 1.2007\n",
      "Epoch 10 - Save Best Score: 1.2007 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.7955(2.8310) \n",
      "Epoch: [11][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 2.9256(2.9256) Grad: 22.3567  LR: 0.004436  \n",
      "Epoch: [11][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 3.5956(3.0279) Grad: 60.0594  LR: 0.004436  \n",
      "Epoch: [11][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.8579(3.0717) Grad: 6.7463  LR: 0.004436  \n",
      "Epoch: [11][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.8188(3.0474) Grad: 28.6133  LR: 0.004436  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 2.6001(2.6001) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 3.0474  avg_val_loss: 2.5590  time: 41s\n",
      "Epoch 11 - MAE Score (without expiratory phase): 1.0765\n",
      "Epoch 11 - Save Best Score: 1.0765 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.4973(2.5590) \n",
      "Epoch: [12][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 2.7994(2.7994) Grad: 9.4060  LR: 0.004332  \n",
      "Epoch: [12][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 3.2430(3.0912) Grad: 48.5746  LR: 0.004332  \n",
      "Epoch: [12][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.3217(3.0039) Grad: 51.0917  LR: 0.004332  \n",
      "Epoch: [12][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 3.0471(3.0122) Grad: 38.4029  LR: 0.004332  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 3.0204(3.0204) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - avg_train_loss: 3.0122  avg_val_loss: 2.9685  time: 41s\n",
      "Epoch 12 - MAE Score (without expiratory phase): 1.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.8916(2.9685) \n",
      "Epoch: [13][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 3.0484(3.0484) Grad: 41.9439  LR: 0.004221  \n",
      "Epoch: [13][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.5953(2.8766) Grad: 7.7545  LR: 0.004221  \n",
      "Epoch: [13][40/58] Elapsed 0m 24s (remain 0m 9s) Loss: 2.8835(2.8425) Grad: 44.3831  LR: 0.004221  \n",
      "Epoch: [13][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 3.4044(2.9179) Grad: 50.5775  LR: 0.004221  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 2.5907(2.5907) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - avg_train_loss: 2.9179  avg_val_loss: 2.5329  time: 41s\n",
      "Epoch 13 - MAE Score (without expiratory phase): 1.0603\n",
      "Epoch 13 - Save Best Score: 1.0603 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.4521(2.5329) \n",
      "Epoch: [14][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 2.7301(2.7301) Grad: 8.9708  LR: 0.004103  \n",
      "Epoch: [14][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.7395(2.7722) Grad: 24.1998  LR: 0.004103  \n",
      "Epoch: [14][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.9191(2.7426) Grad: 30.8036  LR: 0.004103  \n",
      "Epoch: [14][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.5021(2.7431) Grad: 5.6504  LR: 0.004103  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 2.4008(2.4008) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - avg_train_loss: 2.7431  avg_val_loss: 2.3395  time: 41s\n",
      "Epoch 14 - MAE Score (without expiratory phase): 0.9808\n",
      "Epoch 14 - Save Best Score: 0.9808 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.2872(2.3395) \n",
      "Epoch: [15][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 2.5802(2.5802) Grad: 8.7808  LR: 0.003979  \n",
      "Epoch: [15][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.5547(2.6278) Grad: 8.0391  LR: 0.003979  \n",
      "Epoch: [15][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.6771(2.6506) Grad: 28.9374  LR: 0.003979  \n",
      "Epoch: [15][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.4287(2.6021) Grad: 13.1783  LR: 0.003979  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 2.3728(2.3728) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - avg_train_loss: 2.6021  avg_val_loss: 2.3039  time: 41s\n",
      "Epoch 15 - MAE Score (without expiratory phase): 0.9668\n",
      "Epoch 15 - Save Best Score: 0.9668 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.2271(2.3039) \n",
      "Epoch: [16][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 2.5815(2.5815) Grad: 33.1826  LR: 0.003849  \n",
      "Epoch: [16][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.9480(2.8052) Grad: 52.8768  LR: 0.003849  \n",
      "Epoch: [16][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.5914(2.7278) Grad: 12.7269  LR: 0.003849  \n",
      "Epoch: [16][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.4328(2.7046) Grad: 23.6177  LR: 0.003849  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 2.2107(2.2107) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - avg_train_loss: 2.7046  avg_val_loss: 2.1883  time: 42s\n",
      "Epoch 16 - MAE Score (without expiratory phase): 0.9154\n",
      "Epoch 16 - Save Best Score: 0.9154 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 2.1703(2.1883) \n",
      "Epoch: [17][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 2.5050(2.5050) Grad: 19.7510  LR: 0.003714  \n",
      "Epoch: [17][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 2.7457(2.5505) Grad: 41.6993  LR: 0.003714  \n",
      "Epoch: [17][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.3267(2.4971) Grad: 5.2376  LR: 0.003714  \n",
      "Epoch: [17][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.4061(2.4821) Grad: 14.9408  LR: 0.003714  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 2.4076(2.4076) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - avg_train_loss: 2.4821  avg_val_loss: 2.3803  time: 42s\n",
      "Epoch 17 - MAE Score (without expiratory phase): 1.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 2.2654(2.3803) \n",
      "Epoch: [18][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 2.4695(2.4695) Grad: 29.1137  LR: 0.003574  \n",
      "Epoch: [18][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 2.4590(2.4585) Grad: 28.2321  LR: 0.003574  \n",
      "Epoch: [18][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.2726(2.4186) Grad: 9.8290  LR: 0.003574  \n",
      "Epoch: [18][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 2.3408(2.4072) Grad: 16.6341  LR: 0.003574  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 2.2668(2.2668) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - avg_train_loss: 2.4072  avg_val_loss: 2.1564  time: 41s\n",
      "Epoch 18 - MAE Score (without expiratory phase): 0.9033\n",
      "Epoch 18 - Save Best Score: 0.9033 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.0908(2.1564) \n",
      "Epoch: [19][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 2.5007(2.5007) Grad: 35.0740  LR: 0.003430  \n",
      "Epoch: [19][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.3546(2.4848) Grad: 29.4762  LR: 0.003430  \n",
      "Epoch: [19][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.3147(2.4108) Grad: 30.5164  LR: 0.003430  \n",
      "Epoch: [19][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.2200(2.4042) Grad: 15.0917  LR: 0.003430  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 2.2671(2.2671) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - avg_train_loss: 2.4042  avg_val_loss: 2.2303  time: 41s\n",
      "Epoch 19 - MAE Score (without expiratory phase): 0.9307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 2.1883(2.2303) \n",
      "Epoch: [20][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 2.4120(2.4120) Grad: 45.8921  LR: 0.003282  \n",
      "Epoch: [20][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.3305(2.3802) Grad: 13.1877  LR: 0.003282  \n",
      "Epoch: [20][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.6877(2.3563) Grad: 53.1327  LR: 0.003282  \n",
      "Epoch: [20][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.2280(2.3791) Grad: 18.4693  LR: 0.003282  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 2.3617(2.3617) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - avg_train_loss: 2.3791  avg_val_loss: 2.2829  time: 42s\n",
      "Epoch 20 - MAE Score (without expiratory phase): 0.9616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.1919(2.2829) \n",
      "Epoch: [21][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 2.3895(2.3895) Grad: 37.2810  LR: 0.003132  \n",
      "Epoch: [21][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.2253(2.2416) Grad: 19.0444  LR: 0.003132  \n",
      "Epoch: [21][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.2188(2.2757) Grad: 11.2841  LR: 0.003132  \n",
      "Epoch: [21][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.3950(2.2994) Grad: 47.2873  LR: 0.003132  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 2.1649(2.1649) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - avg_train_loss: 2.2994  avg_val_loss: 2.0952  time: 41s\n",
      "Epoch 21 - MAE Score (without expiratory phase): 0.8771\n",
      "Epoch 21 - Save Best Score: 0.8771 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.0515(2.0952) \n",
      "Epoch: [22][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 2.3188(2.3188) Grad: 38.2932  LR: 0.002978  \n",
      "Epoch: [22][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.3090(2.2722) Grad: 24.7732  LR: 0.002978  \n",
      "Epoch: [22][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.1578(2.2424) Grad: 6.8217  LR: 0.002978  \n",
      "Epoch: [22][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.1793(2.2159) Grad: 8.8795  LR: 0.002978  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.9748(1.9748) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - avg_train_loss: 2.2159  avg_val_loss: 1.9294  time: 42s\n",
      "Epoch 22 - MAE Score (without expiratory phase): 0.7978\n",
      "Epoch 22 - Save Best Score: 0.7978 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 1.8680(1.9294) \n",
      "Epoch: [23][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 2.0569(2.0569) Grad: 8.7575  LR: 0.002823  \n",
      "Epoch: [23][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.0486(2.1229) Grad: 3.6449  LR: 0.002823  \n",
      "Epoch: [23][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.0852(2.1165) Grad: 5.9916  LR: 0.002823  \n",
      "Epoch: [23][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.1610(2.1322) Grad: 11.7579  LR: 0.002823  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.9432(1.9432) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - avg_train_loss: 2.1322  avg_val_loss: 1.8834  time: 42s\n",
      "Epoch 23 - MAE Score (without expiratory phase): 0.7731\n",
      "Epoch 23 - Save Best Score: 0.7731 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 1.8583(1.8834) \n",
      "Epoch: [24][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 2.0580(2.0580) Grad: 13.9660  LR: 0.002667  \n",
      "Epoch: [24][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.2625(2.1782) Grad: 37.1840  LR: 0.002667  \n",
      "Epoch: [24][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.0712(2.1709) Grad: 24.5521  LR: 0.002667  \n",
      "Epoch: [24][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.0830(2.1559) Grad: 19.1241  LR: 0.002667  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.9116(1.9116) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - avg_train_loss: 2.1559  avg_val_loss: 1.8595  time: 41s\n",
      "Epoch 24 - MAE Score (without expiratory phase): 0.7673\n",
      "Epoch 24 - Save Best Score: 0.7673 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 1.8020(1.8595) \n",
      "Epoch: [25][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 2.0433(2.0433) Grad: 15.5246  LR: 0.002510  \n",
      "Epoch: [25][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.2262(2.1015) Grad: 26.3607  LR: 0.002510  \n",
      "Epoch: [25][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.1161(2.0988) Grad: 22.5517  LR: 0.002510  \n",
      "Epoch: [25][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.0920(2.0982) Grad: 32.7090  LR: 0.002510  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 2.0028(2.0028) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - avg_train_loss: 2.0982  avg_val_loss: 1.9611  time: 41s\n",
      "Epoch 25 - MAE Score (without expiratory phase): 0.8099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 1.9069(1.9611) \n",
      "Epoch: [26][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 2.2128(2.2128) Grad: 39.6542  LR: 0.002353  \n",
      "Epoch: [26][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.0848(2.2179) Grad: 30.7541  LR: 0.002353  \n",
      "Epoch: [26][40/58] Elapsed 0m 24s (remain 0m 9s) Loss: 2.2375(2.1606) Grad: 34.4019  LR: 0.002353  \n",
      "Epoch: [26][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.0518(2.1542) Grad: 15.8776  LR: 0.002353  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 39s) Loss: 1.9101(1.9101) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - avg_train_loss: 2.1542  avg_val_loss: 1.8733  time: 42s\n",
      "Epoch 26 - MAE Score (without expiratory phase): 0.7727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 1.8225(1.8733) \n",
      "Epoch: [27][0/58] Elapsed 0m 2s (remain 2m 46s) Loss: 1.9570(1.9570) Grad: 6.3536  LR: 0.002196  \n",
      "Epoch: [27][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.0001(2.0751) Grad: 12.0170  LR: 0.002196  \n",
      "Epoch: [27][40/58] Elapsed 0m 24s (remain 0m 10s) Loss: 2.0371(2.0655) Grad: 19.2376  LR: 0.002196  \n",
      "Epoch: [27][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.9271(2.0556) Grad: 6.2993  LR: 0.002196  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 39s) Loss: 1.8417(1.8417) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 - avg_train_loss: 2.0556  avg_val_loss: 1.7922  time: 42s\n",
      "Epoch 27 - MAE Score (without expiratory phase): 0.7367\n",
      "Epoch 27 - Save Best Score: 0.7367 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 1.7589(1.7922) \n",
      "Epoch: [28][0/58] Elapsed 0m 2s (remain 2m 46s) Loss: 1.9750(1.9750) Grad: 8.7235  LR: 0.002041  \n",
      "Epoch: [28][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.0958(1.9721) Grad: 14.0057  LR: 0.002041  \n",
      "Epoch: [28][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.9960(1.9875) Grad: 12.8578  LR: 0.002041  \n",
      "Epoch: [28][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.0107(1.9942) Grad: 10.8429  LR: 0.002041  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 39s) Loss: 1.8518(1.8518) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 - avg_train_loss: 1.9942  avg_val_loss: 1.8169  time: 41s\n",
      "Epoch 28 - MAE Score (without expiratory phase): 0.7445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 1.7647(1.8169) \n",
      "Epoch: [29][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 2.0560(2.0560) Grad: 13.0923  LR: 0.001888  \n",
      "Epoch: [29][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.0452(1.9728) Grad: 36.0037  LR: 0.001888  \n",
      "Epoch: [29][40/58] Elapsed 0m 24s (remain 0m 10s) Loss: 2.0524(1.9724) Grad: 31.3993  LR: 0.001888  \n",
      "Epoch: [29][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.0033(1.9744) Grad: 27.0670  LR: 0.001888  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 39s) Loss: 1.7621(1.7621) \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
