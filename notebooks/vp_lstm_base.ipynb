{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "- PyTorch RNN starter code with W&B  \n",
    "- Pytorch W&B Usage Examples from https://docs.wandb.ai/guides/integrations/pytorch  \n",
    "\n",
    "If this notebook is helpful, feel free to upvote :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/google/deluca-lung/main/assets/2020-10-02%20Ventilator%20diagram.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "EXP_NAME='1005_4layer_300epoch'\n",
    "\n",
    "OUTPUT_DIR = f'./results/{EXP_NAME}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    experiment_name=EXP_NAME\n",
    "    competition='ventilator'\n",
    "    _wandb_kernel='hypknot'\n",
    "    apex=False\n",
    "    print_freq=20\n",
    "    num_workers=4\n",
    "    model_name='rnn'\n",
    "    scheduler='CosineAnnealingLR' # ['linear', 'cosine', 'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    batch_scheduler=False\n",
    "    #num_warmup_steps=100 # ['linear', 'cosine']\n",
    "    #num_cycles=0.5 # 'cosine'\n",
    "    #factor=0.2 # ReduceLROnPlateau\n",
    "    #patience=4 # ReduceLROnPlateau\n",
    "    #eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=50 # CosineAnnealingLR\n",
    "    #T_0=50 # CosineAnnealingWarmRestarts\n",
    "    epochs=300\n",
    "    max_grad_norm=1000\n",
    "    gradient_accumulation_steps=1\n",
    "    hidden_size=1024\n",
    "    hidden2_size=128\n",
    "    lr=5e-3\n",
    "    min_lr=1e-6\n",
    "    weight_decay=1e-6\n",
    "    batch_size=1024\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    cate_seq_cols=['R', 'C']\n",
    "    cont_seq_cols=['time_step', 'u_in', 'u_out'] \\\n",
    "            + ['area', 'u_in_cumsum', 'u_in_lag1', 'u_in_lag2', 'u_in_lag3', 'u_in_lag4',\n",
    "               'u_out_lag1', 'u_out_lag2', 'u_out_lag3', 'u_out_lag4',\n",
    "               'u_in_lag_back1', 'u_in_lag_back2', 'u_in_lag_back3', 'u_in_lag_back4',\n",
    "               'u_out_lag_back1', 'u_out_lag_back2', 'u_out_lag_back3', 'u_out_lag_back4',\n",
    "               'breath_id__u_in__max', 'breath_id__u_out__max',\n",
    "               'u_in_diff1', 'u_in_diff2', 'u_out_diff1', 'u_out_diff2',\n",
    "               'breath_id__u_in__diffmax', 'breath_id__u_in__diffmean',\n",
    "               'u_in_diff3', 'u_in_diff4', 'u_out_diff3', 'u_out_diff4', 'cross', 'cross2']\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if CFG.apex:\n",
    "    from apex import amp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhypknot\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public/runs/2betljnl\" target=\"_blank\">stellar-cosmos-20</a></strong> to <a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "import wandb\n",
    "\n",
    "# try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "#     wandb.login(key=secret_value_0)\n",
    "#     anony = None\n",
    "# except:\n",
    "#     anony = \"must\"\n",
    "#     print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "anony=None # not for kaggle kernel\n",
    "    \n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "run = wandb.init(project=\"Ventilator-Pressure-Public\", \n",
    "                 # name=CFG.model_name,\n",
    "                 config=class2dict(CFG),\n",
    "                 group=CFG.model_name,\n",
    "                 job_type=\"train\",\n",
    "                 anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_trues, y_preds):\n",
    "    score = mean_absolute_error(y_trues, y_preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080043</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>2.964399</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>3.157395</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>3.170056</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>3.271690</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R  C  time_step      u_in  u_out   pressure\n",
       "0   1          1  1  2   0.000000  0.080043      0   5.837492\n",
       "1   2          1  1  2   0.033652  2.964399      0   5.907794\n",
       "2   3          1  1  2   0.067514  3.157395      0   7.876254\n",
       "3   4          1  1  2   0.101542  3.170056      0  11.742872\n",
       "4   5          1  1  2   0.135756  3.271690      0  12.234987"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>2.141835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>2.750578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>3.101470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>3.307654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R  C  time_step      u_in  u_out\n",
       "0   1          0  0  1   0.000000  0.000000      0\n",
       "1   2          0  0  1   0.031904  2.141835      0\n",
       "2   3          0  0  1   0.063827  2.750578      0\n",
       "3   4          0  0  1   0.095751  3.101470      0\n",
       "4   5          0  0  1   0.127644  3.307654      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pressure\n",
       "0   1         0\n",
       "1   2         0\n",
       "2   3         0\n",
       "3   4         0\n",
       "4   5         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "sub = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "for c in ['u_in']:\n",
    "    train[c] = np.log1p(train[c])\n",
    "    test[c] = np.log1p(test[c])\n",
    "    \n",
    "r_map = {5: 0, 20: 1, 50: 2}\n",
    "c_map = {10: 0, 20: 1, 50: 2}\n",
    "train['R'] = train['R'].map(r_map)\n",
    "test['R'] = test['R'].map(r_map)\n",
    "train['C'] = train['C'].map(c_map)\n",
    "test['C'] = test['C'].map(c_map)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# FE\n",
    "# ====================================================\n",
    "def add_feature(df):\n",
    "#     # breath_time\n",
    "#     df['breath_time'] = df['time_step'] - df['time_step'].shift(1)\n",
    "#     df.loc[df['time_step'] == 0, 'breath_time'] = 0\n",
    "#     # u_in_time\n",
    "#     df['u_in_time'] = df['u_in'] - df['u_in'].shift(1)\n",
    "#     df.loc[df['time_step'] == 0, 'u_in_time'] = 0\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "\n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "\n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "\n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "\n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    return df\n",
    "\n",
    "\n",
    "train = add_feature(train)\n",
    "test = add_feature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    1207200\n",
      "1    1207200\n",
      "2    1207200\n",
      "3    1207200\n",
      "4    1207200\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "Fold = GroupKFold(n_splits=5)\n",
    "groups = train['breath_id'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['pressure'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "print(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.groups = df.groupby('breath_id').groups\n",
    "        self.keys = list(self.groups.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.groups[self.keys[idx]]\n",
    "        df = self.df.iloc[indexes]\n",
    "        cate_seq_x = torch.LongTensor(df[CFG.cate_seq_cols].values)\n",
    "        cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n",
    "        u_out = torch.LongTensor(df['u_out'].values)\n",
    "        label = torch.FloatTensor(df['pressure'].values)\n",
    "        return cate_seq_x, cont_seq_x, u_out, label\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.groups = df.groupby('breath_id').groups\n",
    "        self.keys = list(self.groups.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.groups[self.keys[idx]]\n",
    "        df = self.df.iloc[indexes]\n",
    "        cate_seq_x = torch.LongTensor(df[CFG.cate_seq_cols].values)\n",
    "        cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n",
    "        return cate_seq_x, cont_seq_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.hidden_size = cfg.hidden_size\n",
    "        self.hidden2_size = cfg.hidden2_size\n",
    "        self.r_emb = nn.Embedding(3, 2, padding_idx=0)\n",
    "        self.c_emb = nn.Embedding(3, 2, padding_idx=0)\n",
    "        self.seq_emb = nn.Sequential(\n",
    "            nn.Linear(4 + len(cfg.cont_seq_cols), self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden2_size, num_layers=4, dropout=0.2, batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden2_size * 2, self.hidden2_size * 2),\n",
    "            nn.LayerNorm(self.hidden2_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.),\n",
    "            nn.Linear(self.hidden2_size * 2, 1),\n",
    "        )\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.LSTM):\n",
    "                print(f'init {m}')\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        nn.init.normal_(param.data)\n",
    "            elif isinstance(m, nn.GRU):\n",
    "                print(f\"init {m}\")\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        init.normal_(param.data)\n",
    "\n",
    "    def forward(self, cate_seq_x, cont_seq_x):\n",
    "        bs = cont_seq_x.size(0)\n",
    "        r_emb = self.r_emb(cate_seq_x[:,:,0]).view(bs, 80, -1)\n",
    "        c_emb = self.c_emb(cate_seq_x[:,:,1]).view(bs, 80, -1)\n",
    "        seq_x = torch.cat((r_emb, c_emb, cont_seq_x), 2)\n",
    "        seq_emb = self.seq_emb(seq_x)\n",
    "        lstm_emb, _ = self.lstm(seq_emb)\n",
    "        output = self.head(lstm_emb).view(bs, -1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# helper function\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(train_loader):\n",
    "        loss_mask = u_out == 0\n",
    "        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n",
    "        batch_size = cont_seq_x.size(0)\n",
    "        pred = model(cate_seq_x, cont_seq_x)\n",
    "        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if CFG.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step, len(train_loader),\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   loss=losses,\n",
    "                   grad_norm=grad_norm,\n",
    "                   lr=scheduler.get_lr()[0],\n",
    "                   ))\n",
    "        wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(valid_loader):\n",
    "        loss_mask = u_out == 0\n",
    "        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n",
    "        batch_size = cont_seq_x.size(0)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cate_seq_x, cont_seq_x)\n",
    "        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step, len(valid_loader),\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   loss=losses,\n",
    "                   ))\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for step, (cate_seq_x, cont_seq_x) in tk0:\n",
    "        cate_seq_x, cont_seq_x = cate_seq_x.to(device), cont_seq_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cate_seq_x, cont_seq_x)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    y_true = valid_folds['pressure'].values\n",
    "    non_expiratory_phase_val_idx = valid_folds[valid_folds['u_out'] == 0].index # The expiratory phase is not scored\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds)\n",
    "    valid_dataset = TrainDataset(valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif CFG.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=CFG.num_cycles\n",
    "            )\n",
    "        elif CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if CFG.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_true[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - MAE Score (without expiratory phase): {score:.4f}')\n",
    "        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                   f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f\"fold{fold}_best.pth\")\n",
    "            \n",
    "    preds = torch.load(OUTPUT_DIR+f\"fold{fold}_best.pth\", map_location=torch.device('cpu'))['preds']\n",
    "    valid_folds['preds'] = preds\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare: 1.train 2.test\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_result(result_df):\n",
    "        result_df = result_df.reset_index(drop=True) # To make sure indexes has no duplicates\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df['pressure'].values\n",
    "        non_expiratory_phase_val_idx = result_df[result_df['u_out'] == 0].index # The expiratory phase is not scored\n",
    "        score = get_score(labels[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "        LOGGER.info(f'Score (without expiratory phase): {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    \n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size * 2, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
    "        for fold in CFG.trn_fold:\n",
    "            model = CustomModel(CFG)\n",
    "            path = OUTPUT_DIR+f\"fold{fold}_best.pth\"\n",
    "            state = torch.load(path, map_location=torch.device('cpu'))\n",
    "            model.load_state_dict(state['model'])\n",
    "            predictions = inference_fn(test_loader, model, device)\n",
    "            test[f'fold{fold}'] = predictions\n",
    "            del state, predictions; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        # submission\n",
    "        test['pressure'] = test[[f'fold{fold}' for fold in range(CFG.n_fold)]].mean(1)\n",
    "        test[['id', 'pressure']+[f'fold{fold}' for fold in range(CFG.n_fold)]].to_csv(OUTPUT_DIR+'raw_submission.csv', index=False)\n",
    "        test[['id', 'pressure']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LSTM(1024, 128, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "Epoch: [1][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 42.6433(42.6433) Grad: 46.7359  LR: 0.005000  \n",
      "Epoch: [1][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 21.8790(24.0718) Grad: 4.6384  LR: 0.005000  \n",
      "Epoch: [1][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 20.9902(22.8356) Grad: 9.6418  LR: 0.005000  \n",
      "Epoch: [1][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 22.0021(22.4418) Grad: 1.9348  LR: 0.005000  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 21.4937(21.4937) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 22.4418  avg_val_loss: 21.4355  time: 41s\n",
      "Epoch 1 - MAE Score (without expiratory phase): 8.8948\n",
      "Epoch 1 - Save Best Score: 8.8948 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 20.5011(21.4355) \n",
      "Epoch: [2][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 20.9943(20.9943) Grad: 2.6904  LR: 0.004990  \n",
      "Epoch: [2][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 20.9049(21.1692) Grad: 1.4174  LR: 0.004990  \n",
      "Epoch: [2][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 12.3143(18.8075) Grad: 7.9597  LR: 0.004990  \n",
      "Epoch: [2][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 10.0227(16.7402) Grad: 6.6963  LR: 0.004990  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 10.0448(10.0448) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 16.7402  avg_val_loss: 10.0184  time: 41s\n",
      "Epoch 2 - MAE Score (without expiratory phase): 4.3575\n",
      "Epoch 2 - Save Best Score: 4.3575 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 9.7019(10.0184) \n",
      "Epoch: [3][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 10.0483(10.0483) Grad: 10.4303  LR: 0.004966  \n",
      "Epoch: [3][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 8.3252(9.2294) Grad: 10.0542  LR: 0.004966  \n",
      "Epoch: [3][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 8.4465(8.8010) Grad: 21.8728  LR: 0.004966  \n",
      "Epoch: [3][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 7.5762(8.4636) Grad: 39.5654  LR: 0.004966  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 6.9865(6.9865) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 8.4636  avg_val_loss: 7.0995  time: 41s\n",
      "Epoch 3 - MAE Score (without expiratory phase): 3.1334\n",
      "Epoch 3 - Save Best Score: 3.1334 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 7.0166(7.0995) \n",
      "Epoch: [4][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 7.1932(7.1932) Grad: 24.7220  LR: 0.004931  \n",
      "Epoch: [4][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 6.1070(6.9748) Grad: 23.3552  LR: 0.004931  \n",
      "Epoch: [4][40/58] Elapsed 0m 24s (remain 0m 9s) Loss: 7.3923(6.7152) Grad: 63.1916  LR: 0.004931  \n",
      "Epoch: [4][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 5.6792(6.5227) Grad: 39.7970  LR: 0.004931  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 4.9384(4.9384) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 6.5227  avg_val_loss: 4.9969  time: 41s\n",
      "Epoch 4 - MAE Score (without expiratory phase): 2.1444\n",
      "Epoch 4 - Save Best Score: 2.1444 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 4.9000(4.9969) \n",
      "Epoch: [5][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 5.3575(5.3575) Grad: 18.6788  LR: 0.004887  \n",
      "Epoch: [5][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 5.6421(5.4434) Grad: 41.0320  LR: 0.004887  \n",
      "Epoch: [5][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 4.7546(5.1646) Grad: 42.5814  LR: 0.004887  \n",
      "Epoch: [5][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 4.6221(5.0813) Grad: 43.3282  LR: 0.004887  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 4.0199(4.0199) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 5.0813  avg_val_loss: 4.0223  time: 41s\n",
      "Epoch 5 - MAE Score (without expiratory phase): 1.6856\n",
      "Epoch 5 - Save Best Score: 1.6856 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 3.9648(4.0223) \n",
      "Epoch: [6][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 4.2178(4.2178) Grad: 16.3918  LR: 0.004834  \n",
      "Epoch: [6][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 5.3486(4.4322) Grad: 70.5362  LR: 0.004834  \n",
      "Epoch: [6][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 4.2284(4.3896) Grad: 42.2458  LR: 0.004834  \n",
      "Epoch: [6][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 4.6929(4.3179) Grad: 54.2266  LR: 0.004834  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 4.0732(4.0732) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 4.3179  avg_val_loss: 4.1064  time: 41s\n",
      "Epoch 6 - MAE Score (without expiratory phase): 1.7246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 4.1079(4.1064) \n",
      "Epoch: [7][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 4.3807(4.3807) Grad: 51.5877  LR: 0.004772  \n",
      "Epoch: [7][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 4.2023(4.1590) Grad: 41.9890  LR: 0.004772  \n",
      "Epoch: [7][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.5895(4.1033) Grad: 14.1194  LR: 0.004772  \n",
      "Epoch: [7][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 4.3387(4.0260) Grad: 57.1229  LR: 0.004772  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 3.5670(3.5670) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 4.0260  avg_val_loss: 3.5929  time: 41s\n",
      "Epoch 7 - MAE Score (without expiratory phase): 1.4962\n",
      "Epoch 7 - Save Best Score: 1.4962 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 3.5322(3.5929) \n",
      "Epoch: [8][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 3.8009(3.8009) Grad: 43.8676  LR: 0.004701  \n",
      "Epoch: [8][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 3.4450(3.5851) Grad: 36.9407  LR: 0.004701  \n",
      "Epoch: [8][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.3966(3.6454) Grad: 7.1090  LR: 0.004701  \n",
      "Epoch: [8][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 3.7780(3.6714) Grad: 47.9847  LR: 0.004701  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 3.2246(3.2246) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 3.6714  avg_val_loss: 3.2153  time: 41s\n",
      "Epoch 8 - MAE Score (without expiratory phase): 1.3509\n",
      "Epoch 8 - Save Best Score: 1.3509 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 3.2011(3.2153) \n",
      "Epoch: [9][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 3.4828(3.4828) Grad: 29.7979  LR: 0.004621  \n",
      "Epoch: [9][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 3.2727(3.4864) Grad: 14.1008  LR: 0.004621  \n",
      "Epoch: [9][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.1920(3.3819) Grad: 21.7435  LR: 0.004621  \n",
      "Epoch: [9][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 3.4211(3.3829) Grad: 35.7339  LR: 0.004621  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 2.9394(2.9394) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 3.3829  avg_val_loss: 2.9110  time: 41s\n",
      "Epoch 9 - MAE Score (without expiratory phase): 1.2336\n",
      "Epoch 9 - Save Best Score: 1.2336 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.8582(2.9110) \n",
      "Epoch: [10][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 3.1120(3.1120) Grad: 10.4625  LR: 0.004532  \n",
      "Epoch: [10][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 3.5868(3.2519) Grad: 53.6988  LR: 0.004532  \n",
      "Epoch: [10][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.0953(3.3280) Grad: 3.5914  LR: 0.004532  \n",
      "Epoch: [10][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 3.1730(3.2773) Grad: 32.9526  LR: 0.004532  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 2.8834(2.8834) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 3.2773  avg_val_loss: 2.8310  time: 41s\n",
      "Epoch 10 - MAE Score (without expiratory phase): 1.2007\n",
      "Epoch 10 - Save Best Score: 1.2007 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.7955(2.8310) \n",
      "Epoch: [11][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 2.9256(2.9256) Grad: 22.3567  LR: 0.004436  \n",
      "Epoch: [11][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 3.5956(3.0279) Grad: 60.0594  LR: 0.004436  \n",
      "Epoch: [11][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.8579(3.0717) Grad: 6.7463  LR: 0.004436  \n",
      "Epoch: [11][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.8188(3.0474) Grad: 28.6133  LR: 0.004436  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 2.6001(2.6001) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 3.0474  avg_val_loss: 2.5590  time: 41s\n",
      "Epoch 11 - MAE Score (without expiratory phase): 1.0765\n",
      "Epoch 11 - Save Best Score: 1.0765 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.4973(2.5590) \n",
      "Epoch: [12][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 2.7994(2.7994) Grad: 9.4060  LR: 0.004332  \n",
      "Epoch: [12][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 3.2430(3.0912) Grad: 48.5746  LR: 0.004332  \n",
      "Epoch: [12][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 3.3217(3.0039) Grad: 51.0917  LR: 0.004332  \n",
      "Epoch: [12][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 3.0471(3.0122) Grad: 38.4029  LR: 0.004332  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 3.0204(3.0204) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - avg_train_loss: 3.0122  avg_val_loss: 2.9685  time: 41s\n",
      "Epoch 12 - MAE Score (without expiratory phase): 1.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.8916(2.9685) \n",
      "Epoch: [13][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 3.0484(3.0484) Grad: 41.9439  LR: 0.004221  \n",
      "Epoch: [13][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 2.5953(2.8766) Grad: 7.7545  LR: 0.004221  \n",
      "Epoch: [13][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.8835(2.8425) Grad: 44.3831  LR: 0.004221  \n",
      "Epoch: [13][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 3.4044(2.9179) Grad: 50.5775  LR: 0.004221  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 2.5907(2.5907) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - avg_train_loss: 2.9179  avg_val_loss: 2.5329  time: 41s\n",
      "Epoch 13 - MAE Score (without expiratory phase): 1.0603\n",
      "Epoch 13 - Save Best Score: 1.0603 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.4521(2.5329) \n",
      "Epoch: [14][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 2.7301(2.7301) Grad: 8.9708  LR: 0.004103  \n",
      "Epoch: [14][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.7395(2.7722) Grad: 24.1998  LR: 0.004103  \n",
      "Epoch: [14][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.9191(2.7426) Grad: 30.8036  LR: 0.004103  \n",
      "Epoch: [14][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 2.5021(2.7431) Grad: 5.6504  LR: 0.004103  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 2.4008(2.4008) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - avg_train_loss: 2.7431  avg_val_loss: 2.3395  time: 41s\n",
      "Epoch 14 - MAE Score (without expiratory phase): 0.9808\n",
      "Epoch 14 - Save Best Score: 0.9808 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.2872(2.3395) \n",
      "Epoch: [15][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 2.5802(2.5802) Grad: 8.7808  LR: 0.003979  \n",
      "Epoch: [15][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 2.5547(2.6278) Grad: 8.0391  LR: 0.003979  \n",
      "Epoch: [15][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.6771(2.6506) Grad: 28.9374  LR: 0.003979  \n",
      "Epoch: [15][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 2.4287(2.6021) Grad: 13.1783  LR: 0.003979  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 2.3728(2.3728) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - avg_train_loss: 2.6021  avg_val_loss: 2.3039  time: 42s\n",
      "Epoch 15 - MAE Score (without expiratory phase): 0.9668\n",
      "Epoch 15 - Save Best Score: 0.9668 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.2271(2.3039) \n",
      "Epoch: [16][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 2.5815(2.5815) Grad: 33.1826  LR: 0.003849  \n",
      "Epoch: [16][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.9480(2.8052) Grad: 52.8768  LR: 0.003849  \n",
      "Epoch: [16][40/58] Elapsed 0m 24s (remain 0m 9s) Loss: 2.5914(2.7278) Grad: 12.7269  LR: 0.003849  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.5786(1.5786) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 - avg_train_loss: 1.6626  avg_val_loss: 1.5244  time: 41s\n",
      "Epoch 100 - MAE Score (without expiratory phase): 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.5131(1.5244) \n",
      "Epoch: [101][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.7056(1.7056) Grad: 25.8954  LR: 0.005005  \n",
      "Epoch: [101][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.7039(1.6949) Grad: 31.2112  LR: 0.005005  \n",
      "Epoch: [101][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.7210(1.6450) Grad: 32.4196  LR: 0.005005  \n",
      "Epoch: [101][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.5262(1.6140) Grad: 9.3422  LR: 0.005005  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.3989(1.3989) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101 - avg_train_loss: 1.6140  avg_val_loss: 1.3453  time: 41s\n",
      "Epoch 101 - MAE Score (without expiratory phase): 0.5376\n",
      "Epoch 101 - Save Best Score: 0.5376 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3182(1.3453) \n",
      "Epoch: [102][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.5328(1.5328) Grad: 6.8851  LR: 0.004990  \n",
      "Epoch: [102][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.4669(1.5543) Grad: 6.8836  LR: 0.004990  \n",
      "Epoch: [102][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.9159(1.5993) Grad: 25.4487  LR: 0.004990  \n",
      "Epoch: [102][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.7451(1.6360) Grad: 27.7615  LR: 0.004990  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.7127(1.7127) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102 - avg_train_loss: 1.6360  avg_val_loss: 1.6727  time: 40s\n",
      "Epoch 102 - MAE Score (without expiratory phase): 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.6624(1.6727) \n",
      "Epoch: [103][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.7003(1.7003) Grad: 27.3175  LR: 0.004966  \n",
      "Epoch: [103][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.4900(1.6474) Grad: 13.5497  LR: 0.004966  \n",
      "Epoch: [103][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.6926(1.6587) Grad: 25.7178  LR: 0.004966  \n",
      "Epoch: [103][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.6570(1.6678) Grad: 29.9098  LR: 0.004966  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.5240(1.5240) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103 - avg_train_loss: 1.6678  avg_val_loss: 1.4698  time: 41s\n",
      "Epoch 103 - MAE Score (without expiratory phase): 0.5930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.4186(1.4698) \n",
      "Epoch: [104][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.6941(1.6941) Grad: 6.5239  LR: 0.004931  \n",
      "Epoch: [104][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 2.4196(1.8794) Grad: 34.3046  LR: 0.004931  \n",
      "Epoch: [104][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.7588(1.9388) Grad: 6.5803  LR: 0.004931  \n",
      "Epoch: [104][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.7669(1.9149) Grad: 16.9416  LR: 0.004931  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 2.4667(2.4667) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104 - avg_train_loss: 1.9149  avg_val_loss: 2.4162  time: 41s\n",
      "Epoch 104 - MAE Score (without expiratory phase): 1.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.3969(2.4162) \n",
      "Epoch: [105][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 2.3201(2.3201) Grad: 43.4315  LR: 0.004887  \n",
      "Epoch: [105][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.8754(1.8603) Grad: 27.5020  LR: 0.004887  \n",
      "Epoch: [105][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.6896(1.7329) Grad: 10.9484  LR: 0.004887  \n",
      "Epoch: [105][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.4742(1.6933) Grad: 4.4177  LR: 0.004887  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.4397(1.4397) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105 - avg_train_loss: 1.6933  avg_val_loss: 1.4130  time: 40s\n",
      "Epoch 105 - MAE Score (without expiratory phase): 0.5595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3970(1.4130) \n",
      "Epoch: [106][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.5245(1.5245) Grad: 6.7003  LR: 0.004834  \n",
      "Epoch: [106][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.6287(1.6224) Grad: 21.4390  LR: 0.004834  \n",
      "Epoch: [106][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.5193(1.6221) Grad: 7.0864  LR: 0.004834  \n",
      "Epoch: [106][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.5859(1.6227) Grad: 22.1799  LR: 0.004834  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.4115(1.4115) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106 - avg_train_loss: 1.6227  avg_val_loss: 1.3893  time: 40s\n",
      "Epoch 106 - MAE Score (without expiratory phase): 0.5564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3782(1.3893) \n",
      "Epoch: [107][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.4769(1.4769) Grad: 11.0875  LR: 0.004772  \n",
      "Epoch: [107][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.5484(1.5173) Grad: 23.0571  LR: 0.004772  \n",
      "Epoch: [107][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.8673(1.5617) Grad: 38.8506  LR: 0.004772  \n",
      "Epoch: [107][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.5433(1.6303) Grad: 16.8363  LR: 0.004772  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.5629(1.5629) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107 - avg_train_loss: 1.6303  avg_val_loss: 1.5257  time: 40s\n",
      "Epoch 107 - MAE Score (without expiratory phase): 0.6202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.4941(1.5257) \n",
      "Epoch: [108][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.5859(1.5859) Grad: 23.9130  LR: 0.004701  \n",
      "Epoch: [108][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.4855(1.5380) Grad: 5.9761  LR: 0.004701  \n",
      "Epoch: [108][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.5443(1.5992) Grad: 11.1595  LR: 0.004701  \n",
      "Epoch: [108][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.5353(1.6022) Grad: 15.7352  LR: 0.004701  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.6970(1.6970) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108 - avg_train_loss: 1.6022  avg_val_loss: 1.6131  time: 41s\n",
      "Epoch 108 - MAE Score (without expiratory phase): 0.6636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.5449(1.6131) \n",
      "Epoch: [109][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.6523(1.6523) Grad: 33.9473  LR: 0.004621  \n",
      "Epoch: [109][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.5028(1.5527) Grad: 13.0600  LR: 0.004621  \n",
      "Epoch: [109][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.4179(1.4922) Grad: 15.4349  LR: 0.004621  \n",
      "Epoch: [109][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.4328(1.4769) Grad: 6.8951  LR: 0.004621  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.3748(1.3748) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109 - avg_train_loss: 1.4769  avg_val_loss: 1.3145  time: 41s\n",
      "Epoch 109 - MAE Score (without expiratory phase): 0.5245\n",
      "Epoch 109 - Save Best Score: 0.5245 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2695(1.3145) \n",
      "Epoch: [110][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.4151(1.4151) Grad: 8.5371  LR: 0.004532  \n",
      "Epoch: [110][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.5148(1.5084) Grad: 26.9935  LR: 0.004532  \n",
      "Epoch: [110][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.3731(1.5072) Grad: 9.3085  LR: 0.004532  \n",
      "Epoch: [110][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.5535(1.4979) Grad: 30.9388  LR: 0.004532  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.6429(1.6429) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110 - avg_train_loss: 1.4979  avg_val_loss: 1.6125  time: 41s\n",
      "Epoch 110 - MAE Score (without expiratory phase): 0.6642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.5673(1.6125) \n",
      "Epoch: [111][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.6702(1.6702) Grad: 30.1631  LR: 0.004436  \n",
      "Epoch: [111][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.5101(1.4664) Grad: 5.6874  LR: 0.004436  \n",
      "Epoch: [111][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.5067(1.4679) Grad: 19.3470  LR: 0.004436  \n",
      "Epoch: [111][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.7841(1.5151) Grad: 35.7595  LR: 0.004436  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.5937(1.5937) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111 - avg_train_loss: 1.5151  avg_val_loss: 1.5299  time: 41s\n",
      "Epoch 111 - MAE Score (without expiratory phase): 0.6171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.5218(1.5299) \n",
      "Epoch: [112][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.6689(1.6689) Grad: 28.3289  LR: 0.004332  \n",
      "Epoch: [112][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.5256(1.6124) Grad: 9.5606  LR: 0.004332  \n",
      "Epoch: [112][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.8234(1.6207) Grad: 28.2010  LR: 0.004332  \n",
      "Epoch: [112][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.5302(1.6408) Grad: 4.4731  LR: 0.004332  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.4957(1.4957) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112 - avg_train_loss: 1.6408  avg_val_loss: 1.4580  time: 41s\n",
      "Epoch 112 - MAE Score (without expiratory phase): 0.5843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3806(1.4580) \n",
      "Epoch: [113][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 1.5650(1.5650) Grad: 13.9341  LR: 0.004221  \n",
      "Epoch: [113][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.5914(1.5556) Grad: 22.2018  LR: 0.004221  \n",
      "Epoch: [113][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.5249(1.5258) Grad: 15.8417  LR: 0.004221  \n",
      "Epoch: [113][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.4898(1.5112) Grad: 13.6786  LR: 0.004221  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.5493(1.5493) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113 - avg_train_loss: 1.5112  avg_val_loss: 1.4703  time: 41s\n",
      "Epoch 113 - MAE Score (without expiratory phase): 0.5933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.4601(1.4703) \n",
      "Epoch: [114][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.6802(1.6802) Grad: 40.4410  LR: 0.004103  \n",
      "Epoch: [114][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.4639(1.5982) Grad: 19.8644  LR: 0.004103  \n",
      "Epoch: [114][40/58] Elapsed 0m 24s (remain 0m 9s) Loss: 1.5422(1.5412) Grad: 27.7192  LR: 0.004103  \n",
      "Epoch: [114][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.9812(1.6111) Grad: 6.7781  LR: 0.004103  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.9024(1.9024) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114 - avg_train_loss: 1.6111  avg_val_loss: 1.8477  time: 42s\n",
      "Epoch 114 - MAE Score (without expiratory phase): 0.7565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.7814(1.8477) \n",
      "Epoch: [115][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 1.9129(1.9129) Grad: 7.4096  LR: 0.003979  \n",
      "Epoch: [115][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.7012(1.8101) Grad: 9.7089  LR: 0.003979  \n",
      "Epoch: [115][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.5199(1.7249) Grad: 12.3608  LR: 0.003979  \n",
      "Epoch: [115][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.4677(1.6701) Grad: 6.2891  LR: 0.003979  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.4695(1.4695) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115 - avg_train_loss: 1.6701  avg_val_loss: 1.4003  time: 40s\n",
      "Epoch 115 - MAE Score (without expiratory phase): 0.5573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3598(1.4003) \n",
      "Epoch: [116][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.5376(1.5376) Grad: 15.5864  LR: 0.003849  \n",
      "Epoch: [116][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3906(1.4679) Grad: 9.2810  LR: 0.003849  \n",
      "Epoch: [116][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.4397(1.4651) Grad: 7.8915  LR: 0.003849  \n",
      "Epoch: [116][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.4684(1.4581) Grad: 6.5375  LR: 0.003849  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.3838(1.3838) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116 - avg_train_loss: 1.4581  avg_val_loss: 1.3128  time: 41s\n",
      "Epoch 116 - MAE Score (without expiratory phase): 0.5205\n",
      "Epoch 116 - Save Best Score: 0.5205 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2699(1.3128) \n",
      "Epoch: [117][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.4763(1.4763) Grad: 19.0975  LR: 0.003714  \n",
      "Epoch: [117][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.4431(1.4225) Grad: 10.5494  LR: 0.003714  \n",
      "Epoch: [117][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.5805(1.4477) Grad: 21.6053  LR: 0.003714  \n",
      "Epoch: [117][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.4854(1.4471) Grad: 26.8593  LR: 0.003714  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.3373(1.3373) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117 - avg_train_loss: 1.4471  avg_val_loss: 1.2830  time: 40s\n",
      "Epoch 117 - MAE Score (without expiratory phase): 0.5059\n",
      "Epoch 117 - Save Best Score: 0.5059 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2567(1.2830) \n",
      "Epoch: [118][0/58] Elapsed 0m 2s (remain 2m 28s) Loss: 1.3647(1.3647) Grad: 18.1862  LR: 0.003574  \n",
      "Epoch: [118][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.4057(1.4016) Grad: 5.7050  LR: 0.003574  \n",
      "Epoch: [118][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.6035(1.4319) Grad: 31.2823  LR: 0.003574  \n",
      "Epoch: [118][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3474(1.4241) Grad: 6.9919  LR: 0.003574  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.3045(1.3045) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118 - avg_train_loss: 1.4241  avg_val_loss: 1.2532  time: 41s\n",
      "Epoch 118 - MAE Score (without expiratory phase): 0.4933\n",
      "Epoch 118 - Save Best Score: 0.4933 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2001(1.2532) \n",
      "Epoch: [119][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 1.3204(1.3204) Grad: 5.8427  LR: 0.003430  \n",
      "Epoch: [119][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3314(1.3348) Grad: 13.4526  LR: 0.003430  \n",
      "Epoch: [119][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.4563(1.3408) Grad: 19.8803  LR: 0.003430  \n",
      "Epoch: [119][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.5641(1.3610) Grad: 25.0318  LR: 0.003430  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2827(1.2827) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119 - avg_train_loss: 1.3610  avg_val_loss: 1.2255  time: 41s\n",
      "Epoch 119 - MAE Score (without expiratory phase): 0.4829\n",
      "Epoch 119 - Save Best Score: 0.4829 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1714(1.2255) \n",
      "Epoch: [120][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.3522(1.3522) Grad: 7.0201  LR: 0.003282  \n",
      "Epoch: [120][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.4339(1.4088) Grad: 21.1426  LR: 0.003282  \n",
      "Epoch: [120][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.4574(1.4049) Grad: 23.3857  LR: 0.003282  \n",
      "Epoch: [120][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.3239(1.3918) Grad: 8.2476  LR: 0.003282  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.2912(1.2912) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120 - avg_train_loss: 1.3918  avg_val_loss: 1.2218  time: 41s\n",
      "Epoch 120 - MAE Score (without expiratory phase): 0.4797\n",
      "Epoch 120 - Save Best Score: 0.4797 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2037(1.2218) \n",
      "Epoch: [121][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.3617(1.3617) Grad: 16.0309  LR: 0.003132  \n",
      "Epoch: [121][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.3653(1.3133) Grad: 15.2392  LR: 0.003132  \n",
      "Epoch: [121][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.3703(1.3162) Grad: 5.2566  LR: 0.003132  \n",
      "Epoch: [121][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3734(1.3139) Grad: 8.5585  LR: 0.003132  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2363(1.2363) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121 - avg_train_loss: 1.3139  avg_val_loss: 1.1799  time: 41s\n",
      "Epoch 121 - MAE Score (without expiratory phase): 0.4611\n",
      "Epoch 121 - Save Best Score: 0.4611 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1472(1.1799) \n",
      "Epoch: [122][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.3172(1.3172) Grad: 8.6647  LR: 0.002978  \n",
      "Epoch: [122][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.4179(1.3032) Grad: 22.2783  LR: 0.002978  \n",
      "Epoch: [122][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3084(1.3055) Grad: 16.7977  LR: 0.002978  \n",
      "Epoch: [122][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3198(1.3051) Grad: 13.1318  LR: 0.002978  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.5156(1.5156) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122 - avg_train_loss: 1.3051  avg_val_loss: 1.4690  time: 41s\n",
      "Epoch 122 - MAE Score (without expiratory phase): 0.5957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.4235(1.4690) \n",
      "Epoch: [123][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.4850(1.4850) Grad: 30.7833  LR: 0.002823  \n",
      "Epoch: [123][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2875(1.3403) Grad: 16.4339  LR: 0.002823  \n",
      "Epoch: [123][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3597(1.3572) Grad: 9.4647  LR: 0.002823  \n",
      "Epoch: [123][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.4692(1.3603) Grad: 23.2025  LR: 0.002823  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.2365(1.2365) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123 - avg_train_loss: 1.3603  avg_val_loss: 1.1878  time: 41s\n",
      "Epoch 123 - MAE Score (without expiratory phase): 0.4641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1488(1.1878) \n",
      "Epoch: [124][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.2758(1.2758) Grad: 9.8902  LR: 0.002667  \n",
      "Epoch: [124][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3062(1.3466) Grad: 6.1781  LR: 0.002667  \n",
      "Epoch: [124][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3875(1.3360) Grad: 19.4814  LR: 0.002667  \n",
      "Epoch: [124][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.5369(1.3631) Grad: 24.5166  LR: 0.002667  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.4331(1.4331) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124 - avg_train_loss: 1.3631  avg_val_loss: 1.3485  time: 41s\n",
      "Epoch 124 - MAE Score (without expiratory phase): 0.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3116(1.3485) \n",
      "Epoch: [125][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.4352(1.4352) Grad: 6.5145  LR: 0.002510  \n",
      "Epoch: [125][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2843(1.3639) Grad: 7.0562  LR: 0.002510  \n",
      "Epoch: [125][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2568(1.3303) Grad: 6.2034  LR: 0.002510  \n",
      "Epoch: [125][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2984(1.3132) Grad: 10.5223  LR: 0.002510  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.2315(1.2315) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125 - avg_train_loss: 1.3132  avg_val_loss: 1.1901  time: 41s\n",
      "Epoch 125 - MAE Score (without expiratory phase): 0.4668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1736(1.1901) \n",
      "Epoch: [126][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 1.2611(1.2611) Grad: 8.2637  LR: 0.002353  \n",
      "Epoch: [126][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.2680(1.2811) Grad: 10.5935  LR: 0.002353  \n",
      "Epoch: [126][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3546(1.2892) Grad: 19.9599  LR: 0.002353  \n",
      "Epoch: [126][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2416(1.2856) Grad: 6.7584  LR: 0.002353  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2845(1.2845) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126 - avg_train_loss: 1.2856  avg_val_loss: 1.2132  time: 41s\n",
      "Epoch 126 - MAE Score (without expiratory phase): 0.4765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1816(1.2132) \n",
      "Epoch: [127][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.3273(1.3273) Grad: 7.0876  LR: 0.002196  \n",
      "Epoch: [127][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2165(1.2659) Grad: 4.7187  LR: 0.002196  \n",
      "Epoch: [127][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2066(1.2542) Grad: 5.9114  LR: 0.002196  \n",
      "Epoch: [127][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3352(1.2574) Grad: 22.2226  LR: 0.002196  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2223(1.2223) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127 - avg_train_loss: 1.2574  avg_val_loss: 1.1732  time: 40s\n",
      "Epoch 127 - MAE Score (without expiratory phase): 0.4599\n",
      "Epoch 127 - Save Best Score: 0.4599 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1242(1.1732) \n",
      "Epoch: [128][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 1.2355(1.2355) Grad: 10.3206  LR: 0.002041  \n",
      "Epoch: [128][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2223(1.2439) Grad: 8.2127  LR: 0.002041  \n",
      "Epoch: [128][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.2431(1.2322) Grad: 4.6871  LR: 0.002041  \n",
      "Epoch: [128][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.2218(1.2258) Grad: 3.9007  LR: 0.002041  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.1655(1.1655) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128 - avg_train_loss: 1.2258  avg_val_loss: 1.0911  time: 41s\n",
      "Epoch 128 - MAE Score (without expiratory phase): 0.4208\n",
      "Epoch 128 - Save Best Score: 0.4208 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0544(1.0911) \n",
      "Epoch: [129][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.2244(1.2244) Grad: 9.0639  LR: 0.001888  \n",
      "Epoch: [129][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2255(1.1983) Grad: 11.3492  LR: 0.001888  \n",
      "Epoch: [129][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.2260(1.2131) Grad: 6.4850  LR: 0.001888  \n",
      "Epoch: [129][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2488(1.2184) Grad: 5.6953  LR: 0.001888  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.1817(1.1817) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129 - avg_train_loss: 1.2184  avg_val_loss: 1.1580  time: 41s\n",
      "Epoch 129 - MAE Score (without expiratory phase): 0.4447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1132(1.1580) \n",
      "Epoch: [130][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.2559(1.2559) Grad: 9.9338  LR: 0.001737  \n",
      "Epoch: [130][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2428(1.2529) Grad: 6.1379  LR: 0.001737  \n",
      "Epoch: [130][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2167(1.2346) Grad: 14.9774  LR: 0.001737  \n",
      "Epoch: [130][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.2257(1.2343) Grad: 12.5996  LR: 0.001737  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.2078(1.2078) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130 - avg_train_loss: 1.2343  avg_val_loss: 1.1535  time: 41s\n",
      "Epoch 130 - MAE Score (without expiratory phase): 0.4501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1106(1.1535) \n",
      "Epoch: [131][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.2213(1.2213) Grad: 15.9311  LR: 0.001589  \n",
      "Epoch: [131][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2219(1.2013) Grad: 14.5832  LR: 0.001589  \n",
      "Epoch: [131][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2812(1.2152) Grad: 14.4792  LR: 0.001589  \n",
      "Epoch: [131][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2564(1.2302) Grad: 10.2251  LR: 0.001589  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2557(1.2557) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131 - avg_train_loss: 1.2302  avg_val_loss: 1.2270  time: 41s\n",
      "Epoch 131 - MAE Score (without expiratory phase): 0.4842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1599(1.2270) \n",
      "Epoch: [132][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.2938(1.2938) Grad: 24.0543  LR: 0.001445  \n",
      "Epoch: [132][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1626(1.2066) Grad: 3.8615  LR: 0.001445  \n",
      "Epoch: [132][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2221(1.1960) Grad: 4.7774  LR: 0.001445  \n",
      "Epoch: [132][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2041(1.1981) Grad: 9.7467  LR: 0.001445  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1213(1.1213) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132 - avg_train_loss: 1.1981  avg_val_loss: 1.0749  time: 41s\n",
      "Epoch 132 - MAE Score (without expiratory phase): 0.4135\n",
      "Epoch 132 - Save Best Score: 0.4135 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0207(1.0749) \n",
      "Epoch: [133][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.1735(1.1735) Grad: 4.4124  LR: 0.001305  \n",
      "Epoch: [133][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2086(1.1704) Grad: 4.2923  LR: 0.001305  \n",
      "Epoch: [133][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1455(1.1711) Grad: 5.7054  LR: 0.001305  \n",
      "Epoch: [133][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1248(1.1704) Grad: 4.1541  LR: 0.001305  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1172(1.1172) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133 - avg_train_loss: 1.1704  avg_val_loss: 1.0682  time: 41s\n",
      "Epoch 133 - MAE Score (without expiratory phase): 0.4099\n",
      "Epoch 133 - Save Best Score: 0.4099 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0357(1.0682) \n",
      "Epoch: [134][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.1169(1.1169) Grad: 2.4327  LR: 0.001170  \n",
      "Epoch: [134][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1749(1.1627) Grad: 5.1800  LR: 0.001170  \n",
      "Epoch: [134][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.2531(1.1714) Grad: 9.3689  LR: 0.001170  \n",
      "Epoch: [134][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1756(1.1716) Grad: 3.8648  LR: 0.001170  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1009(1.1009) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134 - avg_train_loss: 1.1716  avg_val_loss: 1.0523  time: 41s\n",
      "Epoch 134 - MAE Score (without expiratory phase): 0.4028\n",
      "Epoch 134 - Save Best Score: 0.4028 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0064(1.0523) \n",
      "Epoch: [135][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.2108(1.2108) Grad: 5.8873  LR: 0.001040  \n",
      "Epoch: [135][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1859(1.1702) Grad: 8.7815  LR: 0.001040  \n",
      "Epoch: [135][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1905(1.1637) Grad: 3.2293  LR: 0.001040  \n",
      "Epoch: [135][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1878(1.1634) Grad: 3.2459  LR: 0.001040  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0987(1.0987) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135 - avg_train_loss: 1.1634  avg_val_loss: 1.0573  time: 40s\n",
      "Epoch 135 - MAE Score (without expiratory phase): 0.4053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0099(1.0573) \n",
      "Epoch: [136][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.1742(1.1742) Grad: 5.4401  LR: 0.000916  \n",
      "Epoch: [136][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1717(1.1539) Grad: 3.4035  LR: 0.000916  \n",
      "Epoch: [136][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1769(1.1487) Grad: 7.0046  LR: 0.000916  \n",
      "Epoch: [136][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1498(1.1525) Grad: 6.3606  LR: 0.000916  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.1028(1.1028) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136 - avg_train_loss: 1.1525  avg_val_loss: 1.0578  time: 40s\n",
      "Epoch 136 - MAE Score (without expiratory phase): 0.4055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0113(1.0578) \n",
      "Epoch: [137][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.1327(1.1327) Grad: 2.7480  LR: 0.000798  \n",
      "Epoch: [137][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1582(1.1425) Grad: 2.6699  LR: 0.000798  \n",
      "Epoch: [137][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1091(1.1504) Grad: 9.7856  LR: 0.000798  \n",
      "Epoch: [137][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1178(1.1488) Grad: 4.6708  LR: 0.000798  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0924(1.0924) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137 - avg_train_loss: 1.1488  avg_val_loss: 1.0441  time: 41s\n",
      "Epoch 137 - MAE Score (without expiratory phase): 0.3991\n",
      "Epoch 137 - Save Best Score: 0.3991 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0063(1.0441) \n",
      "Epoch: [138][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.1477(1.1477) Grad: 4.2347  LR: 0.000687  \n",
      "Epoch: [138][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2120(1.1305) Grad: 10.1066  LR: 0.000687  \n",
      "Epoch: [138][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1309(1.1311) Grad: 4.1220  LR: 0.000687  \n",
      "Epoch: [138][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1507(1.1317) Grad: 4.1571  LR: 0.000687  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.0847(1.0847) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138 - avg_train_loss: 1.1317  avg_val_loss: 1.0272  time: 41s\n",
      "Epoch 138 - MAE Score (without expiratory phase): 0.3909\n",
      "Epoch 138 - Save Best Score: 0.3909 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9877(1.0272) \n",
      "Epoch: [139][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.0937(1.0937) Grad: 2.7551  LR: 0.000583  \n",
      "Epoch: [139][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1273(1.1271) Grad: 4.5671  LR: 0.000583  \n",
      "Epoch: [139][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.0781(1.1294) Grad: 2.4052  LR: 0.000583  \n",
      "Epoch: [139][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1321(1.1288) Grad: 5.7425  LR: 0.000583  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0686(1.0686) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139 - avg_train_loss: 1.1288  avg_val_loss: 1.0203  time: 41s\n",
      "Epoch 139 - MAE Score (without expiratory phase): 0.3877\n",
      "Epoch 139 - Save Best Score: 0.3877 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9706(1.0203) \n",
      "Epoch: [140][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.1267(1.1267) Grad: 2.4934  LR: 0.000487  \n",
      "Epoch: [140][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1214(1.1163) Grad: 5.6718  LR: 0.000487  \n",
      "Epoch: [140][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1210(1.1188) Grad: 5.5109  LR: 0.000487  \n",
      "Epoch: [140][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1055(1.1185) Grad: 2.0262  LR: 0.000487  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0821(1.0821) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140 - avg_train_loss: 1.1185  avg_val_loss: 1.0343  time: 41s\n",
      "Epoch 140 - MAE Score (without expiratory phase): 0.3945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9890(1.0343) \n",
      "Epoch: [141][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 1.1157(1.1157) Grad: 2.7162  LR: 0.000398  \n",
      "Epoch: [141][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1516(1.1171) Grad: 4.4435  LR: 0.000398  \n",
      "Epoch: [141][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1307(1.1217) Grad: 6.2115  LR: 0.000398  \n",
      "Epoch: [141][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1636(1.1232) Grad: 8.3107  LR: 0.000398  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0658(1.0658) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141 - avg_train_loss: 1.1232  avg_val_loss: 1.0219  time: 41s\n",
      "Epoch 141 - MAE Score (without expiratory phase): 0.3885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9594(1.0219) \n",
      "Epoch: [142][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.1081(1.1081) Grad: 5.8794  LR: 0.000318  \n",
      "Epoch: [142][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1135(1.1174) Grad: 2.8896  LR: 0.000318  \n",
      "Epoch: [142][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0660(1.1118) Grad: 5.3173  LR: 0.000318  \n",
      "Epoch: [142][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1613(1.1123) Grad: 3.5755  LR: 0.000318  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0694(1.0694) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142 - avg_train_loss: 1.1123  avg_val_loss: 1.0084  time: 40s\n",
      "Epoch 142 - MAE Score (without expiratory phase): 0.3823\n",
      "Epoch 142 - Save Best Score: 0.3823 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9518(1.0084) \n",
      "Epoch: [143][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 1.0885(1.0885) Grad: 2.6486  LR: 0.000247  \n",
      "Epoch: [143][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0970(1.1121) Grad: 4.7875  LR: 0.000247  \n",
      "Epoch: [143][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1328(1.1110) Grad: 10.5065  LR: 0.000247  \n",
      "Epoch: [143][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1292(1.1100) Grad: 2.1637  LR: 0.000247  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0661(1.0661) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143 - avg_train_loss: 1.1100  avg_val_loss: 1.0154  time: 41s\n",
      "Epoch 143 - MAE Score (without expiratory phase): 0.3855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9672(1.0154) \n",
      "Epoch: [144][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.1472(1.1472) Grad: 5.9591  LR: 0.000184  \n",
      "Epoch: [144][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1104(1.1073) Grad: 2.6872  LR: 0.000184  \n",
      "Epoch: [144][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1164(1.1085) Grad: 2.8515  LR: 0.000184  \n",
      "Epoch: [144][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0627(1.1067) Grad: 5.0541  LR: 0.000184  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0763(1.0763) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144 - avg_train_loss: 1.1067  avg_val_loss: 1.0258  time: 40s\n",
      "Epoch 144 - MAE Score (without expiratory phase): 0.3908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9759(1.0258) \n",
      "Epoch: [145][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 1.1027(1.1027) Grad: 3.5818  LR: 0.000131  \n",
      "Epoch: [145][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1348(1.1144) Grad: 2.9259  LR: 0.000131  \n",
      "Epoch: [145][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0875(1.1062) Grad: 2.6313  LR: 0.000131  \n",
      "Epoch: [145][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1068(1.1006) Grad: 2.5386  LR: 0.000131  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0606(1.0606) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145 - avg_train_loss: 1.1006  avg_val_loss: 1.0097  time: 41s\n",
      "Epoch 145 - MAE Score (without expiratory phase): 0.3830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9566(1.0097) \n",
      "Epoch: [146][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 1.0542(1.0542) Grad: 4.2945  LR: 0.000086  \n",
      "Epoch: [146][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0554(1.0925) Grad: 1.8571  LR: 0.000086  \n",
      "Epoch: [146][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0516(1.0985) Grad: 1.9208  LR: 0.000086  \n",
      "Epoch: [146][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0976(1.0973) Grad: 2.0287  LR: 0.000086  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0556(1.0556) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146 - avg_train_loss: 1.0973  avg_val_loss: 1.0064  time: 41s\n",
      "Epoch 146 - MAE Score (without expiratory phase): 0.3814\n",
      "Epoch 146 - Save Best Score: 0.3814 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9598(1.0064) \n",
      "Epoch: [147][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.1452(1.1452) Grad: 2.4033  LR: 0.000051  \n",
      "Epoch: [147][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0870(1.0939) Grad: 2.2538  LR: 0.000051  \n",
      "Epoch: [147][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0744(1.0979) Grad: 3.7312  LR: 0.000051  \n",
      "Epoch: [147][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1236(1.0973) Grad: 2.5026  LR: 0.000051  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0543(1.0543) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147 - avg_train_loss: 1.0973  avg_val_loss: 1.0036  time: 41s\n",
      "Epoch 147 - MAE Score (without expiratory phase): 0.3801\n",
      "Epoch 147 - Save Best Score: 0.3801 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9576(1.0036) \n",
      "Epoch: [148][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.1124(1.1124) Grad: 4.1537  LR: 0.000026  \n",
      "Epoch: [148][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0747(1.0945) Grad: 2.0686  LR: 0.000026  \n",
      "Epoch: [148][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0901(1.0926) Grad: 1.8177  LR: 0.000026  \n",
      "Epoch: [148][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1318(1.0940) Grad: 1.7900  LR: 0.000026  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0546(1.0546) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148 - avg_train_loss: 1.0940  avg_val_loss: 1.0030  time: 41s\n",
      "Epoch 148 - MAE Score (without expiratory phase): 0.3798\n",
      "Epoch 148 - Save Best Score: 0.3798 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9558(1.0030) \n",
      "Epoch: [149][0/58] Elapsed 0m 2s (remain 2m 29s) Loss: 1.1164(1.1164) Grad: 2.5941  LR: 0.000010  \n",
      "Epoch: [149][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1543(1.0944) Grad: 3.6960  LR: 0.000010  \n",
      "Epoch: [149][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1225(1.0953) Grad: 3.3241  LR: 0.000010  \n",
      "Epoch: [149][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0809(1.0928) Grad: 8.0287  LR: 0.000010  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0536(1.0536) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149 - avg_train_loss: 1.0928  avg_val_loss: 1.0019  time: 41s\n",
      "Epoch 149 - MAE Score (without expiratory phase): 0.3793\n",
      "Epoch 149 - Save Best Score: 0.3793 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9580(1.0019) \n",
      "Epoch: [150][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.0819(1.0819) Grad: 2.5596  LR: 0.000002  \n",
      "Epoch: [150][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.0822(1.0844) Grad: 3.7511  LR: 0.000002  \n",
      "Epoch: [150][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0828(1.0891) Grad: 1.5061  LR: 0.000002  \n",
      "Epoch: [150][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0930(1.0898) Grad: 3.9270  LR: 0.000002  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.0519(1.0519) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150 - avg_train_loss: 1.0898  avg_val_loss: 1.0004  time: 41s\n",
      "Epoch 150 - MAE Score (without expiratory phase): 0.3786\n",
      "Epoch 150 - Save Best Score: 0.3786 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9560(1.0004) \n",
      "Epoch: [151][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.0925(1.0925) Grad: 1.7822  LR: 0.000001  \n",
      "Epoch: [151][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0600(1.0816) Grad: 2.6188  LR: 0.000001  \n",
      "Epoch: [151][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0781(1.0899) Grad: 1.9927  LR: 0.000001  \n",
      "Epoch: [151][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1138(1.0929) Grad: 3.1245  LR: 0.000001  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.0526(1.0526) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151 - avg_train_loss: 1.0929  avg_val_loss: 1.0014  time: 41s\n",
      "Epoch 151 - MAE Score (without expiratory phase): 0.3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9568(1.0014) \n",
      "Epoch: [152][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.0765(1.0765) Grad: 2.6200  LR: 0.000011  \n",
      "Epoch: [152][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0741(1.0877) Grad: 1.7236  LR: 0.000011  \n",
      "Epoch: [152][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1005(1.0894) Grad: 2.0162  LR: 0.000011  \n",
      "Epoch: [152][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0790(1.0904) Grad: 1.7599  LR: 0.000011  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.0537(1.0537) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152 - avg_train_loss: 1.0904  avg_val_loss: 1.0011  time: 41s\n",
      "Epoch 152 - MAE Score (without expiratory phase): 0.3789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9563(1.0011) \n",
      "Epoch: [153][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 1.0837(1.0837) Grad: 2.1395  LR: 0.000080  \n",
      "Epoch: [153][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1132(1.0909) Grad: 3.1028  LR: 0.000080  \n",
      "Epoch: [153][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.0567(1.0884) Grad: 3.5771  LR: 0.000080  \n",
      "Epoch: [153][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0485(1.0890) Grad: 4.3929  LR: 0.000080  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0539(1.0539) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153 - avg_train_loss: 1.0890  avg_val_loss: 1.0028  time: 41s\n",
      "Epoch 153 - MAE Score (without expiratory phase): 0.3797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 0.9567(1.0028) \n",
      "Epoch: [154][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.0572(1.0572) Grad: 1.2078  LR: 0.000100  \n",
      "Epoch: [154][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0754(1.0916) Grad: 5.1140  LR: 0.000100  \n",
      "Epoch: [154][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0950(1.0952) Grad: 3.7666  LR: 0.000100  \n",
      "Epoch: [154][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0401(1.0915) Grad: 2.7534  LR: 0.000100  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.0526(1.0526) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154 - avg_train_loss: 1.0915  avg_val_loss: 1.0026  time: 41s\n",
      "Epoch 154 - MAE Score (without expiratory phase): 0.3797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9545(1.0026) \n",
      "Epoch: [155][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.0936(1.0936) Grad: 3.9338  LR: 0.000140  \n",
      "Epoch: [155][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0913(1.0927) Grad: 2.4754  LR: 0.000140  \n",
      "Epoch: [155][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0888(1.0913) Grad: 2.0655  LR: 0.000140  \n",
      "Epoch: [155][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0604(1.0925) Grad: 1.5192  LR: 0.000140  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0561(1.0561) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155 - avg_train_loss: 1.0925  avg_val_loss: 1.0028  time: 41s\n",
      "Epoch 155 - MAE Score (without expiratory phase): 0.3797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9573(1.0028) \n",
      "Epoch: [156][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.1280(1.1280) Grad: 4.0093  LR: 0.000192  \n",
      "Epoch: [156][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1001(1.0915) Grad: 6.7118  LR: 0.000192  \n",
      "Epoch: [156][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0820(1.0927) Grad: 5.6672  LR: 0.000192  \n",
      "Epoch: [156][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1254(1.0939) Grad: 3.7121  LR: 0.000192  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0564(1.0564) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 156 - avg_train_loss: 1.0939  avg_val_loss: 1.0065  time: 41s\n",
      "Epoch 156 - MAE Score (without expiratory phase): 0.3815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9608(1.0065) \n",
      "Epoch: [157][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.1157(1.1157) Grad: 4.2713  LR: 0.000253  \n",
      "Epoch: [157][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1049(1.0905) Grad: 5.1464  LR: 0.000253  \n",
      "Epoch: [157][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1142(1.0980) Grad: 3.2638  LR: 0.000253  \n",
      "Epoch: [157][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0769(1.0983) Grad: 1.7296  LR: 0.000253  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0545(1.0545) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 157 - avg_train_loss: 1.0983  avg_val_loss: 1.0056  time: 41s\n",
      "Epoch 157 - MAE Score (without expiratory phase): 0.3812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9594(1.0056) \n",
      "Epoch: [158][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.0840(1.0840) Grad: 2.3041  LR: 0.000323  \n",
      "Epoch: [158][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0999(1.0963) Grad: 8.8175  LR: 0.000323  \n",
      "Epoch: [158][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.0555(1.0974) Grad: 2.6613  LR: 0.000323  \n",
      "Epoch: [158][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1439(1.1024) Grad: 5.2015  LR: 0.000323  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0575(1.0575) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 158 - avg_train_loss: 1.1024  avg_val_loss: 1.0077  time: 41s\n",
      "Epoch 158 - MAE Score (without expiratory phase): 0.3822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9719(1.0077) \n",
      "Epoch: [159][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.0812(1.0812) Grad: 3.5558  LR: 0.000403  \n",
      "Epoch: [159][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0994(1.1009) Grad: 4.0704  LR: 0.000403  \n",
      "Epoch: [159][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0903(1.1010) Grad: 3.6630  LR: 0.000403  \n",
      "Epoch: [159][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0622(1.1002) Grad: 2.7984  LR: 0.000403  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.0519(1.0519) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159 - avg_train_loss: 1.1002  avg_val_loss: 1.0015  time: 41s\n",
      "Epoch 159 - MAE Score (without expiratory phase): 0.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9450(1.0015) \n",
      "Epoch: [160][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.1245(1.1245) Grad: 3.9345  LR: 0.000491  \n",
      "Epoch: [160][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1007(1.1130) Grad: 2.8452  LR: 0.000491  \n",
      "Epoch: [160][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0883(1.1046) Grad: 3.7220  LR: 0.000491  \n",
      "Epoch: [160][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1049(1.1049) Grad: 6.1967  LR: 0.000491  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0546(1.0546) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160 - avg_train_loss: 1.1049  avg_val_loss: 1.0073  time: 41s\n",
      "Epoch 160 - MAE Score (without expiratory phase): 0.3818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9616(1.0073) \n",
      "Epoch: [161][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.1370(1.1370) Grad: 2.3679  LR: 0.000587  \n",
      "Epoch: [161][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1551(1.1063) Grad: 9.8244  LR: 0.000587  \n",
      "Epoch: [161][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.1361(1.1070) Grad: 8.5188  LR: 0.000587  \n",
      "Epoch: [161][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0835(1.1074) Grad: 6.8645  LR: 0.000587  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.0762(1.0762) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161 - avg_train_loss: 1.1074  avg_val_loss: 1.0328  time: 40s\n",
      "Epoch 161 - MAE Score (without expiratory phase): 0.3943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9860(1.0328) \n",
      "Epoch: [162][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.1197(1.1197) Grad: 5.6016  LR: 0.000690  \n",
      "Epoch: [162][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.0938(1.1142) Grad: 1.3919  LR: 0.000690  \n",
      "Epoch: [162][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0863(1.1121) Grad: 2.4846  LR: 0.000690  \n",
      "Epoch: [162][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0806(1.1106) Grad: 4.4348  LR: 0.000690  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0789(1.0789) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162 - avg_train_loss: 1.1106  avg_val_loss: 1.0302  time: 41s\n",
      "Epoch 162 - MAE Score (without expiratory phase): 0.3920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9784(1.0302) \n",
      "Epoch: [163][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.0906(1.0906) Grad: 12.1165  LR: 0.000801  \n",
      "Epoch: [163][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1752(1.1598) Grad: 9.1604  LR: 0.000801  \n",
      "Epoch: [163][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1555(1.1414) Grad: 6.1488  LR: 0.000801  \n",
      "Epoch: [163][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1174(1.1313) Grad: 4.1164  LR: 0.000801  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0702(1.0702) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 163 - avg_train_loss: 1.1313  avg_val_loss: 1.0161  time: 41s\n",
      "Epoch 163 - MAE Score (without expiratory phase): 0.3858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 0.9733(1.0161) \n",
      "Epoch: [164][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.1284(1.1284) Grad: 3.3529  LR: 0.000919  \n",
      "Epoch: [164][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1062(1.1126) Grad: 1.9546  LR: 0.000919  \n",
      "Epoch: [164][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0760(1.1132) Grad: 3.7924  LR: 0.000919  \n",
      "Epoch: [164][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0805(1.1125) Grad: 2.5692  LR: 0.000919  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0796(1.0796) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 164 - avg_train_loss: 1.1125  avg_val_loss: 1.0218  time: 41s\n",
      "Epoch 164 - MAE Score (without expiratory phase): 0.3885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9741(1.0218) \n",
      "Epoch: [165][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.1342(1.1342) Grad: 4.3363  LR: 0.001043  \n",
      "Epoch: [165][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0761(1.1177) Grad: 3.7259  LR: 0.001043  \n",
      "Epoch: [165][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.0787(1.1166) Grad: 6.5886  LR: 0.001043  \n",
      "Epoch: [165][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1279(1.1157) Grad: 14.3622  LR: 0.001043  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0725(1.0725) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165 - avg_train_loss: 1.1157  avg_val_loss: 1.0205  time: 41s\n",
      "Epoch 165 - MAE Score (without expiratory phase): 0.3882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9902(1.0205) \n",
      "Epoch: [166][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 1.1289(1.1289) Grad: 9.4317  LR: 0.001172  \n",
      "Epoch: [166][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2338(1.1501) Grad: 19.9731  LR: 0.001172  \n",
      "Epoch: [166][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2697(1.1763) Grad: 26.5555  LR: 0.001172  \n",
      "Epoch: [166][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1435(1.1693) Grad: 15.5202  LR: 0.001172  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.1013(1.1013) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166 - avg_train_loss: 1.1693  avg_val_loss: 1.0489  time: 41s\n",
      "Epoch 166 - MAE Score (without expiratory phase): 0.4012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0088(1.0489) \n",
      "Epoch: [167][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.0967(1.0967) Grad: 7.9644  LR: 0.001307  \n",
      "Epoch: [167][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2617(1.2698) Grad: 13.7640  LR: 0.001307  \n",
      "Epoch: [167][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1690(1.2300) Grad: 8.4317  LR: 0.001307  \n",
      "Epoch: [167][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2737(1.2208) Grad: 23.5935  LR: 0.001307  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.1133(1.1133) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167 - avg_train_loss: 1.2208  avg_val_loss: 1.0559  time: 41s\n",
      "Epoch 167 - MAE Score (without expiratory phase): 0.4023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0062(1.0559) \n",
      "Epoch: [168][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 1.1112(1.1112) Grad: 8.7085  LR: 0.001447  \n",
      "Epoch: [168][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1607(1.1575) Grad: 4.5376  LR: 0.001447  \n",
      "Epoch: [168][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1682(1.1805) Grad: 16.1146  LR: 0.001447  \n",
      "Epoch: [168][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3453(1.2109) Grad: 16.8960  LR: 0.001447  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1535(1.1535) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168 - avg_train_loss: 1.2109  avg_val_loss: 1.1241  time: 41s\n",
      "Epoch 168 - MAE Score (without expiratory phase): 0.4354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0604(1.1241) \n",
      "Epoch: [169][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.1992(1.1992) Grad: 5.9678  LR: 0.001591  \n",
      "Epoch: [169][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.4976(1.3425) Grad: 21.0288  LR: 0.001591  \n",
      "Epoch: [169][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3609(1.3852) Grad: 5.8905  LR: 0.001591  \n",
      "Epoch: [169][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2437(1.3597) Grad: 6.6653  LR: 0.001591  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2621(1.2621) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169 - avg_train_loss: 1.3597  avg_val_loss: 1.1953  time: 41s\n",
      "Epoch 169 - MAE Score (without expiratory phase): 0.4626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1857(1.1953) \n",
      "Epoch: [170][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.2301(1.2301) Grad: 8.4847  LR: 0.001739  \n",
      "Epoch: [170][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.3974(1.4361) Grad: 9.7780  LR: 0.001739  \n",
      "Epoch: [170][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.4460(1.4629) Grad: 7.3507  LR: 0.001739  \n",
      "Epoch: [170][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3887(1.4419) Grad: 25.0066  LR: 0.001739  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.2269(1.2269) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170 - avg_train_loss: 1.4419  avg_val_loss: 1.1662  time: 40s\n",
      "Epoch 170 - MAE Score (without expiratory phase): 0.4517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1368(1.1662) \n",
      "Epoch: [171][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.2905(1.2905) Grad: 3.9214  LR: 0.001890  \n",
      "Epoch: [171][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.4905(1.3914) Grad: 19.5439  LR: 0.001890  \n",
      "Epoch: [171][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3071(1.3929) Grad: 14.1799  LR: 0.001890  \n",
      "Epoch: [171][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2029(1.3430) Grad: 4.9968  LR: 0.001890  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.1647(1.1647) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 171 - avg_train_loss: 1.3430  avg_val_loss: 1.0966  time: 41s\n",
      "Epoch 171 - MAE Score (without expiratory phase): 0.4182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0695(1.0966) \n",
      "Epoch: [172][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 1.1461(1.1461) Grad: 8.2854  LR: 0.002043  \n",
      "Epoch: [172][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.1577(1.1805) Grad: 6.4775  LR: 0.002043  \n",
      "Epoch: [172][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1879(1.1967) Grad: 15.4587  LR: 0.002043  \n",
      "Epoch: [172][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2535(1.1966) Grad: 17.2077  LR: 0.002043  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.1400(1.1400) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 172 - avg_train_loss: 1.1966  avg_val_loss: 1.0750  time: 41s\n",
      "Epoch 172 - MAE Score (without expiratory phase): 0.4117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0328(1.0750) \n",
      "Epoch: [173][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.1558(1.1558) Grad: 8.2538  LR: 0.002198  \n",
      "Epoch: [173][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2331(1.2386) Grad: 15.8682  LR: 0.002198  \n",
      "Epoch: [173][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2887(1.2269) Grad: 6.1681  LR: 0.002198  \n",
      "Epoch: [173][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.5739(1.2764) Grad: 35.3602  LR: 0.002198  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.3477(1.3477) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 173 - avg_train_loss: 1.2764  avg_val_loss: 1.2650  time: 41s\n",
      "Epoch 173 - MAE Score (without expiratory phase): 0.5032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2047(1.2650) \n",
      "Epoch: [174][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 1.4265(1.4265) Grad: 18.4412  LR: 0.002354  \n",
      "Epoch: [174][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2449(1.3976) Grad: 15.0570  LR: 0.002354  \n",
      "Epoch: [174][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.5628(1.4658) Grad: 23.1484  LR: 0.002354  \n",
      "Epoch: [174][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2950(1.4471) Grad: 6.8702  LR: 0.002354  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.3424(1.3424) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 174 - avg_train_loss: 1.4471  avg_val_loss: 1.2660  time: 41s\n",
      "Epoch 174 - MAE Score (without expiratory phase): 0.4956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2401(1.2660) \n",
      "Epoch: [175][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 1.3400(1.3400) Grad: 8.7310  LR: 0.002511  \n",
      "Epoch: [175][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.5117(1.3609) Grad: 33.2173  LR: 0.002511  \n",
      "Epoch: [175][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.2644(1.3610) Grad: 5.8660  LR: 0.002511  \n",
      "Epoch: [175][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.4121(1.4039) Grad: 6.1194  LR: 0.002511  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.8516(1.8516) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 175 - avg_train_loss: 1.4039  avg_val_loss: 1.7900  time: 40s\n",
      "Epoch 175 - MAE Score (without expiratory phase): 0.7424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.8513(1.7900) \n",
      "Epoch: [176][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.9179(1.9179) Grad: 37.3656  LR: 0.002668  \n",
      "Epoch: [176][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2817(1.4072) Grad: 12.7482  LR: 0.002668  \n",
      "Epoch: [176][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2559(1.3322) Grad: 16.8351  LR: 0.002668  \n",
      "Epoch: [176][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3095(1.2916) Grad: 19.4729  LR: 0.002668  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1973(1.1973) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 176 - avg_train_loss: 1.2916  avg_val_loss: 1.1503  time: 41s\n",
      "Epoch 176 - MAE Score (without expiratory phase): 0.4499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1251(1.1503) \n",
      "Epoch: [177][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.2395(1.2395) Grad: 16.5795  LR: 0.002824  \n",
      "Epoch: [177][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2370(1.2114) Grad: 12.8896  LR: 0.002824  \n",
      "Epoch: [177][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1541(1.2238) Grad: 4.0793  LR: 0.002824  \n",
      "Epoch: [177][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.5375(1.2666) Grad: 30.6928  LR: 0.002824  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.6225(1.6225) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177 - avg_train_loss: 1.2666  avg_val_loss: 1.6030  time: 41s\n",
      "Epoch 177 - MAE Score (without expiratory phase): 0.6626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.5263(1.6030) \n",
      "Epoch: [178][0/58] Elapsed 0m 2s (remain 2m 29s) Loss: 1.6100(1.6100) Grad: 31.1600  LR: 0.002979  \n",
      "Epoch: [178][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.4092(1.3846) Grad: 19.2375  LR: 0.002979  \n",
      "Epoch: [178][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2133(1.3353) Grad: 14.1160  LR: 0.002979  \n",
      "Epoch: [178][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3597(1.3483) Grad: 20.7669  LR: 0.002979  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.5423(1.5423) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 178 - avg_train_loss: 1.3483  avg_val_loss: 1.5028  time: 41s\n",
      "Epoch 178 - MAE Score (without expiratory phase): 0.6172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.4216(1.5028) \n",
      "Epoch: [179][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 1.6079(1.6079) Grad: 33.5429  LR: 0.003133  \n",
      "Epoch: [179][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2027(1.2708) Grad: 11.6203  LR: 0.003133  \n",
      "Epoch: [179][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.2764(1.2466) Grad: 18.4612  LR: 0.003133  \n",
      "Epoch: [179][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2295(1.2375) Grad: 7.2393  LR: 0.003133  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1719(1.1719) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179 - avg_train_loss: 1.2375  avg_val_loss: 1.1359  time: 40s\n",
      "Epoch 179 - MAE Score (without expiratory phase): 0.4424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0693(1.1359) \n",
      "Epoch: [180][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.1971(1.1971) Grad: 11.3757  LR: 0.003283  \n",
      "Epoch: [180][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.3637(1.3318) Grad: 11.3314  LR: 0.003283  \n",
      "Epoch: [180][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2912(1.3134) Grad: 8.4262  LR: 0.003283  \n",
      "Epoch: [180][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2296(1.2950) Grad: 14.3732  LR: 0.003283  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.1040(1.1040) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 180 - avg_train_loss: 1.2950  avg_val_loss: 1.0737  time: 41s\n",
      "Epoch 180 - MAE Score (without expiratory phase): 0.4127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 1.0291(1.0737) \n",
      "Epoch: [181][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.1653(1.1653) Grad: 9.9876  LR: 0.003431  \n",
      "Epoch: [181][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.7638(1.3679) Grad: 42.9739  LR: 0.003431  \n",
      "Epoch: [181][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.6309(1.4201) Grad: 28.1116  LR: 0.003431  \n",
      "Epoch: [181][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2583(1.4175) Grad: 6.6090  LR: 0.003431  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.1852(1.1852) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 181 - avg_train_loss: 1.4175  avg_val_loss: 1.1487  time: 40s\n",
      "Epoch 181 - MAE Score (without expiratory phase): 0.4480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1120(1.1487) \n",
      "Epoch: [182][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.2214(1.2214) Grad: 12.1276  LR: 0.003575  \n",
      "Epoch: [182][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2636(1.2423) Grad: 5.0778  LR: 0.003575  \n",
      "Epoch: [182][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.4039(1.3255) Grad: 20.8989  LR: 0.003575  \n",
      "Epoch: [182][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.4104(1.3598) Grad: 11.9628  LR: 0.003575  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.4793(1.4793) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 182 - avg_train_loss: 1.3598  avg_val_loss: 1.4151  time: 41s\n",
      "Epoch 182 - MAE Score (without expiratory phase): 0.5678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3535(1.4151) \n",
      "Epoch: [183][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.4658(1.4658) Grad: 26.0003  LR: 0.003715  \n",
      "Epoch: [183][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2103(1.3388) Grad: 8.2428  LR: 0.003715  \n",
      "Epoch: [183][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3683(1.5371) Grad: 15.0996  LR: 0.003715  \n",
      "Epoch: [183][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.6437(1.4876) Grad: 17.6112  LR: 0.003715  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.4257(1.4257) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 183 - avg_train_loss: 1.4876  avg_val_loss: 1.3666  time: 41s\n",
      "Epoch 183 - MAE Score (without expiratory phase): 0.5288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3584(1.3666) \n",
      "Epoch: [184][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.4140(1.4140) Grad: 7.9013  LR: 0.003850  \n",
      "Epoch: [184][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.2846(1.4018) Grad: 3.2547  LR: 0.003850  \n",
      "Epoch: [184][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3764(1.3669) Grad: 13.4160  LR: 0.003850  \n",
      "Epoch: [184][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.4929(1.3745) Grad: 28.6301  LR: 0.003850  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1955(1.1955) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 184 - avg_train_loss: 1.3745  avg_val_loss: 1.1724  time: 41s\n",
      "Epoch 184 - MAE Score (without expiratory phase): 0.4577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1346(1.1724) \n",
      "Epoch: [185][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 1.2484(1.2484) Grad: 15.0006  LR: 0.003980  \n",
      "Epoch: [185][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2747(1.4506) Grad: 9.4434  LR: 0.003980  \n",
      "Epoch: [185][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3562(1.4121) Grad: 23.3190  LR: 0.003980  \n",
      "Epoch: [185][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.5370(1.3960) Grad: 31.8666  LR: 0.003980  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.2696(1.2696) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185 - avg_train_loss: 1.3960  avg_val_loss: 1.2155  time: 41s\n",
      "Epoch 185 - MAE Score (without expiratory phase): 0.4803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1976(1.2155) \n",
      "Epoch: [186][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.3586(1.3586) Grad: 10.8051  LR: 0.004104  \n",
      "Epoch: [186][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2485(1.3806) Grad: 9.6857  LR: 0.004104  \n",
      "Epoch: [186][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2172(1.3217) Grad: 5.1337  LR: 0.004104  \n",
      "Epoch: [186][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2541(1.3096) Grad: 4.1495  LR: 0.004104  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2510(1.2510) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 186 - avg_train_loss: 1.3096  avg_val_loss: 1.2194  time: 41s\n",
      "Epoch 186 - MAE Score (without expiratory phase): 0.4819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1957(1.2194) \n",
      "Epoch: [187][0/58] Elapsed 0m 2s (remain 2m 29s) Loss: 1.2636(1.2636) Grad: 7.5888  LR: 0.004222  \n",
      "Epoch: [187][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 2.4415(1.6226) Grad: 54.5845  LR: 0.004222  \n",
      "Epoch: [187][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.3022(1.5769) Grad: 8.3227  LR: 0.004222  \n",
      "Epoch: [187][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.5744(1.5286) Grad: 27.9647  LR: 0.004222  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.4497(1.4497) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 187 - avg_train_loss: 1.5286  avg_val_loss: 1.3904  time: 40s\n",
      "Epoch 187 - MAE Score (without expiratory phase): 0.5596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3583(1.3904) \n",
      "Epoch: [188][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.3673(1.3673) Grad: 23.9275  LR: 0.004333  \n",
      "Epoch: [188][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2916(1.2884) Grad: 12.8439  LR: 0.004333  \n",
      "Epoch: [188][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3316(1.2820) Grad: 18.7941  LR: 0.004333  \n",
      "Epoch: [188][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2950(1.3024) Grad: 12.6766  LR: 0.004333  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2114(1.2114) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188 - avg_train_loss: 1.3024  avg_val_loss: 1.1525  time: 41s\n",
      "Epoch 188 - MAE Score (without expiratory phase): 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1006(1.1525) \n",
      "Epoch: [189][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.1990(1.1990) Grad: 4.7847  LR: 0.004437  \n",
      "Epoch: [189][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3648(1.2759) Grad: 24.5508  LR: 0.004437  \n",
      "Epoch: [189][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.4455(1.2996) Grad: 25.8735  LR: 0.004437  \n",
      "Epoch: [189][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.2028(1.2915) Grad: 8.6654  LR: 0.004437  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.1399(1.1399) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189 - avg_train_loss: 1.2915  avg_val_loss: 1.1010  time: 41s\n",
      "Epoch 189 - MAE Score (without expiratory phase): 0.4251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0710(1.1010) \n",
      "Epoch: [190][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.2481(1.2481) Grad: 6.3172  LR: 0.004533  \n",
      "Epoch: [190][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3049(1.3715) Grad: 16.0303  LR: 0.004533  \n",
      "Epoch: [190][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3443(1.3250) Grad: 8.6458  LR: 0.004533  \n",
      "Epoch: [190][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1997(1.3056) Grad: 12.2054  LR: 0.004533  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.2675(1.2675) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 190 - avg_train_loss: 1.3056  avg_val_loss: 1.2199  time: 41s\n",
      "Epoch 190 - MAE Score (without expiratory phase): 0.4849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1781(1.2199) \n",
      "Epoch: [191][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.2887(1.2887) Grad: 23.1470  LR: 0.004621  \n",
      "Epoch: [191][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.8215(1.6897) Grad: 31.8205  LR: 0.004621  \n",
      "Epoch: [191][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3152(1.5749) Grad: 4.4939  LR: 0.004621  \n",
      "Epoch: [191][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.5703(1.5070) Grad: 29.4857  LR: 0.004621  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.2880(1.2880) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 191 - avg_train_loss: 1.5070  avg_val_loss: 1.2563  time: 40s\n",
      "Epoch 191 - MAE Score (without expiratory phase): 0.5004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1807(1.2563) \n",
      "Epoch: [192][0/58] Elapsed 0m 2s (remain 2m 29s) Loss: 1.3507(1.3507) Grad: 15.8236  LR: 0.004701  \n",
      "Epoch: [192][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2988(1.3555) Grad: 15.9915  LR: 0.004701  \n",
      "Epoch: [192][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2633(1.3250) Grad: 5.6009  LR: 0.004701  \n",
      "Epoch: [192][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.3337(1.3547) Grad: 6.9520  LR: 0.004701  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.3071(1.3071) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 192 - avg_train_loss: 1.3547  avg_val_loss: 1.2600  time: 41s\n",
      "Epoch 192 - MAE Score (without expiratory phase): 0.5016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2321(1.2600) \n",
      "Epoch: [193][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 1.2949(1.2949) Grad: 21.3364  LR: 0.004772  \n",
      "Epoch: [193][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3548(1.3863) Grad: 18.8178  LR: 0.004772  \n",
      "Epoch: [193][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 2.0703(1.4114) Grad: 32.1489  LR: 0.004772  \n",
      "Epoch: [193][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.7386(1.6222) Grad: 10.1790  LR: 0.004772  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.6774(1.6774) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193 - avg_train_loss: 1.6222  avg_val_loss: 1.6207  time: 41s\n",
      "Epoch 193 - MAE Score (without expiratory phase): 0.6490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.5796(1.6207) \n",
      "Epoch: [194][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.7792(1.7792) Grad: 11.8331  LR: 0.004834  \n",
      "Epoch: [194][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.4983(1.7004) Grad: 8.8482  LR: 0.004834  \n",
      "Epoch: [194][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.5527(1.6276) Grad: 19.5926  LR: 0.004834  \n",
      "Epoch: [194][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.6282(1.6705) Grad: 11.5737  LR: 0.004834  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.5418(1.5418) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 194 - avg_train_loss: 1.6705  avg_val_loss: 1.5427  time: 41s\n",
      "Epoch 194 - MAE Score (without expiratory phase): 0.6140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.4955(1.5427) \n",
      "Epoch: [195][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.6829(1.6829) Grad: 9.2709  LR: 0.004888  \n",
      "Epoch: [195][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.5412(1.5752) Grad: 11.4905  LR: 0.004888  \n",
      "Epoch: [195][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.5598(1.5352) Grad: 17.7647  LR: 0.004888  \n",
      "Epoch: [195][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.6163(1.5394) Grad: 14.6727  LR: 0.004888  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.3783(1.3783) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 195 - avg_train_loss: 1.5394  avg_val_loss: 1.3249  time: 40s\n",
      "Epoch 195 - MAE Score (without expiratory phase): 0.5301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2876(1.3249) \n",
      "Epoch: [196][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.3980(1.3980) Grad: 12.6430  LR: 0.004931  \n",
      "Epoch: [196][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.6685(1.5879) Grad: 20.6725  LR: 0.004931  \n",
      "Epoch: [196][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.9601(1.6092) Grad: 34.8885  LR: 0.004931  \n",
      "Epoch: [196][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.9914(1.7981) Grad: 12.5145  LR: 0.004931  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 2.3918(2.3918) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 196 - avg_train_loss: 1.7981  avg_val_loss: 2.3542  time: 41s\n",
      "Epoch 196 - MAE Score (without expiratory phase): 1.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 2.2949(2.3542) \n",
      "Epoch: [197][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 2.4170(2.4170) Grad: 32.1126  LR: 0.004966  \n",
      "Epoch: [197][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.5982(1.8280) Grad: 12.2398  LR: 0.004966  \n",
      "Epoch: [197][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.4712(1.7379) Grad: 9.2352  LR: 0.004966  \n",
      "Epoch: [197][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.4690(1.6686) Grad: 18.4764  LR: 0.004966  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.5730(1.5730) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197 - avg_train_loss: 1.6686  avg_val_loss: 1.5181  time: 41s\n",
      "Epoch 197 - MAE Score (without expiratory phase): 0.6194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.5053(1.5181) \n",
      "Epoch: [198][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.5650(1.5650) Grad: 21.7201  LR: 0.004990  \n",
      "Epoch: [198][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.4239(1.5888) Grad: 11.8228  LR: 0.004990  \n",
      "Epoch: [198][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.3205(1.5047) Grad: 9.4932  LR: 0.004990  \n",
      "Epoch: [198][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.3387(1.4703) Grad: 13.3947  LR: 0.004990  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2337(1.2337) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 198 - avg_train_loss: 1.4703  avg_val_loss: 1.2195  time: 41s\n",
      "Epoch 198 - MAE Score (without expiratory phase): 0.4810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1785(1.2195) \n",
      "Epoch: [199][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.3462(1.3462) Grad: 9.6686  LR: 0.005005  \n",
      "Epoch: [199][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3522(1.3625) Grad: 11.5415  LR: 0.005005  \n",
      "Epoch: [199][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.4656(1.3521) Grad: 15.5433  LR: 0.005005  \n",
      "Epoch: [199][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.3147(1.3683) Grad: 7.6979  LR: 0.005005  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.2430(1.2430) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199 - avg_train_loss: 1.3683  avg_val_loss: 1.1933  time: 41s\n",
      "Epoch 199 - MAE Score (without expiratory phase): 0.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1595(1.1933) \n",
      "Epoch: [200][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.2531(1.2531) Grad: 3.6977  LR: 0.005010  \n",
      "Epoch: [200][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.2253(1.2803) Grad: 6.0702  LR: 0.005010  \n",
      "Epoch: [200][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2424(1.2974) Grad: 7.9508  LR: 0.005010  \n",
      "Epoch: [200][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2512(1.2996) Grad: 11.0781  LR: 0.005010  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.1946(1.1946) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200 - avg_train_loss: 1.2996  avg_val_loss: 1.1712  time: 41s\n",
      "Epoch 200 - MAE Score (without expiratory phase): 0.4587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1402(1.1712) \n",
      "Epoch: [201][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.1993(1.1993) Grad: 4.7574  LR: 0.005005  \n",
      "Epoch: [201][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 2.1122(1.4506) Grad: 39.6851  LR: 0.005005  \n",
      "Epoch: [201][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.6695(1.5318) Grad: 26.0431  LR: 0.005005  \n",
      "Epoch: [201][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.2793(1.5210) Grad: 4.1637  LR: 0.005005  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.4895(1.4895) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 201 - avg_train_loss: 1.5210  avg_val_loss: 1.4475  time: 41s\n",
      "Epoch 201 - MAE Score (without expiratory phase): 0.5823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.4166(1.4475) \n",
      "Epoch: [202][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 1.4546(1.4546) Grad: 19.0413  LR: 0.004990  \n",
      "Epoch: [202][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2869(1.2812) Grad: 10.6064  LR: 0.004990  \n",
      "Epoch: [202][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2253(1.2718) Grad: 6.0128  LR: 0.004990  \n",
      "Epoch: [202][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.2761(1.2599) Grad: 8.3480  LR: 0.004990  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.1780(1.1780) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 202 - avg_train_loss: 1.2599  avg_val_loss: 1.1433  time: 41s\n",
      "Epoch 202 - MAE Score (without expiratory phase): 0.4454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1200(1.1433) \n",
      "Epoch: [203][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.2276(1.2276) Grad: 9.9970  LR: 0.004966  \n",
      "Epoch: [203][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1465(1.1852) Grad: 4.9997  LR: 0.004966  \n",
      "Epoch: [203][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2510(1.1940) Grad: 4.4219  LR: 0.004966  \n",
      "Epoch: [203][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.2702(1.1928) Grad: 14.8978  LR: 0.004966  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1000(1.1000) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 203 - avg_train_loss: 1.1928  avg_val_loss: 1.0644  time: 41s\n",
      "Epoch 203 - MAE Score (without expiratory phase): 0.4095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0328(1.0644) \n",
      "Epoch: [204][0/58] Elapsed 0m 2s (remain 2m 28s) Loss: 1.1778(1.1778) Grad: 5.3480  LR: 0.004931  \n",
      "Epoch: [204][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1468(1.1639) Grad: 6.0753  LR: 0.004931  \n",
      "Epoch: [204][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2437(1.2175) Grad: 5.1954  LR: 0.004931  \n",
      "Epoch: [204][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.5661(1.2634) Grad: 24.2324  LR: 0.004931  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.2744(1.2744) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 204 - avg_train_loss: 1.2634  avg_val_loss: 1.2609  time: 41s\n",
      "Epoch 204 - MAE Score (without expiratory phase): 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2157(1.2609) \n",
      "Epoch: [205][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.3028(1.3028) Grad: 17.2866  LR: 0.004887  \n",
      "Epoch: [205][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.3133(1.3536) Grad: 23.8777  LR: 0.004887  \n",
      "Epoch: [205][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2586(1.3659) Grad: 11.0693  LR: 0.004887  \n",
      "Epoch: [205][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2602(1.3300) Grad: 7.7715  LR: 0.004887  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1443(1.1443) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 205 - avg_train_loss: 1.3300  avg_val_loss: 1.0882  time: 41s\n",
      "Epoch 205 - MAE Score (without expiratory phase): 0.4213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0531(1.0882) \n",
      "Epoch: [206][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 1.1669(1.1669) Grad: 3.4533  LR: 0.004834  \n",
      "Epoch: [206][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1772(1.1565) Grad: 6.5550  LR: 0.004834  \n",
      "Epoch: [206][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1499(1.1511) Grad: 5.9904  LR: 0.004834  \n",
      "Epoch: [206][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1996(1.1621) Grad: 3.2858  LR: 0.004834  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0822(1.0822) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 206 - avg_train_loss: 1.1621  avg_val_loss: 1.0517  time: 41s\n",
      "Epoch 206 - MAE Score (without expiratory phase): 0.4026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0302(1.0517) \n",
      "Epoch: [207][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.1514(1.1514) Grad: 5.9952  LR: 0.004772  \n",
      "Epoch: [207][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2144(1.1941) Grad: 6.5746  LR: 0.004772  \n",
      "Epoch: [207][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.1894(1.2131) Grad: 4.5873  LR: 0.004772  \n",
      "Epoch: [207][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1696(1.2374) Grad: 5.6605  LR: 0.004772  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.4520(1.4520) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 207 - avg_train_loss: 1.2374  avg_val_loss: 1.4281  time: 41s\n",
      "Epoch 207 - MAE Score (without expiratory phase): 0.5754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3332(1.4281) \n",
      "Epoch: [208][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.5219(1.5219) Grad: 24.3811  LR: 0.004701  \n",
      "Epoch: [208][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.6402(1.2954) Grad: 35.1218  LR: 0.004701  \n",
      "Epoch: [208][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1660(1.3290) Grad: 5.9773  LR: 0.004701  \n",
      "Epoch: [208][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1873(1.2936) Grad: 6.7659  LR: 0.004701  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.1665(1.1665) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 208 - avg_train_loss: 1.2936  avg_val_loss: 1.1375  time: 40s\n",
      "Epoch 208 - MAE Score (without expiratory phase): 0.4445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0691(1.1375) \n",
      "Epoch: [209][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.1821(1.1821) Grad: 14.1887  LR: 0.004621  \n",
      "Epoch: [209][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.2024(1.1799) Grad: 7.6644  LR: 0.004621  \n",
      "Epoch: [209][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2289(1.2233) Grad: 16.2799  LR: 0.004621  \n",
      "Epoch: [209][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1926(1.2126) Grad: 8.2364  LR: 0.004621  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.0713(1.0713) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209 - avg_train_loss: 1.2126  avg_val_loss: 1.0400  time: 41s\n",
      "Epoch 209 - MAE Score (without expiratory phase): 0.3978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9999(1.0400) \n",
      "Epoch: [210][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 1.0943(1.0943) Grad: 5.1254  LR: 0.004532  \n",
      "Epoch: [210][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1609(1.1378) Grad: 9.1364  LR: 0.004532  \n",
      "Epoch: [210][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2548(1.1667) Grad: 18.4568  LR: 0.004532  \n",
      "Epoch: [210][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1868(1.1782) Grad: 11.1230  LR: 0.004532  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2200(1.2200) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 210 - avg_train_loss: 1.1782  avg_val_loss: 1.1804  time: 42s\n",
      "Epoch 210 - MAE Score (without expiratory phase): 0.4679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.1334(1.1804) \n",
      "Epoch: [211][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.2472(1.2472) Grad: 14.3184  LR: 0.004436  \n",
      "Epoch: [211][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3933(1.2814) Grad: 26.3989  LR: 0.004436  \n",
      "Epoch: [211][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1924(1.2426) Grad: 8.2357  LR: 0.004436  \n",
      "Epoch: [211][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1788(1.2191) Grad: 11.0914  LR: 0.004436  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0386(1.0386) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 211 - avg_train_loss: 1.2191  avg_val_loss: 1.0227  time: 41s\n",
      "Epoch 211 - MAE Score (without expiratory phase): 0.3917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9806(1.0227) \n",
      "Epoch: [212][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.0788(1.0788) Grad: 3.8041  LR: 0.004332  \n",
      "Epoch: [212][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2805(1.1969) Grad: 19.0648  LR: 0.004332  \n",
      "Epoch: [212][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.2227(1.2228) Grad: 13.2202  LR: 0.004332  \n",
      "Epoch: [212][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1283(1.1902) Grad: 7.9396  LR: 0.004332  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0778(1.0778) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 212 - avg_train_loss: 1.1902  avg_val_loss: 1.0418  time: 41s\n",
      "Epoch 212 - MAE Score (without expiratory phase): 0.4011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9920(1.0418) \n",
      "Epoch: [213][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.0491(1.0491) Grad: 2.8931  LR: 0.004221  \n",
      "Epoch: [213][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0853(1.1032) Grad: 5.6182  LR: 0.004221  \n",
      "Epoch: [213][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0087(1.0871) Grad: 2.6428  LR: 0.004221  \n",
      "Epoch: [213][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0750(1.0918) Grad: 4.8992  LR: 0.004221  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0275(1.0275) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 213 - avg_train_loss: 1.0918  avg_val_loss: 0.9990  time: 40s\n",
      "Epoch 213 - MAE Score (without expiratory phase): 0.3807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9544(0.9990) \n",
      "Epoch: [214][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.0510(1.0510) Grad: 3.2626  LR: 0.004103  \n",
      "Epoch: [214][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2307(1.2554) Grad: 11.8720  LR: 0.004103  \n",
      "Epoch: [214][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1405(1.2118) Grad: 8.2186  LR: 0.004103  \n",
      "Epoch: [214][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1033(1.1845) Grad: 4.2814  LR: 0.004103  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0633(1.0633) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 214 - avg_train_loss: 1.1845  avg_val_loss: 1.0214  time: 40s\n",
      "Epoch 214 - MAE Score (without expiratory phase): 0.3925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9649(1.0214) \n",
      "Epoch: [215][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.0686(1.0686) Grad: 4.4421  LR: 0.003979  \n",
      "Epoch: [215][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.1045(1.1203) Grad: 5.1106  LR: 0.003979  \n",
      "Epoch: [215][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.3234(1.1407) Grad: 27.2005  LR: 0.003979  \n",
      "Epoch: [215][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1752(1.1578) Grad: 12.9353  LR: 0.003979  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0887(1.0887) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 215 - avg_train_loss: 1.1578  avg_val_loss: 1.0574  time: 41s\n",
      "Epoch 215 - MAE Score (without expiratory phase): 0.4076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0230(1.0574) \n",
      "Epoch: [216][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.1305(1.1305) Grad: 5.2687  LR: 0.003849  \n",
      "Epoch: [216][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2481(1.1402) Grad: 22.9304  LR: 0.003849  \n",
      "Epoch: [216][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.1533(1.1620) Grad: 11.2850  LR: 0.003849  \n",
      "Epoch: [216][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1339(1.1535) Grad: 8.0428  LR: 0.003849  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.1287(1.1287) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 216 - avg_train_loss: 1.1535  avg_val_loss: 1.1318  time: 40s\n",
      "Epoch 216 - MAE Score (without expiratory phase): 0.4390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0563(1.1318) \n",
      "Epoch: [217][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.1650(1.1650) Grad: 8.1902  LR: 0.003714  \n",
      "Epoch: [217][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0799(1.0885) Grad: 5.8456  LR: 0.003714  \n",
      "Epoch: [217][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0706(1.0814) Grad: 4.3976  LR: 0.003714  \n",
      "Epoch: [217][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0254(1.0839) Grad: 5.5224  LR: 0.003714  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0138(1.0138) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 217 - avg_train_loss: 1.0839  avg_val_loss: 0.9815  time: 40s\n",
      "Epoch 217 - MAE Score (without expiratory phase): 0.3740\n",
      "Epoch 217 - Save Best Score: 0.3740 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9308(0.9815) \n",
      "Epoch: [218][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.0612(1.0612) Grad: 8.6824  LR: 0.003574  \n",
      "Epoch: [218][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0313(1.0599) Grad: 4.2371  LR: 0.003574  \n",
      "Epoch: [218][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1524(1.0809) Grad: 10.1217  LR: 0.003574  \n",
      "Epoch: [218][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1623(1.0889) Grad: 7.7148  LR: 0.003574  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0824(1.0824) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 218 - avg_train_loss: 1.0889  avg_val_loss: 1.0549  time: 41s\n",
      "Epoch 218 - MAE Score (without expiratory phase): 0.4070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9954(1.0549) \n",
      "Epoch: [219][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 1.1150(1.1150) Grad: 11.0221  LR: 0.003430  \n",
      "Epoch: [219][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0691(1.0806) Grad: 10.9383  LR: 0.003430  \n",
      "Epoch: [219][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1259(1.0988) Grad: 8.8515  LR: 0.003430  \n",
      "Epoch: [219][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0544(1.0929) Grad: 4.3850  LR: 0.003430  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0107(1.0107) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219 - avg_train_loss: 1.0929  avg_val_loss: 0.9797  time: 41s\n",
      "Epoch 219 - MAE Score (without expiratory phase): 0.3715\n",
      "Epoch 219 - Save Best Score: 0.3715 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9569(0.9797) \n",
      "Epoch: [220][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.0393(1.0393) Grad: 4.6699  LR: 0.003282  \n",
      "Epoch: [220][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1327(1.0846) Grad: 6.5946  LR: 0.003282  \n",
      "Epoch: [220][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0872(1.1062) Grad: 11.7432  LR: 0.003282  \n",
      "Epoch: [220][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1182(1.1111) Grad: 4.5580  LR: 0.003282  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0618(1.0618) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 220 - avg_train_loss: 1.1111  avg_val_loss: 0.9988  time: 41s\n",
      "Epoch 220 - MAE Score (without expiratory phase): 0.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9561(0.9988) \n",
      "Epoch: [221][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.0650(1.0650) Grad: 4.1577  LR: 0.003132  \n",
      "Epoch: [221][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0380(1.0613) Grad: 5.4680  LR: 0.003132  \n",
      "Epoch: [221][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0303(1.0642) Grad: 4.9928  LR: 0.003132  \n",
      "Epoch: [221][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9913(1.0529) Grad: 3.7019  LR: 0.003132  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0025(1.0025) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 221 - avg_train_loss: 1.0529  avg_val_loss: 0.9756  time: 41s\n",
      "Epoch 221 - MAE Score (without expiratory phase): 0.3714\n",
      "Epoch 221 - Save Best Score: 0.3714 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9195(0.9756) \n",
      "Epoch: [222][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.0477(1.0477) Grad: 5.2284  LR: 0.002978  \n",
      "Epoch: [222][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9938(1.0521) Grad: 3.2697  LR: 0.002978  \n",
      "Epoch: [222][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0301(1.0482) Grad: 7.4533  LR: 0.002978  \n",
      "Epoch: [222][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0471(1.0492) Grad: 7.0721  LR: 0.002978  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0545(1.0545) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 222 - avg_train_loss: 1.0492  avg_val_loss: 1.0266  time: 41s\n",
      "Epoch 222 - MAE Score (without expiratory phase): 0.3939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9703(1.0266) \n",
      "Epoch: [223][0/58] Elapsed 0m 2s (remain 2m 43s) Loss: 1.0900(1.0900) Grad: 11.6926  LR: 0.002823  \n",
      "Epoch: [223][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9976(1.0331) Grad: 6.0425  LR: 0.002823  \n",
      "Epoch: [223][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0307(1.0259) Grad: 7.0911  LR: 0.002823  \n",
      "Epoch: [223][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0432(1.0280) Grad: 4.7173  LR: 0.002823  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.9915(0.9915) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 223 - avg_train_loss: 1.0280  avg_val_loss: 0.9819  time: 41s\n",
      "Epoch 223 - MAE Score (without expiratory phase): 0.3743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9334(0.9819) \n",
      "Epoch: [224][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.0937(1.0937) Grad: 6.8159  LR: 0.002667  \n",
      "Epoch: [224][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0643(1.0558) Grad: 7.3835  LR: 0.002667  \n",
      "Epoch: [224][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0144(1.0649) Grad: 6.0842  LR: 0.002667  \n",
      "Epoch: [224][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0194(1.0532) Grad: 4.4449  LR: 0.002667  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0040(1.0040) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 224 - avg_train_loss: 1.0532  avg_val_loss: 0.9696  time: 41s\n",
      "Epoch 224 - MAE Score (without expiratory phase): 0.3683\n",
      "Epoch 224 - Save Best Score: 0.3683 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9274(0.9696) \n",
      "Epoch: [225][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.0327(1.0327) Grad: 8.1556  LR: 0.002510  \n",
      "Epoch: [225][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0211(1.0165) Grad: 3.2742  LR: 0.002510  \n",
      "Epoch: [225][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9820(1.0225) Grad: 7.1686  LR: 0.002510  \n",
      "Epoch: [225][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0396(1.0235) Grad: 5.8100  LR: 0.002510  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.9794(0.9794) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 225 - avg_train_loss: 1.0235  avg_val_loss: 0.9609  time: 41s\n",
      "Epoch 225 - MAE Score (without expiratory phase): 0.3647\n",
      "Epoch 225 - Save Best Score: 0.3647 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9138(0.9609) \n",
      "Epoch: [226][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 0.9606(0.9606) Grad: 5.3375  LR: 0.002353  \n",
      "Epoch: [226][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0507(1.0316) Grad: 6.6660  LR: 0.002353  \n",
      "Epoch: [226][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9740(1.0213) Grad: 2.2840  LR: 0.002353  \n",
      "Epoch: [226][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0199(1.0195) Grad: 5.8415  LR: 0.002353  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 0.9401(0.9401) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 226 - avg_train_loss: 1.0195  avg_val_loss: 0.9344  time: 41s\n",
      "Epoch 226 - MAE Score (without expiratory phase): 0.3513\n",
      "Epoch 226 - Save Best Score: 0.3513 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8704(0.9344) \n",
      "Epoch: [227][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 0.9619(0.9619) Grad: 3.2564  LR: 0.002196  \n",
      "Epoch: [227][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9857(0.9915) Grad: 4.7218  LR: 0.002196  \n",
      "Epoch: [227][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9914(0.9909) Grad: 4.1629  LR: 0.002196  \n",
      "Epoch: [227][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9738(0.9908) Grad: 3.8361  LR: 0.002196  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9485(0.9485) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 227 - avg_train_loss: 0.9908  avg_val_loss: 0.9196  time: 41s\n",
      "Epoch 227 - MAE Score (without expiratory phase): 0.3453\n",
      "Epoch 227 - Save Best Score: 0.3453 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9024(0.9196) \n",
      "Epoch: [228][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.0129(1.0129) Grad: 8.9364  LR: 0.002041  \n",
      "Epoch: [228][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 0.9642(0.9918) Grad: 6.4471  LR: 0.002041  \n",
      "Epoch: [228][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9840(0.9988) Grad: 6.0597  LR: 0.002041  \n",
      "Epoch: [228][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9710(1.0074) Grad: 4.2200  LR: 0.002041  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.0089(1.0089) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 228 - avg_train_loss: 1.0074  avg_val_loss: 0.9785  time: 41s\n",
      "Epoch 228 - MAE Score (without expiratory phase): 0.3730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9222(0.9785) \n",
      "Epoch: [229][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 0.9948(0.9948) Grad: 9.4581  LR: 0.001888  \n",
      "Epoch: [229][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9459(0.9958) Grad: 3.5036  LR: 0.001888  \n",
      "Epoch: [229][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9862(0.9947) Grad: 8.4350  LR: 0.001888  \n",
      "Epoch: [229][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0322(1.0049) Grad: 7.8297  LR: 0.001888  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.0240(1.0240) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229 - avg_train_loss: 1.0049  avg_val_loss: 0.9847  time: 41s\n",
      "Epoch 229 - MAE Score (without expiratory phase): 0.3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9548(0.9847) \n",
      "Epoch: [230][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.0793(1.0793) Grad: 6.7547  LR: 0.001737  \n",
      "Epoch: [230][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9809(1.0255) Grad: 5.1139  LR: 0.001737  \n",
      "Epoch: [230][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9814(1.0013) Grad: 4.6414  LR: 0.001737  \n",
      "Epoch: [230][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0116(0.9957) Grad: 3.9760  LR: 0.001737  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.9350(0.9350) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 230 - avg_train_loss: 0.9957  avg_val_loss: 0.9087  time: 41s\n",
      "Epoch 230 - MAE Score (without expiratory phase): 0.3396\n",
      "Epoch 230 - Save Best Score: 0.3396 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8664(0.9087) \n",
      "Epoch: [231][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 0.9533(0.9533) Grad: 2.6777  LR: 0.001589  \n",
      "Epoch: [231][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9637(0.9737) Grad: 5.5006  LR: 0.001589  \n",
      "Epoch: [231][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9573(0.9734) Grad: 4.2934  LR: 0.001589  \n",
      "Epoch: [231][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9757(0.9809) Grad: 6.8457  LR: 0.001589  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.9076(0.9076) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 231 - avg_train_loss: 0.9809  avg_val_loss: 0.9044  time: 40s\n",
      "Epoch 231 - MAE Score (without expiratory phase): 0.3382\n",
      "Epoch 231 - Save Best Score: 0.3382 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8340(0.9044) \n",
      "Epoch: [232][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 0.9684(0.9684) Grad: 42.7359  LR: 0.001445  \n",
      "Epoch: [232][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0367(1.1427) Grad: 5.3988  LR: 0.001445  \n",
      "Epoch: [232][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9877(1.0817) Grad: 2.8639  LR: 0.001445  \n",
      "Epoch: [232][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9791(1.0558) Grad: 4.9804  LR: 0.001445  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9797(0.9797) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 232 - avg_train_loss: 1.0558  avg_val_loss: 0.9432  time: 41s\n",
      "Epoch 232 - MAE Score (without expiratory phase): 0.3566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8759(0.9432) \n",
      "Epoch: [233][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 0.9829(0.9829) Grad: 6.9461  LR: 0.001305  \n",
      "Epoch: [233][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 0.9315(0.9612) Grad: 3.1859  LR: 0.001305  \n",
      "Epoch: [233][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9578(0.9605) Grad: 4.5247  LR: 0.001305  \n",
      "Epoch: [233][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9714(0.9606) Grad: 4.8361  LR: 0.001305  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9627(0.9627) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 233 - avg_train_loss: 0.9606  avg_val_loss: 0.9303  time: 41s\n",
      "Epoch 233 - MAE Score (without expiratory phase): 0.3508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8719(0.9303) \n",
      "Epoch: [234][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 0.9609(0.9609) Grad: 6.7040  LR: 0.001170  \n",
      "Epoch: [234][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9424(0.9499) Grad: 4.7944  LR: 0.001170  \n",
      "Epoch: [234][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9435(0.9480) Grad: 4.0723  LR: 0.001170  \n",
      "Epoch: [234][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9441(0.9550) Grad: 6.6754  LR: 0.001170  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 0.9182(0.9182) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 234 - avg_train_loss: 0.9550  avg_val_loss: 0.8986  time: 41s\n",
      "Epoch 234 - MAE Score (without expiratory phase): 0.3360\n",
      "Epoch 234 - Save Best Score: 0.3360 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8352(0.8986) \n",
      "Epoch: [235][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 0.9581(0.9581) Grad: 5.1528  LR: 0.001040  \n",
      "Epoch: [235][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9590(0.9448) Grad: 5.3240  LR: 0.001040  \n",
      "Epoch: [235][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9372(0.9479) Grad: 6.4066  LR: 0.001040  \n",
      "Epoch: [235][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9341(0.9493) Grad: 3.1426  LR: 0.001040  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.9309(0.9309) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 235 - avg_train_loss: 0.9493  avg_val_loss: 0.9005  time: 41s\n",
      "Epoch 235 - MAE Score (without expiratory phase): 0.3365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8516(0.9005) \n",
      "Epoch: [236][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 0.9359(0.9359) Grad: 9.6698  LR: 0.000916  \n",
      "Epoch: [236][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9245(0.9556) Grad: 3.9611  LR: 0.000916  \n",
      "Epoch: [236][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9467(0.9535) Grad: 7.1721  LR: 0.000916  \n",
      "Epoch: [236][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9909(0.9480) Grad: 3.0346  LR: 0.000916  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.9032(0.9032) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 236 - avg_train_loss: 0.9480  avg_val_loss: 0.8757  time: 41s\n",
      "Epoch 236 - MAE Score (without expiratory phase): 0.3254\n",
      "Epoch 236 - Save Best Score: 0.3254 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8150(0.8757) \n",
      "Epoch: [237][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 0.9217(0.9217) Grad: 5.0460  LR: 0.000798  \n",
      "Epoch: [237][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8968(0.9275) Grad: 1.7782  LR: 0.000798  \n",
      "Epoch: [237][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9596(0.9342) Grad: 5.0029  LR: 0.000798  \n",
      "Epoch: [237][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9513(0.9472) Grad: 4.0113  LR: 0.000798  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9241(0.9241) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 237 - avg_train_loss: 0.9472  avg_val_loss: 0.9041  time: 41s\n",
      "Epoch 237 - MAE Score (without expiratory phase): 0.3385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8588(0.9041) \n",
      "Epoch: [238][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 0.9534(0.9534) Grad: 3.5037  LR: 0.000687  \n",
      "Epoch: [238][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9515(0.9529) Grad: 4.4339  LR: 0.000687  \n",
      "Epoch: [238][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9334(0.9550) Grad: 2.5927  LR: 0.000687  \n",
      "Epoch: [238][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9384(0.9515) Grad: 3.7898  LR: 0.000687  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.9240(0.9240) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 238 - avg_train_loss: 0.9515  avg_val_loss: 0.8813  time: 40s\n",
      "Epoch 238 - MAE Score (without expiratory phase): 0.3279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8542(0.8813) \n",
      "Epoch: [239][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 0.9339(0.9339) Grad: 1.7439  LR: 0.000583  \n",
      "Epoch: [239][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9339(0.9340) Grad: 4.6618  LR: 0.000583  \n",
      "Epoch: [239][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9026(0.9305) Grad: 1.4088  LR: 0.000583  \n",
      "Epoch: [239][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9255(0.9289) Grad: 1.4768  LR: 0.000583  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9102(0.9102) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239 - avg_train_loss: 0.9289  avg_val_loss: 0.8699  time: 41s\n",
      "Epoch 239 - MAE Score (without expiratory phase): 0.3225\n",
      "Epoch 239 - Save Best Score: 0.3225 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8220(0.8699) \n",
      "Epoch: [240][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 0.9380(0.9380) Grad: 3.0116  LR: 0.000487  \n",
      "Epoch: [240][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8777(0.9206) Grad: 4.7621  LR: 0.000487  \n",
      "Epoch: [240][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8986(0.9224) Grad: 3.8151  LR: 0.000487  \n",
      "Epoch: [240][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9371(0.9230) Grad: 5.0467  LR: 0.000487  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.8827(0.8827) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 240 - avg_train_loss: 0.9230  avg_val_loss: 0.8608  time: 41s\n",
      "Epoch 240 - MAE Score (without expiratory phase): 0.3183\n",
      "Epoch 240 - Save Best Score: 0.3183 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8097(0.8608) \n",
      "Epoch: [241][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 0.9491(0.9491) Grad: 6.3575  LR: 0.000398  \n",
      "Epoch: [241][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9008(0.9185) Grad: 1.9422  LR: 0.000398  \n",
      "Epoch: [241][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8854(0.9166) Grad: 1.6315  LR: 0.000398  \n",
      "Epoch: [241][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9200(0.9141) Grad: 1.5279  LR: 0.000398  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 0.8878(0.8878) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 241 - avg_train_loss: 0.9141  avg_val_loss: 0.8577  time: 41s\n",
      "Epoch 241 - MAE Score (without expiratory phase): 0.3167\n",
      "Epoch 241 - Save Best Score: 0.3167 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8059(0.8577) \n",
      "Epoch: [242][0/58] Elapsed 0m 3s (remain 2m 53s) Loss: 0.8879(0.8879) Grad: 2.4041  LR: 0.000318  \n",
      "Epoch: [242][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8963(0.9078) Grad: 0.9617  LR: 0.000318  \n",
      "Epoch: [242][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9620(0.9132) Grad: 4.5436  LR: 0.000318  \n",
      "Epoch: [242][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9183(0.9237) Grad: 2.0986  LR: 0.000318  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.8830(0.8830) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 242 - avg_train_loss: 0.9237  avg_val_loss: 0.8639  time: 41s\n",
      "Epoch 242 - MAE Score (without expiratory phase): 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 0.8168(0.8639) \n",
      "Epoch: [243][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 0.9290(0.9290) Grad: 1.9408  LR: 0.000247  \n",
      "Epoch: [243][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9089(0.9075) Grad: 2.6579  LR: 0.000247  \n",
      "Epoch: [243][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8969(0.9118) Grad: 3.7607  LR: 0.000247  \n",
      "Epoch: [243][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9153(0.9106) Grad: 1.9630  LR: 0.000247  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 38s) Loss: 0.8818(0.8818) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 243 - avg_train_loss: 0.9106  avg_val_loss: 0.8533  time: 41s\n",
      "Epoch 243 - MAE Score (without expiratory phase): 0.3148\n",
      "Epoch 243 - Save Best Score: 0.3148 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8048(0.8533) \n",
      "Epoch: [244][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 0.9183(0.9183) Grad: 3.2972  LR: 0.000184  \n",
      "Epoch: [244][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.8983(0.9028) Grad: 2.3459  LR: 0.000184  \n",
      "Epoch: [244][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9268(0.9047) Grad: 2.3365  LR: 0.000184  \n",
      "Epoch: [244][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.8880(0.9039) Grad: 2.0845  LR: 0.000184  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8752(0.8752) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 244 - avg_train_loss: 0.9039  avg_val_loss: 0.8508  time: 41s\n",
      "Epoch 244 - MAE Score (without expiratory phase): 0.3135\n",
      "Epoch 244 - Save Best Score: 0.3135 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8082(0.8508) \n",
      "Epoch: [245][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 0.8860(0.8860) Grad: 2.3534  LR: 0.000131  \n",
      "Epoch: [245][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9087(0.8940) Grad: 1.2011  LR: 0.000131  \n",
      "Epoch: [245][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9174(0.8988) Grad: 2.8143  LR: 0.000131  \n",
      "Epoch: [245][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9281(0.9008) Grad: 1.3041  LR: 0.000131  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8752(0.8752) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 245 - avg_train_loss: 0.9008  avg_val_loss: 0.8473  time: 40s\n",
      "Epoch 245 - MAE Score (without expiratory phase): 0.3120\n",
      "Epoch 245 - Save Best Score: 0.3120 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8057(0.8473) \n",
      "Epoch: [246][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 0.8838(0.8838) Grad: 2.1312  LR: 0.000086  \n",
      "Epoch: [246][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9152(0.9028) Grad: 2.3641  LR: 0.000086  \n",
      "Epoch: [246][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9115(0.9006) Grad: 1.5391  LR: 0.000086  \n",
      "Epoch: [246][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.8790(0.9000) Grad: 3.0717  LR: 0.000086  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8739(0.8739) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 246 - avg_train_loss: 0.9000  avg_val_loss: 0.8486  time: 41s\n",
      "Epoch 246 - MAE Score (without expiratory phase): 0.3126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 0.8070(0.8486) \n",
      "Epoch: [247][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 0.9250(0.9250) Grad: 5.5960  LR: 0.000051  \n",
      "Epoch: [247][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8887(0.9017) Grad: 1.5458  LR: 0.000051  \n",
      "Epoch: [247][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8714(0.8975) Grad: 2.4922  LR: 0.000051  \n",
      "Epoch: [247][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.8910(0.8994) Grad: 2.5010  LR: 0.000051  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8807(0.8807) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 247 - avg_train_loss: 0.8994  avg_val_loss: 0.8536  time: 41s\n",
      "Epoch 247 - MAE Score (without expiratory phase): 0.3150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8083(0.8536) \n",
      "Epoch: [248][0/58] Elapsed 0m 2s (remain 2m 46s) Loss: 0.8768(0.8768) Grad: 2.7393  LR: 0.000026  \n",
      "Epoch: [248][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9142(0.8962) Grad: 1.8177  LR: 0.000026  \n",
      "Epoch: [248][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8977(0.9010) Grad: 1.6529  LR: 0.000026  \n",
      "Epoch: [248][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.8833(0.8973) Grad: 1.2026  LR: 0.000026  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8751(0.8751) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 248 - avg_train_loss: 0.8973  avg_val_loss: 0.8457  time: 40s\n",
      "Epoch 248 - MAE Score (without expiratory phase): 0.3112\n",
      "Epoch 248 - Save Best Score: 0.3112 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8016(0.8457) \n",
      "Epoch: [249][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 0.9073(0.9073) Grad: 1.4282  LR: 0.000010  \n",
      "Epoch: [249][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8942(0.8984) Grad: 1.4180  LR: 0.000010  \n",
      "Epoch: [249][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8931(0.8966) Grad: 1.9778  LR: 0.000010  \n",
      "Epoch: [249][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.8928(0.8954) Grad: 1.8655  LR: 0.000010  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8747(0.8747) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249 - avg_train_loss: 0.8954  avg_val_loss: 0.8457  time: 40s\n",
      "Epoch 249 - MAE Score (without expiratory phase): 0.3112\n",
      "Epoch 249 - Save Best Score: 0.3112 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8019(0.8457) \n",
      "Epoch: [250][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 0.8882(0.8882) Grad: 2.9631  LR: 0.000002  \n",
      "Epoch: [250][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9281(0.8993) Grad: 1.3193  LR: 0.000002  \n",
      "Epoch: [250][40/58] Elapsed 0m 24s (remain 0m 9s) Loss: 0.8816(0.8947) Grad: 1.0891  LR: 0.000002  \n",
      "Epoch: [250][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.8895(0.8948) Grad: 1.8819  LR: 0.000002  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8749(0.8749) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 250 - avg_train_loss: 0.8948  avg_val_loss: 0.8465  time: 42s\n",
      "Epoch 250 - MAE Score (without expiratory phase): 0.3116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8024(0.8465) \n",
      "Epoch: [251][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 0.9166(0.9166) Grad: 1.1444  LR: 0.000001  \n",
      "Epoch: [251][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8960(0.8994) Grad: 1.6353  LR: 0.000001  \n",
      "Epoch: [251][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8599(0.8929) Grad: 9.2503  LR: 0.000001  \n",
      "Epoch: [251][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.8876(0.8942) Grad: 1.4049  LR: 0.000001  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.8749(0.8749) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 251 - avg_train_loss: 0.8942  avg_val_loss: 0.8462  time: 41s\n",
      "Epoch 251 - MAE Score (without expiratory phase): 0.3115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8024(0.8462) \n",
      "Epoch: [252][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 0.8789(0.8789) Grad: 2.0816  LR: 0.000011  \n",
      "Epoch: [252][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8925(0.8939) Grad: 1.6892  LR: 0.000011  \n",
      "Epoch: [252][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8869(0.8956) Grad: 2.3333  LR: 0.000011  \n",
      "Epoch: [252][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9096(0.8936) Grad: 1.3764  LR: 0.000011  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.8760(0.8760) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 252 - avg_train_loss: 0.8936  avg_val_loss: 0.8466  time: 41s\n",
      "Epoch 252 - MAE Score (without expiratory phase): 0.3117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8019(0.8466) \n",
      "Epoch: [253][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 0.8960(0.8960) Grad: 2.1686  LR: 0.000080  \n",
      "Epoch: [253][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.8979(0.8894) Grad: 4.1924  LR: 0.000080  \n",
      "Epoch: [253][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9023(0.8904) Grad: 2.2444  LR: 0.000080  \n",
      "Epoch: [253][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9011(0.8925) Grad: 1.7506  LR: 0.000080  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.8754(0.8754) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 253 - avg_train_loss: 0.8925  avg_val_loss: 0.8464  time: 40s\n",
      "Epoch 253 - MAE Score (without expiratory phase): 0.3116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8028(0.8464) \n",
      "Epoch: [254][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 0.8925(0.8925) Grad: 1.5191  LR: 0.000100  \n",
      "Epoch: [254][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9089(0.9024) Grad: 1.8804  LR: 0.000100  \n",
      "Epoch: [254][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8852(0.8969) Grad: 2.1369  LR: 0.000100  \n",
      "Epoch: [254][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.8755(0.8958) Grad: 3.0604  LR: 0.000100  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.8715(0.8715) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 254 - avg_train_loss: 0.8958  avg_val_loss: 0.8430  time: 41s\n",
      "Epoch 254 - MAE Score (without expiratory phase): 0.3100\n",
      "Epoch 254 - Save Best Score: 0.3100 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.7961(0.8430) \n",
      "Epoch: [255][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 0.8928(0.8928) Grad: 1.1949  LR: 0.000140  \n",
      "Epoch: [255][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8852(0.8990) Grad: 3.8844  LR: 0.000140  \n",
      "Epoch: [255][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9032(0.8942) Grad: 2.4754  LR: 0.000140  \n",
      "Epoch: [255][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9257(0.8944) Grad: 5.2067  LR: 0.000140  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.8779(0.8779) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 255 - avg_train_loss: 0.8944  avg_val_loss: 0.8478  time: 41s\n",
      "Epoch 255 - MAE Score (without expiratory phase): 0.3123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8004(0.8478) \n",
      "Epoch: [256][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 0.8803(0.8803) Grad: 1.5667  LR: 0.000192  \n",
      "Epoch: [256][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9131(0.8970) Grad: 3.5878  LR: 0.000192  \n",
      "Epoch: [256][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8984(0.8982) Grad: 2.2910  LR: 0.000192  \n",
      "Epoch: [256][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.8683(0.8989) Grad: 1.4761  LR: 0.000192  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 38s) Loss: 0.8643(0.8643) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 256 - avg_train_loss: 0.8989  avg_val_loss: 0.8415  time: 41s\n",
      "Epoch 256 - MAE Score (without expiratory phase): 0.3092\n",
      "Epoch 256 - Save Best Score: 0.3092 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.7985(0.8415) \n",
      "Epoch: [257][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 0.8634(0.8634) Grad: 1.5409  LR: 0.000253  \n",
      "Epoch: [257][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9028(0.8936) Grad: 2.7620  LR: 0.000253  \n",
      "Epoch: [257][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.8919(0.8949) Grad: 2.2273  LR: 0.000253  \n",
      "Epoch: [257][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9260(0.8968) Grad: 1.7776  LR: 0.000253  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8683(0.8683) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 257 - avg_train_loss: 0.8968  avg_val_loss: 0.8465  time: 41s\n",
      "Epoch 257 - MAE Score (without expiratory phase): 0.3116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.7963(0.8465) \n",
      "Epoch: [258][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 0.8926(0.8926) Grad: 6.3363  LR: 0.000323  \n",
      "Epoch: [258][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8803(0.8927) Grad: 3.4261  LR: 0.000323  \n",
      "Epoch: [258][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9121(0.8979) Grad: 2.8011  LR: 0.000323  \n",
      "Epoch: [258][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9259(0.8972) Grad: 2.2475  LR: 0.000323  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8709(0.8709) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 258 - avg_train_loss: 0.8972  avg_val_loss: 0.8463  time: 41s\n",
      "Epoch 258 - MAE Score (without expiratory phase): 0.3116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.7956(0.8463) \n",
      "Epoch: [259][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 0.8902(0.8902) Grad: 2.0144  LR: 0.000403  \n",
      "Epoch: [259][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.8828(0.9001) Grad: 3.9723  LR: 0.000403  \n",
      "Epoch: [259][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9164(0.9047) Grad: 2.9284  LR: 0.000403  \n",
      "Epoch: [259][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9201(0.9044) Grad: 1.3309  LR: 0.000403  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8802(0.8802) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259 - avg_train_loss: 0.9044  avg_val_loss: 0.8571  time: 41s\n",
      "Epoch 259 - MAE Score (without expiratory phase): 0.3167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8065(0.8571) \n",
      "Epoch: [260][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 0.9083(0.9083) Grad: 3.2057  LR: 0.000491  \n",
      "Epoch: [260][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8917(0.8979) Grad: 2.1275  LR: 0.000491  \n",
      "Epoch: [260][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9154(0.9009) Grad: 2.9417  LR: 0.000491  \n",
      "Epoch: [260][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.8811(0.9017) Grad: 4.1028  LR: 0.000491  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.8553(0.8553) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 260 - avg_train_loss: 0.9017  avg_val_loss: 0.8391  time: 41s\n",
      "Epoch 260 - MAE Score (without expiratory phase): 0.3081\n",
      "Epoch 260 - Save Best Score: 0.3081 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.7912(0.8391) \n",
      "Epoch: [261][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 0.8915(0.8915) Grad: 3.6808  LR: 0.000587  \n",
      "Epoch: [261][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9110(0.9012) Grad: 4.2507  LR: 0.000587  \n",
      "Epoch: [261][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9085(0.9140) Grad: 4.2442  LR: 0.000587  \n",
      "Epoch: [261][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9569(0.9201) Grad: 8.3125  LR: 0.000587  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.8993(0.8993) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 261 - avg_train_loss: 0.9201  avg_val_loss: 0.8711  time: 41s\n",
      "Epoch 261 - MAE Score (without expiratory phase): 0.3235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8314(0.8711) \n",
      "Epoch: [262][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 0.9366(0.9366) Grad: 4.6968  LR: 0.000690  \n",
      "Epoch: [262][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.8822(0.9264) Grad: 3.0980  LR: 0.000690  \n",
      "Epoch: [262][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9122(0.9188) Grad: 2.3708  LR: 0.000690  \n",
      "Epoch: [262][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9091(0.9157) Grad: 2.2042  LR: 0.000690  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.8786(0.8786) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 262 - avg_train_loss: 0.9157  avg_val_loss: 0.8493  time: 41s\n",
      "Epoch 262 - MAE Score (without expiratory phase): 0.3131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.7991(0.8493) \n",
      "Epoch: [263][0/58] Elapsed 0m 2s (remain 2m 40s) Loss: 0.9053(0.9053) Grad: 1.8518  LR: 0.000801  \n",
      "Epoch: [263][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9829(0.9112) Grad: 7.4519  LR: 0.000801  \n",
      "Epoch: [263][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9704(0.9426) Grad: 7.1457  LR: 0.000801  \n",
      "Epoch: [263][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9261(0.9367) Grad: 2.5629  LR: 0.000801  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.9079(0.9079) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 263 - avg_train_loss: 0.9367  avg_val_loss: 0.8714  time: 41s\n",
      "Epoch 263 - MAE Score (without expiratory phase): 0.3235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8175(0.8714) \n",
      "Epoch: [264][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 0.9128(0.9128) Grad: 2.4903  LR: 0.000919  \n",
      "Epoch: [264][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.8830(0.9154) Grad: 2.6750  LR: 0.000919  \n",
      "Epoch: [264][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9303(0.9152) Grad: 1.9773  LR: 0.000919  \n",
      "Epoch: [264][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9399(0.9156) Grad: 6.4879  LR: 0.000919  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.9080(0.9080) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 264 - avg_train_loss: 0.9156  avg_val_loss: 0.8706  time: 41s\n",
      "Epoch 264 - MAE Score (without expiratory phase): 0.3224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8300(0.8706) \n",
      "Epoch: [265][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 0.9090(0.9090) Grad: 3.1473  LR: 0.001043  \n",
      "Epoch: [265][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9016(0.9150) Grad: 3.6644  LR: 0.001043  \n",
      "Epoch: [265][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9378(0.9206) Grad: 6.6334  LR: 0.001043  \n",
      "Epoch: [265][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9083(0.9168) Grad: 5.3685  LR: 0.001043  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.8971(0.8971) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 265 - avg_train_loss: 0.9168  avg_val_loss: 0.8668  time: 41s\n",
      "Epoch 265 - MAE Score (without expiratory phase): 0.3213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8104(0.8668) \n",
      "Epoch: [266][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 0.9391(0.9391) Grad: 4.6218  LR: 0.001172  \n",
      "Epoch: [266][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9579(0.9310) Grad: 11.7227  LR: 0.001172  \n",
      "Epoch: [266][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9458(0.9307) Grad: 6.1259  LR: 0.001172  \n",
      "Epoch: [266][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9192(0.9306) Grad: 7.9742  LR: 0.001172  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 0.9328(0.9328) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 266 - avg_train_loss: 0.9306  avg_val_loss: 0.9023  time: 40s\n",
      "Epoch 266 - MAE Score (without expiratory phase): 0.3378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8551(0.9023) \n",
      "Epoch: [267][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 0.9510(0.9510) Grad: 7.8186  LR: 0.001307  \n",
      "Epoch: [267][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9554(0.9466) Grad: 9.1312  LR: 0.001307  \n",
      "Epoch: [267][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9412(0.9447) Grad: 10.0996  LR: 0.001307  \n",
      "Epoch: [267][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9548(0.9455) Grad: 4.4151  LR: 0.001307  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9453(0.9453) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 267 - avg_train_loss: 0.9455  avg_val_loss: 0.9252  time: 41s\n",
      "Epoch 267 - MAE Score (without expiratory phase): 0.3486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8660(0.9252) \n",
      "Epoch: [268][0/58] Elapsed 0m 2s (remain 2m 39s) Loss: 1.0046(1.0046) Grad: 11.0957  LR: 0.001447  \n",
      "Epoch: [268][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0273(1.0070) Grad: 10.4510  LR: 0.001447  \n",
      "Epoch: [268][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9423(1.0024) Grad: 5.6343  LR: 0.001447  \n",
      "Epoch: [268][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9535(1.0065) Grad: 8.8842  LR: 0.001447  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.9843(0.9843) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 268 - avg_train_loss: 1.0065  avg_val_loss: 0.9676  time: 41s\n",
      "Epoch 268 - MAE Score (without expiratory phase): 0.3688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9389(0.9676) \n",
      "Epoch: [269][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 0.9788(0.9788) Grad: 11.0607  LR: 0.001591  \n",
      "Epoch: [269][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0665(0.9723) Grad: 12.9207  LR: 0.001591  \n",
      "Epoch: [269][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9695(1.0005) Grad: 5.2833  LR: 0.001591  \n",
      "Epoch: [269][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9252(0.9911) Grad: 4.0604  LR: 0.001591  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9228(0.9228) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269 - avg_train_loss: 0.9911  avg_val_loss: 0.8957  time: 40s\n",
      "Epoch 269 - MAE Score (without expiratory phase): 0.3349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8519(0.8957) \n",
      "Epoch: [270][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 0.9521(0.9521) Grad: 4.2220  LR: 0.001739  \n",
      "Epoch: [270][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0828(1.0660) Grad: 8.9396  LR: 0.001739  \n",
      "Epoch: [270][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0848(1.1030) Grad: 10.4251  LR: 0.001739  \n",
      "Epoch: [270][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 0.9612(1.0795) Grad: 4.9678  LR: 0.001739  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0134(1.0134) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 270 - avg_train_loss: 1.0795  avg_val_loss: 0.9802  time: 41s\n",
      "Epoch 270 - MAE Score (without expiratory phase): 0.3732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9215(0.9802) \n",
      "Epoch: [271][0/58] Elapsed 0m 2s (remain 2m 29s) Loss: 1.0455(1.0455) Grad: 9.7396  LR: 0.001890  \n",
      "Epoch: [271][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0243(1.0520) Grad: 15.5767  LR: 0.001890  \n",
      "Epoch: [271][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1072(1.0795) Grad: 11.8711  LR: 0.001890  \n",
      "Epoch: [271][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9653(1.0663) Grad: 7.0576  LR: 0.001890  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.0271(1.0271) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 271 - avg_train_loss: 1.0663  avg_val_loss: 0.9642  time: 41s\n",
      "Epoch 271 - MAE Score (without expiratory phase): 0.3638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 0.9361(0.9642) \n",
      "Epoch: [272][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.0138(1.0138) Grad: 7.9976  LR: 0.002043  \n",
      "Epoch: [272][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9932(1.0070) Grad: 4.2884  LR: 0.002043  \n",
      "Epoch: [272][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 0.9406(0.9916) Grad: 7.2398  LR: 0.002043  \n",
      "Epoch: [272][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 0.9705(0.9933) Grad: 5.2174  LR: 0.002043  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0531(1.0531) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 272 - avg_train_loss: 0.9933  avg_val_loss: 1.0250  time: 41s\n",
      "Epoch 272 - MAE Score (without expiratory phase): 0.3975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9760(1.0250) \n",
      "Epoch: [273][0/58] Elapsed 0m 2s (remain 2m 31s) Loss: 1.0217(1.0217) Grad: 16.9067  LR: 0.002198  \n",
      "Epoch: [273][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 0.9441(0.9900) Grad: 5.2668  LR: 0.002198  \n",
      "Epoch: [273][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 0.9793(0.9914) Grad: 8.5475  LR: 0.002198  \n",
      "Epoch: [273][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0186(1.0097) Grad: 5.2812  LR: 0.002198  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9797(0.9797) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 273 - avg_train_loss: 1.0097  avg_val_loss: 0.9658  time: 41s\n",
      "Epoch 273 - MAE Score (without expiratory phase): 0.3672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9230(0.9658) \n",
      "Epoch: [274][0/58] Elapsed 0m 2s (remain 2m 42s) Loss: 0.9979(0.9979) Grad: 4.7479  LR: 0.002354  \n",
      "Epoch: [274][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1271(1.0910) Grad: 12.5923  LR: 0.002354  \n",
      "Epoch: [274][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0532(1.0966) Grad: 11.0926  LR: 0.002354  \n",
      "Epoch: [274][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1680(1.0914) Grad: 14.9996  LR: 0.002354  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 0.9958(0.9958) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 274 - avg_train_loss: 1.0914  avg_val_loss: 0.9747  time: 41s\n",
      "Epoch 274 - MAE Score (without expiratory phase): 0.3693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9495(0.9747) \n",
      "Epoch: [275][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 1.0122(1.0122) Grad: 6.3465  LR: 0.002511  \n",
      "Epoch: [275][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 0.9493(1.0462) Grad: 4.5562  LR: 0.002511  \n",
      "Epoch: [275][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0239(1.0413) Grad: 8.9449  LR: 0.002511  \n",
      "Epoch: [275][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.4189(1.0548) Grad: 26.6225  LR: 0.002511  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1074(1.1074) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 275 - avg_train_loss: 1.0548  avg_val_loss: 1.0392  time: 41s\n",
      "Epoch 275 - MAE Score (without expiratory phase): 0.4013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9561(1.0392) \n",
      "Epoch: [276][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.1218(1.1218) Grad: 4.0763  LR: 0.002668  \n",
      "Epoch: [276][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0515(1.1087) Grad: 5.4910  LR: 0.002668  \n",
      "Epoch: [276][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.0584(1.0747) Grad: 11.7351  LR: 0.002668  \n",
      "Epoch: [276][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0715(1.0698) Grad: 7.6972  LR: 0.002668  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9871(0.9871) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 276 - avg_train_loss: 1.0698  avg_val_loss: 0.9650  time: 40s\n",
      "Epoch 276 - MAE Score (without expiratory phase): 0.3660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9281(0.9650) \n",
      "Epoch: [277][0/58] Elapsed 0m 2s (remain 2m 36s) Loss: 0.9891(0.9891) Grad: 5.5599  LR: 0.002824  \n",
      "Epoch: [277][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.4615(1.1923) Grad: 34.8944  LR: 0.002824  \n",
      "Epoch: [277][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1488(1.2229) Grad: 8.2955  LR: 0.002824  \n",
      "Epoch: [277][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.2569(1.2123) Grad: 11.8147  LR: 0.002824  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.2749(1.2749) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 277 - avg_train_loss: 1.2123  avg_val_loss: 1.2734  time: 41s\n",
      "Epoch 277 - MAE Score (without expiratory phase): 0.5105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2122(1.2734) \n",
      "Epoch: [278][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 1.3334(1.3334) Grad: 21.9185  LR: 0.002979  \n",
      "Epoch: [278][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1493(1.3051) Grad: 13.6148  LR: 0.002979  \n",
      "Epoch: [278][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1473(1.2663) Grad: 11.6329  LR: 0.002979  \n",
      "Epoch: [278][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0693(1.2190) Grad: 23.2651  LR: 0.002979  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 35s) Loss: 1.4400(1.4400) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 278 - avg_train_loss: 1.2190  avg_val_loss: 1.4230  time: 41s\n",
      "Epoch 278 - MAE Score (without expiratory phase): 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3668(1.4230) \n",
      "Epoch: [279][0/58] Elapsed 0m 2s (remain 2m 34s) Loss: 1.5032(1.5032) Grad: 34.5145  LR: 0.003133  \n",
      "Epoch: [279][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1155(1.1760) Grad: 9.4211  LR: 0.003133  \n",
      "Epoch: [279][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0442(1.1235) Grad: 5.9915  LR: 0.003133  \n",
      "Epoch: [279][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0387(1.1019) Grad: 7.2892  LR: 0.003133  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 0.9714(0.9714) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279 - avg_train_loss: 1.1019  avg_val_loss: 0.9355  time: 41s\n",
      "Epoch 279 - MAE Score (without expiratory phase): 0.3537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9011(0.9355) \n",
      "Epoch: [280][0/58] Elapsed 0m 2s (remain 2m 38s) Loss: 1.0098(1.0098) Grad: 5.8384  LR: 0.003283  \n",
      "Epoch: [280][20/58] Elapsed 0m 13s (remain 0m 22s) Loss: 1.0175(1.0141) Grad: 4.6752  LR: 0.003283  \n",
      "Epoch: [280][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0500(1.0120) Grad: 10.5437  LR: 0.003283  \n",
      "Epoch: [280][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0971(1.0129) Grad: 10.7253  LR: 0.003283  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.0458(1.0458) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 280 - avg_train_loss: 1.0129  avg_val_loss: 1.0186  time: 40s\n",
      "Epoch 280 - MAE Score (without expiratory phase): 0.3936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9435(1.0186) \n",
      "Epoch: [281][0/58] Elapsed 0m 2s (remain 2m 29s) Loss: 1.1164(1.1164) Grad: 19.9037  LR: 0.003431  \n",
      "Epoch: [281][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.1484(1.2525) Grad: 13.6399  LR: 0.003431  \n",
      "Epoch: [281][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.1545(1.2019) Grad: 12.5102  LR: 0.003431  \n",
      "Epoch: [281][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.0224(1.1690) Grad: 9.7687  LR: 0.003431  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.0442(1.0442) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 281 - avg_train_loss: 1.1690  avg_val_loss: 1.0072  time: 41s\n",
      "Epoch 281 - MAE Score (without expiratory phase): 0.3855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9537(1.0072) \n",
      "Epoch: [282][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.0921(1.0921) Grad: 16.9736  LR: 0.003575  \n",
      "Epoch: [282][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1017(1.1865) Grad: 11.2244  LR: 0.003575  \n",
      "Epoch: [282][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1401(1.1195) Grad: 9.0434  LR: 0.003575  \n",
      "Epoch: [282][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.0792(1.1098) Grad: 6.4405  LR: 0.003575  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.0371(1.0371) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 282 - avg_train_loss: 1.1098  avg_val_loss: 0.9985  time: 41s\n",
      "Epoch 282 - MAE Score (without expiratory phase): 0.3802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.9192(0.9985) \n",
      "Epoch: [283][0/58] Elapsed 0m 2s (remain 2m 30s) Loss: 1.0316(1.0316) Grad: 7.9626  LR: 0.003715  \n",
      "Epoch: [283][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0644(1.0787) Grad: 9.3494  LR: 0.003715  \n",
      "Epoch: [283][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.0829(1.0712) Grad: 6.4524  LR: 0.003715  \n",
      "Epoch: [283][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1297(1.0785) Grad: 10.7398  LR: 0.003715  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.0711(1.0711) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 283 - avg_train_loss: 1.0785  avg_val_loss: 1.0523  time: 41s\n",
      "Epoch 283 - MAE Score (without expiratory phase): 0.4069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0060(1.0523) \n",
      "Epoch: [284][0/58] Elapsed 0m 3s (remain 2m 58s) Loss: 1.0523(1.0523) Grad: 7.9836  LR: 0.003850  \n",
      "Epoch: [284][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.1013(1.0661) Grad: 10.8162  LR: 0.003850  \n",
      "Epoch: [284][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.4035(1.1894) Grad: 17.6348  LR: 0.003850  \n",
      "Epoch: [284][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.3804(1.2343) Grad: 22.3834  LR: 0.003850  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.3804(1.3804) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 284 - avg_train_loss: 1.2343  avg_val_loss: 1.2906  time: 41s\n",
      "Epoch 284 - MAE Score (without expiratory phase): 0.5217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.2179(1.2906) \n",
      "Epoch: [285][0/58] Elapsed 0m 2s (remain 2m 32s) Loss: 1.3190(1.3190) Grad: 15.1211  LR: 0.003980  \n",
      "Epoch: [285][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.0940(1.2418) Grad: 4.3856  LR: 0.003980  \n",
      "Epoch: [285][40/58] Elapsed 0m 22s (remain 0m 9s) Loss: 1.0360(1.1528) Grad: 10.8995  LR: 0.003980  \n",
      "Epoch: [285][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.1033(1.1138) Grad: 8.6151  LR: 0.003980  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 0.9496(0.9496) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 285 - avg_train_loss: 1.1138  avg_val_loss: 0.9453  time: 41s\n",
      "Epoch 285 - MAE Score (without expiratory phase): 0.3580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 0.8872(0.9453) \n",
      "Epoch: [286][0/58] Elapsed 0m 2s (remain 2m 37s) Loss: 1.0448(1.0448) Grad: 2.8436  LR: 0.004104  \n",
      "Epoch: [286][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.0963(1.1030) Grad: 6.7027  LR: 0.004104  \n",
      "Epoch: [286][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.1079(1.1265) Grad: 9.1357  LR: 0.004104  \n",
      "Epoch: [286][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 1.6758(1.1291) Grad: 32.3961  LR: 0.004104  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 34s) Loss: 1.9809(1.9809) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 286 - avg_train_loss: 1.1291  avg_val_loss: 1.7973  time: 41s\n",
      "Epoch 286 - MAE Score (without expiratory phase): 0.7390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.6893(1.7973) \n",
      "Epoch: [287][0/58] Elapsed 0m 2s (remain 2m 41s) Loss: 1.9247(1.9247) Grad: 32.6394  LR: 0.004222  \n",
      "Epoch: [287][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.6539(1.7522) Grad: 12.7256  LR: 0.004222  \n",
      "Epoch: [287][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2501(1.6071) Grad: 5.5102  LR: 0.004222  \n",
      "Epoch: [287][57/58] Elapsed 0m 31s (remain 0m 0s) Loss: 2.6176(1.6720) Grad: 42.7582  LR: 0.004222  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 37s) Loss: 1.4461(1.4461) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 287 - avg_train_loss: 1.6720  avg_val_loss: 1.4191  time: 41s\n",
      "Epoch 287 - MAE Score (without expiratory phase): 0.5729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.3411(1.4191) \n",
      "Epoch: [288][0/58] Elapsed 0m 2s (remain 2m 35s) Loss: 1.5258(1.5258) Grad: 22.3242  LR: 0.004333  \n",
      "Epoch: [288][20/58] Elapsed 0m 13s (remain 0m 23s) Loss: 1.3164(1.4482) Grad: 7.4608  LR: 0.004333  \n",
      "Epoch: [288][40/58] Elapsed 0m 23s (remain 0m 9s) Loss: 1.2189(1.3718) Grad: 5.3603  LR: 0.004333  \n",
      "Epoch: [288][57/58] Elapsed 0m 32s (remain 0m 0s) Loss: 1.1457(1.3112) Grad: 4.1960  LR: 0.004333  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 36s) Loss: 1.1322(1.1322) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 288 - avg_train_loss: 1.3112  avg_val_loss: 1.1188  time: 41s\n",
      "Epoch 288 - MAE Score (without expiratory phase): 0.4381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 8s (remain 0m 0s) Loss: 1.0285(1.1188) \n",
      "Epoch: [289][0/58] Elapsed 0m 2s (remain 2m 33s) Loss: 1.2011(1.2011) Grad: 4.7288  LR: 0.004437  \n",
      "Epoch: [289][20/58] Elapsed 0m 12s (remain 0m 22s) Loss: 1.2293(1.1629) Grad: 13.2284  LR: 0.004437  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
