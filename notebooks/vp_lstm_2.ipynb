{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "- PyTorch RNN starter code with W&B  \n",
    "- Pytorch W&B Usage Examples from https://docs.wandb.ai/guides/integrations/pytorch  \n",
    "\n",
    "If this notebook is helpful, feel free to upvote :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/google/deluca-lung/main/assets/2020-10-02%20Ventilator%20diagram.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "EXP_NAME='1005_1024_512_256'\n",
    "\n",
    "OUTPUT_DIR = f'./results/{EXP_NAME}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    experiment_name=EXP_NAME\n",
    "    competition='ventilator'\n",
    "    _wandb_kernel='hypknot'\n",
    "    apex=False\n",
    "    print_freq=20\n",
    "    num_workers=4\n",
    "    model_name='rnn'\n",
    "    scheduler='CosineAnnealingLR' # ['linear', 'cosine', 'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    batch_scheduler=False\n",
    "    #num_warmup_steps=100 # ['linear', 'cosine']\n",
    "    #num_cycles=0.5 # 'cosine'\n",
    "    #factor=0.2 # ReduceLROnPlateau\n",
    "    #patience=4 # ReduceLROnPlateau\n",
    "    #eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=50 # CosineAnnealingLR\n",
    "    #T_0=50 # CosineAnnealingWarmRestarts\n",
    "    epochs=30\n",
    "    max_grad_norm=1000\n",
    "    gradient_accumulation_steps=1\n",
    "    hidden_size=1024\n",
    "    hidden2_size=512\n",
    "    hidden3_size=256\n",
    "    lr=5e-3\n",
    "    min_lr=1e-6\n",
    "    weight_decay=1e-6\n",
    "    batch_size=1024\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    cate_seq_cols=['R', 'C']\n",
    "    cont_seq_cols=['time_step', 'u_in', 'u_out'] \\\n",
    "            + ['area', 'u_in_cumsum', 'u_in_lag1', 'u_in_lag2', 'u_in_lag3', 'u_in_lag4',\n",
    "               'u_out_lag1', 'u_out_lag2', 'u_out_lag3', 'u_out_lag4',\n",
    "               'u_in_lag_back1', 'u_in_lag_back2', 'u_in_lag_back3', 'u_in_lag_back4',\n",
    "               'u_out_lag_back1', 'u_out_lag_back2', 'u_out_lag_back3', 'u_out_lag_back4',\n",
    "               'breath_id__u_in__max', 'breath_id__u_out__max',\n",
    "               'u_in_diff1', 'u_in_diff2', 'u_out_diff1', 'u_out_diff2',\n",
    "               'breath_id__u_in__diffmax', 'breath_id__u_in__diffmean',\n",
    "               'u_in_diff3', 'u_in_diff4', 'u_out_diff3', 'u_out_diff4', 'cross', 'cross2']\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if CFG.apex:\n",
    "    from apex import amp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhypknot\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public/runs/3n942f6v\" target=\"_blank\">genial-shadow-16</a></strong> to <a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "import wandb\n",
    "\n",
    "# try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "#     wandb.login(key=secret_value_0)\n",
    "#     anony = None\n",
    "# except:\n",
    "#     anony = \"must\"\n",
    "#     print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "anony=None # not for kaggle kernel\n",
    "    \n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "run = wandb.init(project=\"Ventilator-Pressure-Public\", \n",
    "                 # name=CFG.model_name,\n",
    "                 config=class2dict(CFG),\n",
    "                 group=CFG.model_name,\n",
    "                 job_type=\"train\",\n",
    "                 anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_trues, y_preds):\n",
    "    score = mean_absolute_error(y_trues, y_preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080043</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>2.964399</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>3.157395</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>3.170056</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>3.271690</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R  C  time_step      u_in  u_out   pressure\n",
       "0   1          1  1  2   0.000000  0.080043      0   5.837492\n",
       "1   2          1  1  2   0.033652  2.964399      0   5.907794\n",
       "2   3          1  1  2   0.067514  3.157395      0   7.876254\n",
       "3   4          1  1  2   0.101542  3.170056      0  11.742872\n",
       "4   5          1  1  2   0.135756  3.271690      0  12.234987"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>2.141835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>2.750578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>3.101470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>3.307654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R  C  time_step      u_in  u_out\n",
       "0   1          0  0  1   0.000000  0.000000      0\n",
       "1   2          0  0  1   0.031904  2.141835      0\n",
       "2   3          0  0  1   0.063827  2.750578      0\n",
       "3   4          0  0  1   0.095751  3.101470      0\n",
       "4   5          0  0  1   0.127644  3.307654      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pressure\n",
       "0   1         0\n",
       "1   2         0\n",
       "2   3         0\n",
       "3   4         0\n",
       "4   5         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "sub = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "for c in ['u_in']:\n",
    "    train[c] = np.log1p(train[c])\n",
    "    test[c] = np.log1p(test[c])\n",
    "    \n",
    "r_map = {5: 0, 20: 1, 50: 2}\n",
    "c_map = {10: 0, 20: 1, 50: 2}\n",
    "train['R'] = train['R'].map(r_map)\n",
    "test['R'] = test['R'].map(r_map)\n",
    "train['C'] = train['C'].map(c_map)\n",
    "test['C'] = test['C'].map(c_map)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# FE\n",
    "# ====================================================\n",
    "def add_feature(df):\n",
    "#     # breath_time\n",
    "#     df['breath_time'] = df['time_step'] - df['time_step'].shift(1)\n",
    "#     df.loc[df['time_step'] == 0, 'breath_time'] = 0\n",
    "#     # u_in_time\n",
    "#     df['u_in_time'] = df['u_in'] - df['u_in'].shift(1)\n",
    "#     df.loc[df['time_step'] == 0, 'u_in_time'] = 0\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "\n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "\n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "\n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "\n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    return df\n",
    "\n",
    "\n",
    "train = add_feature(train)\n",
    "test = add_feature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    1207200\n",
      "1    1207200\n",
      "2    1207200\n",
      "3    1207200\n",
      "4    1207200\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "Fold = GroupKFold(n_splits=5)\n",
    "groups = train['breath_id'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['pressure'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "print(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.groups = df.groupby('breath_id').groups\n",
    "        self.keys = list(self.groups.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.groups[self.keys[idx]]\n",
    "        df = self.df.iloc[indexes]\n",
    "        cate_seq_x = torch.LongTensor(df[CFG.cate_seq_cols].values)\n",
    "        cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n",
    "        u_out = torch.LongTensor(df['u_out'].values)\n",
    "        label = torch.FloatTensor(df['pressure'].values)\n",
    "        return cate_seq_x, cont_seq_x, u_out, label\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.groups = df.groupby('breath_id').groups\n",
    "        self.keys = list(self.groups.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.groups[self.keys[idx]]\n",
    "        df = self.df.iloc[indexes]\n",
    "        cate_seq_x = torch.LongTensor(df[CFG.cate_seq_cols].values)\n",
    "        cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n",
    "        return cate_seq_x, cont_seq_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.hidden_size = cfg.hidden_size\n",
    "        self.hidden2_size = cfg.hidden2_size\n",
    "        self.hidden3_size = cfg.hidden3_size\n",
    "        self.r_emb = nn.Embedding(3, 2, padding_idx=0)\n",
    "        self.c_emb = nn.Embedding(3, 2, padding_idx=0)\n",
    "        self.seq_emb = nn.Sequential(\n",
    "            nn.Linear(4 + len(cfg.cont_seq_cols), self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.lstm1 = nn.LSTM(self.hidden_size, self.hidden_size, dropout=0.2, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_size*2, self.hidden2_size, dropout=0.2, batch_first=True, bidirectional=True)\n",
    "        self.lstm3 = nn.LSTM(self.hidden2_size*2, self.hidden3_size, dropout=0.2, batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden3_size * 2, self.hidden3_size * 2),\n",
    "            nn.LayerNorm(self.hidden3_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.),\n",
    "            nn.Linear(self.hidden3_size * 2, 1),\n",
    "        )\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.LSTM):\n",
    "                print(f'init {m}')\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        nn.init.normal_(param.data)\n",
    "            elif isinstance(m, nn.GRU):\n",
    "                print(f\"init {m}\")\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        init.normal_(param.data)\n",
    "\n",
    "    def forward(self, cate_seq_x, cont_seq_x):\n",
    "        bs = cont_seq_x.size(0)\n",
    "        r_emb = self.r_emb(cate_seq_x[:,:,0]).view(bs, 80, -1)\n",
    "        c_emb = self.c_emb(cate_seq_x[:,:,1]).view(bs, 80, -1)\n",
    "        seq_x = torch.cat((r_emb, c_emb, cont_seq_x), 2)\n",
    "        seq_emb = self.seq_emb(seq_x)\n",
    "        lstm_emb, _ = self.lstm1(seq_emb)\n",
    "        lstm_emb, _ = self.lstm2(lstm_emb)\n",
    "        lstm_emb, _ = self.lstm3(lstm_emb)\n",
    "        output = self.head(lstm_emb).view(bs, -1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# helper function\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(train_loader):\n",
    "        loss_mask = u_out == 0\n",
    "        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n",
    "        batch_size = cont_seq_x.size(0)\n",
    "        pred = model(cate_seq_x, cont_seq_x)\n",
    "        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if CFG.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step, len(train_loader),\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   loss=losses,\n",
    "                   grad_norm=grad_norm,\n",
    "                   lr=scheduler.get_lr()[0],\n",
    "                   ))\n",
    "        wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(valid_loader):\n",
    "        loss_mask = u_out == 0\n",
    "        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n",
    "        batch_size = cont_seq_x.size(0)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cate_seq_x, cont_seq_x)\n",
    "        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step, len(valid_loader),\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   loss=losses,\n",
    "                   ))\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for step, (cate_seq_x, cont_seq_x) in tk0:\n",
    "        cate_seq_x, cont_seq_x = cate_seq_x.to(device), cont_seq_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cate_seq_x, cont_seq_x)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    y_true = valid_folds['pressure'].values\n",
    "    non_expiratory_phase_val_idx = valid_folds[valid_folds['u_out'] == 0].index # The expiratory phase is not scored\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds)\n",
    "    valid_dataset = TrainDataset(valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif CFG.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=CFG.num_cycles\n",
    "            )\n",
    "        elif CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if CFG.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_true[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - MAE Score (without expiratory phase): {score:.4f}')\n",
    "        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                   f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f\"fold{fold}_best.pth\")\n",
    "            \n",
    "    preds = torch.load(OUTPUT_DIR+f\"fold{fold}_best.pth\", map_location=torch.device('cpu'))['preds']\n",
    "    valid_folds['preds'] = preds\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare: 1.train 2.test\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df['pressure'].values\n",
    "        non_expiratory_phase_val_idx = result_df[result_df['u_out'] == 0].index # The expiratory phase is not scored\n",
    "        score = get_score(labels[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "        LOGGER.info(f'Score (without expiratory phase): {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    \n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size * 2, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
    "        for fold in CFG.trn_fold:\n",
    "            model = CustomModel(CFG)\n",
    "            path = OUTPUT_DIR+f\"fold{fold}_best.pth\"\n",
    "            state = torch.load(path, map_location=torch.device('cpu'))\n",
    "            model.load_state_dict(state['model'])\n",
    "            predictions = inference_fn(test_loader, model, device)\n",
    "            test[f'fold{fold}'] = predictions\n",
    "            del state, predictions; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        # submission\n",
    "        test['pressure'] = test[[f'fold{fold}' for fold in range(CFG.n_fold)]].mean(1)\n",
    "        test[['id', 'pressure']+[f'fold{fold}' for fold in range(CFG.n_fold)]].to_csv(OUTPUT_DIR+'raw_submission.csv', index=False)\n",
    "        test[['id', 'pressure']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LSTM(1024, 1024, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "init LSTM(2048, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "init LSTM(1024, 256, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "Epoch: [1][0/58] Elapsed 0m 3s (remain 3m 38s) Loss: 41.0321(41.0321) Grad: 70.3836  LR: 0.005000  \n",
      "Epoch: [1][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.9700(22.6823) Grad: 1.3240  LR: 0.005000  \n",
      "Epoch: [1][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.8375(22.1289) Grad: 0.2619  LR: 0.005000  \n",
      "Epoch: [1][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.5788(21.9856) Grad: 1.0189  LR: 0.005000  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 21.4690(21.4690) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 21.9856  avg_val_loss: 21.4100  time: 79s\n",
      "Epoch 1 - MAE Score (without expiratory phase): 8.7237\n",
      "Epoch 1 - Save Best Score: 8.7237 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.4970(21.4100) \n",
      "Epoch: [2][0/58] Elapsed 0m 3s (remain 3m 39s) Loss: 21.3021(21.3021) Grad: 1.0780  LR: 0.004990  \n",
      "Epoch: [2][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.2682(21.3420) Grad: 1.4810  LR: 0.004990  \n",
      "Epoch: [2][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 24.0719(20.8562) Grad: 26.5560  LR: 0.004990  \n",
      "Epoch: [2][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.2540(21.1439) Grad: 4.3014  LR: 0.004990  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 20.7797(20.7797) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 21.1439  avg_val_loss: 20.7292  time: 79s\n",
      "Epoch 2 - MAE Score (without expiratory phase): 8.5250\n",
      "Epoch 2 - Save Best Score: 8.5250 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 19.8117(20.7292) \n",
      "Epoch: [3][0/58] Elapsed 0m 3s (remain 3m 28s) Loss: 21.4182(21.4182) Grad: 3.1698  LR: 0.004966  \n",
      "Epoch: [3][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 17.0038(19.5200) Grad: 4.7613  LR: 0.004966  \n",
      "Epoch: [3][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 14.1421(18.1462) Grad: 28.9017  LR: 0.004966  \n",
      "Epoch: [3][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 11.4856(16.7214) Grad: 3.6950  LR: 0.004966  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 43s) Loss: 16.3624(16.3624) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 16.7214  avg_val_loss: 16.3772  time: 80s\n",
      "Epoch 3 - MAE Score (without expiratory phase): 6.7880\n",
      "Epoch 3 - Save Best Score: 6.7880 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 15.9339(16.3772) \n",
      "Epoch: [4][0/58] Elapsed 0m 3s (remain 3m 31s) Loss: 16.8350(16.8350) Grad: 58.9659  LR: 0.004931  \n",
      "Epoch: [4][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 10.5802(12.0407) Grad: 43.9335  LR: 0.004931  \n",
      "Epoch: [4][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 9.6677(11.2182) Grad: 22.3832  LR: 0.004931  \n",
      "Epoch: [4][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 7.9828(10.7397) Grad: 9.5304  LR: 0.004931  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 8.7805(8.7805) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 10.7397  avg_val_loss: 8.8984  time: 80s\n",
      "Epoch 4 - MAE Score (without expiratory phase): 3.8194\n",
      "Epoch 4 - Save Best Score: 3.8194 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 8.7464(8.8984) \n",
      "Epoch: [5][0/58] Elapsed 0m 3s (remain 3m 36s) Loss: 9.0000(9.0000) Grad: 45.2478  LR: 0.004887  \n",
      "Epoch: [5][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 8.9434(9.6897) Grad: 44.3275  LR: 0.004887  \n",
      "Epoch: [5][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 10.8732(9.5735) Grad: 31.4644  LR: 0.004887  \n",
      "Epoch: [5][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 8.7491(9.2662) Grad: 80.2800  LR: 0.004887  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 8.0712(8.0712) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 9.2662  avg_val_loss: 8.2158  time: 80s\n",
      "Epoch 5 - MAE Score (without expiratory phase): 3.3044\n",
      "Epoch 5 - Save Best Score: 3.3044 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 8.1437(8.2158) \n",
      "Epoch: [6][0/58] Elapsed 0m 3s (remain 3m 36s) Loss: 8.4323(8.4323) Grad: 66.8426  LR: 0.004834  \n",
      "Epoch: [6][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 9.4971(8.4766) Grad: 66.7633  LR: 0.004834  \n",
      "Epoch: [6][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 6.5401(8.4339) Grad: 39.8765  LR: 0.004834  \n",
      "Epoch: [6][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 6.9607(8.3189) Grad: 41.4475  LR: 0.004834  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 7.7563(7.7563) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 8.3189  avg_val_loss: 7.8723  time: 80s\n",
      "Epoch 6 - MAE Score (without expiratory phase): 3.2048\n",
      "Epoch 6 - Save Best Score: 3.2048 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 7.6925(7.8723) \n",
      "Epoch: [7][0/58] Elapsed 0m 3s (remain 3m 38s) Loss: 7.6730(7.6730) Grad: 55.3152  LR: 0.004772  \n",
      "Epoch: [7][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 7.9694(6.0262) Grad: 96.1726  LR: 0.004772  \n",
      "Epoch: [7][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 5.0267(5.8394) Grad: 35.3980  LR: 0.004772  \n",
      "Epoch: [7][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 5.1720(5.7479) Grad: 65.2423  LR: 0.004772  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 5.2402(5.2402) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 5.7479  avg_val_loss: 5.3205  time: 80s\n",
      "Epoch 7 - MAE Score (without expiratory phase): 2.1810\n",
      "Epoch 7 - Save Best Score: 2.1810 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 5.3036(5.3205) \n",
      "Epoch: [8][0/58] Elapsed 0m 3s (remain 3m 32s) Loss: 5.4211(5.4211) Grad: 63.7537  LR: 0.004701  \n",
      "Epoch: [8][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 4.7060(5.2140) Grad: 47.0244  LR: 0.004701  \n",
      "Epoch: [8][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 5.9975(5.1938) Grad: 87.0366  LR: 0.004701  \n",
      "Epoch: [8][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 4.2665(5.1511) Grad: 45.8791  LR: 0.004701  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 43s) Loss: 4.7969(4.7969) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 5.1511  avg_val_loss: 4.8756  time: 80s\n",
      "Epoch 8 - MAE Score (without expiratory phase): 2.0586\n",
      "Epoch 8 - Save Best Score: 2.0586 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 4.8913(4.8756) \n",
      "Epoch: [9][0/58] Elapsed 0m 3s (remain 3m 33s) Loss: 4.8390(4.8390) Grad: 68.6862  LR: 0.004621  \n",
      "Epoch: [9][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 4.3893(4.7757) Grad: 50.8205  LR: 0.004621  \n",
      "Epoch: [9][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 4.9995(4.9776) Grad: 66.3969  LR: 0.004621  \n",
      "Epoch: [9][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 3.9999(4.8625) Grad: 30.0296  LR: 0.004621  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 4.2401(4.2401) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 4.8625  avg_val_loss: 4.2426  time: 81s\n",
      "Epoch 9 - MAE Score (without expiratory phase): 1.7231\n",
      "Epoch 9 - Save Best Score: 1.7231 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 4.2775(4.2426) \n",
      "Epoch: [10][0/58] Elapsed 0m 3s (remain 3m 28s) Loss: 4.1747(4.1747) Grad: 50.9541  LR: 0.004532  \n",
      "Epoch: [10][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 3.9423(4.4893) Grad: 33.5774  LR: 0.004532  \n",
      "Epoch: [10][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.8060(4.5335) Grad: 24.5788  LR: 0.004532  \n",
      "Epoch: [10][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 4.3574(4.5173) Grad: 59.9788  LR: 0.004532  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 3.8748(3.8748) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 4.5173  avg_val_loss: 3.8486  time: 80s\n",
      "Epoch 10 - MAE Score (without expiratory phase): 1.5287\n",
      "Epoch 10 - Save Best Score: 1.5287 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 3.8325(3.8486) \n",
      "Epoch: [11][0/58] Elapsed 0m 3s (remain 3m 29s) Loss: 3.9129(3.9129) Grad: 34.4419  LR: 0.004436  \n",
      "Epoch: [11][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 3.7553(4.3141) Grad: 41.1402  LR: 0.004436  \n",
      "Epoch: [11][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 4.1742(4.2649) Grad: 69.6081  LR: 0.004436  \n",
      "Epoch: [11][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 3.8279(4.2683) Grad: 35.6501  LR: 0.004436  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 3.5061(3.5061) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 4.2683  avg_val_loss: 3.4925  time: 80s\n",
      "Epoch 11 - MAE Score (without expiratory phase): 1.4171\n",
      "Epoch 11 - Save Best Score: 1.4171 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 3.4590(3.4925) \n",
      "Epoch: [12][0/58] Elapsed 0m 3s (remain 3m 38s) Loss: 3.6295(3.6295) Grad: 21.3804  LR: 0.004332  \n",
      "Epoch: [12][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 4.6229(4.2990) Grad: 66.3407  LR: 0.004332  \n",
      "Epoch: [12][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.5268(4.3258) Grad: 26.1095  LR: 0.004332  \n",
      "Epoch: [12][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 3.2786(4.2073) Grad: 14.7062  LR: 0.004332  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 3.7946(3.7946) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - avg_train_loss: 4.2073  avg_val_loss: 3.7003  time: 80s\n",
      "Epoch 12 - MAE Score (without expiratory phase): 1.5309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 3.6893(3.7003) \n",
      "Epoch: [13][0/58] Elapsed 0m 3s (remain 3m 33s) Loss: 3.7275(3.7275) Grad: 54.8687  LR: 0.004221  \n",
      "Epoch: [13][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 3.4069(3.9645) Grad: 20.1972  LR: 0.004221  \n",
      "Epoch: [13][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.5244(4.0226) Grad: 45.5677  LR: 0.004221  \n",
      "Epoch: [13][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 5.5816(3.9958) Grad: 100.8984  LR: 0.004221  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 4.5039(4.5039) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - avg_train_loss: 3.9958  avg_val_loss: 4.3920  time: 80s\n",
      "Epoch 13 - MAE Score (without expiratory phase): 1.8267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 4.4066(4.3920) \n",
      "Epoch: [14][0/58] Elapsed 0m 3s (remain 3m 33s) Loss: 4.4221(4.4221) Grad: 76.7532  LR: 0.004103  \n",
      "Epoch: [14][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 3.2914(3.8733) Grad: 20.1088  LR: 0.004103  \n",
      "Epoch: [14][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 5.8336(3.8390) Grad: 98.3562  LR: 0.004103  \n",
      "Epoch: [14][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 3.9929(4.0774) Grad: 63.5491  LR: 0.004103  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 5.0821(5.0821) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - avg_train_loss: 4.0774  avg_val_loss: 5.1065  time: 80s\n",
      "Epoch 14 - MAE Score (without expiratory phase): 2.1334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 5.0891(5.1065) \n",
      "Epoch: [15][0/58] Elapsed 0m 3s (remain 3m 29s) Loss: 5.2833(5.2833) Grad: 92.0353  LR: 0.003979  \n",
      "Epoch: [15][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 4.1714(4.0755) Grad: 71.7155  LR: 0.003979  \n",
      "Epoch: [15][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.8884(3.8422) Grad: 69.5997  LR: 0.003979  \n",
      "Epoch: [15][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 3.3304(3.7654) Grad: 35.4853  LR: 0.003979  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 39s) Loss: 3.1243(3.1243) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - avg_train_loss: 3.7654  avg_val_loss: 3.0980  time: 80s\n",
      "Epoch 15 - MAE Score (without expiratory phase): 1.2839\n",
      "Epoch 15 - Save Best Score: 1.2839 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 3.0890(3.0980) \n",
      "Epoch: [16][0/58] Elapsed 0m 3s (remain 3m 33s) Loss: 3.2366(3.2366) Grad: 31.0454  LR: 0.003849  \n",
      "Epoch: [16][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 3.4754(3.6059) Grad: 62.2184  LR: 0.003849  \n",
      "Epoch: [16][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.5006(3.5656) Grad: 41.0271  LR: 0.003849  \n",
      "Epoch: [16][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 3.0654(3.5290) Grad: 20.7972  LR: 0.003849  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 3.5025(3.5025) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - avg_train_loss: 3.5290  avg_val_loss: 3.4741  time: 80s\n",
      "Epoch 16 - MAE Score (without expiratory phase): 1.3890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 3.4996(3.4741) \n",
      "Epoch: [17][0/58] Elapsed 0m 3s (remain 3m 31s) Loss: 3.6482(3.6482) Grad: 67.6431  LR: 0.003714  \n",
      "Epoch: [17][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 3.8089(3.5069) Grad: 79.3737  LR: 0.003714  \n",
      "Epoch: [17][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 4.1767(3.4614) Grad: 91.1842  LR: 0.003714  \n",
      "Epoch: [17][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 4.0896(3.4620) Grad: 78.6642  LR: 0.003714  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 3.6018(3.6018) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - avg_train_loss: 3.4620  avg_val_loss: 3.5514  time: 80s\n",
      "Epoch 17 - MAE Score (without expiratory phase): 1.4686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 3.5471(3.5514) \n",
      "Epoch: [18][0/58] Elapsed 0m 3s (remain 3m 38s) Loss: 3.6236(3.6236) Grad: 66.4232  LR: 0.003574  \n",
      "Epoch: [18][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 2.7294(3.3807) Grad: 20.5004  LR: 0.003574  \n",
      "Epoch: [18][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.6923(3.4595) Grad: 77.4046  LR: 0.003574  \n",
      "Epoch: [18][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 3.3140(3.4167) Grad: 57.5058  LR: 0.003574  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 39s) Loss: 3.4192(3.4192) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - avg_train_loss: 3.4167  avg_val_loss: 3.3864  time: 80s\n",
      "Epoch 18 - MAE Score (without expiratory phase): 1.3525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 3.3727(3.3864) \n",
      "Epoch: [19][0/58] Elapsed 0m 3s (remain 3m 39s) Loss: 3.4824(3.4824) Grad: 68.8812  LR: 0.003430  \n",
      "Epoch: [19][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 3.1271(3.2175) Grad: 50.1119  LR: 0.003430  \n",
      "Epoch: [19][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 4.3301(3.3572) Grad: 85.7757  LR: 0.003430  \n",
      "Epoch: [19][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.7560(3.3401) Grad: 11.9159  LR: 0.003430  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 2.9145(2.9145) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - avg_train_loss: 3.3401  avg_val_loss: 2.8422  time: 81s\n",
      "Epoch 19 - MAE Score (without expiratory phase): 1.1723\n",
      "Epoch 19 - Save Best Score: 1.1723 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.8923(2.8422) \n",
      "Epoch: [20][0/58] Elapsed 0m 3s (remain 3m 31s) Loss: 2.9464(2.9464) Grad: 34.1566  LR: 0.003282  \n",
      "Epoch: [20][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 2.7195(3.2682) Grad: 14.5032  LR: 0.003282  \n",
      "Epoch: [20][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.4486(3.2431) Grad: 82.0716  LR: 0.003282  \n",
      "Epoch: [20][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 3.2822(3.2316) Grad: 65.0708  LR: 0.003282  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 3.3397(3.3397) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - avg_train_loss: 3.2316  avg_val_loss: 3.2703  time: 81s\n",
      "Epoch 20 - MAE Score (without expiratory phase): 1.3587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 3.2512(3.2703) \n",
      "Epoch: [21][0/58] Elapsed 0m 3s (remain 3m 34s) Loss: 3.3078(3.3078) Grad: 65.4347  LR: 0.003132  \n",
      "Epoch: [21][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 4.4498(3.2062) Grad: 99.2986  LR: 0.003132  \n",
      "Epoch: [21][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.2405(3.5025) Grad: 51.4551  LR: 0.003132  \n",
      "Epoch: [21][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.7614(3.3498) Grad: 21.4781  LR: 0.003132  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 2.6951(2.6951) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - avg_train_loss: 3.3498  avg_val_loss: 2.6150  time: 81s\n",
      "Epoch 21 - MAE Score (without expiratory phase): 1.0728\n",
      "Epoch 21 - Save Best Score: 1.0728 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.6519(2.6150) \n",
      "Epoch: [22][0/58] Elapsed 0m 3s (remain 3m 38s) Loss: 2.7230(2.7230) Grad: 12.3387  LR: 0.002978  \n",
      "Epoch: [22][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 3.1890(2.8775) Grad: 75.8507  LR: 0.002978  \n",
      "Epoch: [22][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 3.2801(3.6929) Grad: 13.2835  LR: 0.002978  \n",
      "Epoch: [22][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 5.1871(3.9063) Grad: 89.7265  LR: 0.002978  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 4.0369(4.0369) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - avg_train_loss: 3.9063  avg_val_loss: 3.9561  time: 81s\n",
      "Epoch 22 - MAE Score (without expiratory phase): 1.6852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 3.8597(3.9561) \n",
      "Epoch: [23][0/58] Elapsed 0m 3s (remain 3m 36s) Loss: 4.0541(4.0541) Grad: 66.7603  LR: 0.002823  \n",
      "Epoch: [23][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 4.8347(4.1087) Grad: 88.2530  LR: 0.002823  \n",
      "Epoch: [23][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 2.5502(3.7638) Grad: 2.8919  LR: 0.002823  \n",
      "Epoch: [23][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.9404(3.4636) Grad: 51.0548  LR: 0.002823  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 2.8941(2.8941) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - avg_train_loss: 3.4636  avg_val_loss: 2.8423  time: 80s\n",
      "Epoch 23 - MAE Score (without expiratory phase): 1.1326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.8956(2.8423) \n",
      "Epoch: [24][0/58] Elapsed 0m 3s (remain 3m 30s) Loss: 2.9792(2.9792) Grad: 49.5479  LR: 0.002667  \n",
      "Epoch: [24][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 3.2703(2.9140) Grad: 73.3529  LR: 0.002667  \n",
      "Epoch: [24][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 2.8137(3.1467) Grad: 25.1971  LR: 0.002667  \n",
      "Epoch: [24][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.5063(3.0117) Grad: 22.7485  LR: 0.002667  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 39s) Loss: 2.5803(2.5803) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - avg_train_loss: 3.0117  avg_val_loss: 2.5157  time: 80s\n",
      "Epoch 24 - MAE Score (without expiratory phase): 1.0276\n",
      "Epoch 24 - Save Best Score: 1.0276 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 2.5589(2.5157) \n",
      "Epoch: [25][0/58] Elapsed 0m 3s (remain 3m 38s) Loss: 2.5373(2.5373) Grad: 15.9820  LR: 0.002510  \n",
      "Epoch: [25][20/58] Elapsed 0m 27s (remain 0m 48s) Loss: 2.5855(2.7348) Grad: 27.8691  LR: 0.002510  \n",
      "Epoch: [25][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 2.4747(2.7054) Grad: 12.1299  LR: 0.002510  \n",
      "Epoch: [25][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.5710(2.6928) Grad: 44.5842  LR: 0.002510  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 2.6467(2.6467) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - avg_train_loss: 2.6928  avg_val_loss: 2.5704  time: 81s\n",
      "Epoch 25 - MAE Score (without expiratory phase): 1.0554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.6183(2.5704) \n",
      "Epoch: [26][0/58] Elapsed 0m 3s (remain 3m 30s) Loss: 2.6977(2.6977) Grad: 40.1020  LR: 0.002353  \n",
      "Epoch: [26][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 2.4802(2.6589) Grad: 17.6674  LR: 0.002353  \n",
      "Epoch: [26][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 2.5696(2.6388) Grad: 18.9446  LR: 0.002353  \n",
      "Epoch: [26][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.4397(2.6421) Grad: 13.1923  LR: 0.002353  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 44s) Loss: 2.7832(2.7832) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - avg_train_loss: 2.6421  avg_val_loss: 2.7055  time: 81s\n",
      "Epoch 26 - MAE Score (without expiratory phase): 1.1182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.7446(2.7055) \n",
      "Epoch: [27][0/58] Elapsed 0m 3s (remain 3m 41s) Loss: 2.7450(2.7450) Grad: 61.5261  LR: 0.002196  \n",
      "Epoch: [27][20/58] Elapsed 0m 27s (remain 0m 48s) Loss: 2.4450(2.7636) Grad: 7.0124  LR: 0.002196  \n",
      "Epoch: [27][40/58] Elapsed 0m 50s (remain 0m 21s) Loss: 2.7339(2.6706) Grad: 47.5713  LR: 0.002196  \n",
      "Epoch: [27][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.5403(2.6426) Grad: 38.1174  LR: 0.002196  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 43s) Loss: 2.6619(2.6619) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 - avg_train_loss: 2.6426  avg_val_loss: 2.5774  time: 81s\n",
      "Epoch 27 - MAE Score (without expiratory phase): 1.0269\n",
      "Epoch 27 - Save Best Score: 1.0269 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.6331(2.5774) \n",
      "Epoch: [28][0/58] Elapsed 0m 3s (remain 3m 45s) Loss: 2.6518(2.6518) Grad: 42.5318  LR: 0.002041  \n",
      "Epoch: [28][20/58] Elapsed 0m 27s (remain 0m 48s) Loss: 2.5584(2.4910) Grad: 44.8599  LR: 0.002041  \n",
      "Epoch: [28][40/58] Elapsed 0m 50s (remain 0m 21s) Loss: 2.4517(2.4943) Grad: 38.4171  LR: 0.002041  \n",
      "Epoch: [28][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.6474(2.4871) Grad: 48.2047  LR: 0.002041  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 43s) Loss: 2.4389(2.4389) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 - avg_train_loss: 2.4871  avg_val_loss: 2.3684  time: 81s\n",
      "Epoch 28 - MAE Score (without expiratory phase): 0.9617\n",
      "Epoch 28 - Save Best Score: 0.9617 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.4005(2.3684) \n",
      "Epoch: [29][0/58] Elapsed 0m 4s (remain 3m 50s) Loss: 2.4456(2.4456) Grad: 28.4031  LR: 0.001888  \n",
      "Epoch: [29][20/58] Elapsed 0m 27s (remain 0m 48s) Loss: 2.4598(2.5728) Grad: 38.6932  LR: 0.001888  \n",
      "Epoch: [29][40/58] Elapsed 0m 50s (remain 0m 21s) Loss: 2.4026(2.4928) Grad: 8.5271  LR: 0.001888  \n",
      "Epoch: [29][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.6959(2.5117) Grad: 64.3482  LR: 0.001888  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 43s) Loss: 2.3624(2.3624) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 - avg_train_loss: 2.5117  avg_val_loss: 2.3090  time: 81s\n",
      "Epoch 29 - MAE Score (without expiratory phase): 0.9502\n",
      "Epoch 29 - Save Best Score: 0.9502 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.3538(2.3090) \n",
      "Epoch: [30][0/58] Elapsed 0m 3s (remain 3m 45s) Loss: 2.4544(2.4544) Grad: 28.0156  LR: 0.001737  \n",
      "Epoch: [30][20/58] Elapsed 0m 27s (remain 0m 48s) Loss: 2.4230(2.5220) Grad: 20.2649  LR: 0.001737  \n",
      "Epoch: [30][40/58] Elapsed 0m 50s (remain 0m 21s) Loss: 2.2833(2.4904) Grad: 15.2515  LR: 0.001737  \n",
      "Epoch: [30][57/58] Elapsed 1m 10s (remain 0m 0s) Loss: 2.4580(2.4573) Grad: 30.2608  LR: 0.001737  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 44s) Loss: 2.3223(2.3223) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 - avg_train_loss: 2.4573  avg_val_loss: 2.2450  time: 81s\n",
      "Epoch 30 - MAE Score (without expiratory phase): 0.9241\n",
      "Epoch 30 - Save Best Score: 0.9241 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 2.2827(2.2450) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score (without expiratory phase): 0.9241\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LSTM(1024, 1024, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "init LSTM(2048, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "init LSTM(1024, 256, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "Epoch: [1][0/58] Elapsed 0m 3s (remain 3m 36s) Loss: 42.2206(42.2206) Grad: 71.2941  LR: 0.005000  \n",
      "Epoch: [1][20/58] Elapsed 0m 27s (remain 0m 47s) Loss: 21.2901(22.8742) Grad: 2.4309  LR: 0.005000  \n",
      "Epoch: [1][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 21.2610(22.2148) Grad: 0.9118  LR: 0.005000  \n",
      "Epoch: [1][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.7040(21.9704) Grad: 1.8496  LR: 0.005000  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 21.1893(21.1893) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 21.9704  avg_val_loss: 21.2417  time: 80s\n",
      "Epoch 1 - MAE Score (without expiratory phase): 8.6561\n",
      "Epoch 1 - Save Best Score: 8.6561 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 20.5684(21.2417) \n",
      "Epoch: [2][0/58] Elapsed 0m 3s (remain 3m 39s) Loss: 21.2475(21.2475) Grad: 0.9001  LR: 0.004990  \n",
      "Epoch: [2][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 19.7156(20.9532) Grad: 16.9020  LR: 0.004990  \n",
      "Epoch: [2][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.7490(21.2260) Grad: 4.3526  LR: 0.004990  \n",
      "Epoch: [2][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.5004(21.0758) Grad: 11.0375  LR: 0.004990  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 20.0126(20.0126) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 21.0758  avg_val_loss: 20.0458  time: 80s\n",
      "Epoch 2 - MAE Score (without expiratory phase): 8.7748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 19.3759(20.0458) \n",
      "Epoch: [3][0/58] Elapsed 0m 3s (remain 3m 32s) Loss: 20.4769(20.4769) Grad: 25.9338  LR: 0.004966  \n",
      "Epoch: [3][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.8085(21.3678) Grad: 5.2432  LR: 0.004966  \n",
      "Epoch: [3][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.5430(21.4759) Grad: 2.5741  LR: 0.004966  \n",
      "Epoch: [3][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.0811(21.4536) Grad: 0.2069  LR: 0.004966  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 21.3239(21.3239) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 21.4536  avg_val_loss: 21.3765  time: 79s\n",
      "Epoch 3 - MAE Score (without expiratory phase): 8.6256\n",
      "Epoch 3 - Save Best Score: 8.6256 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.7011(21.3765) \n",
      "Epoch: [4][0/58] Elapsed 0m 3s (remain 3m 33s) Loss: 21.7877(21.7877) Grad: 0.2849  LR: 0.004931  \n",
      "Epoch: [4][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.7378(21.3582) Grad: 1.6815  LR: 0.004931  \n",
      "Epoch: [4][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.4424(21.3493) Grad: 1.7414  LR: 0.004931  \n",
      "Epoch: [4][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.7976(21.2864) Grad: 0.3247  LR: 0.004931  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 21.0232(21.0232) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 21.2864  avg_val_loss: 21.0832  time: 79s\n",
      "Epoch 4 - MAE Score (without expiratory phase): 8.3442\n",
      "Epoch 4 - Save Best Score: 8.3442 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.3919(21.0832) \n",
      "Epoch: [5][0/58] Elapsed 0m 3s (remain 3m 37s) Loss: 20.7062(20.7062) Grad: 1.6507  LR: 0.004887  \n",
      "Epoch: [5][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.2361(21.1214) Grad: 1.5705  LR: 0.004887  \n",
      "Epoch: [5][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.4088(21.1730) Grad: 1.6988  LR: 0.004887  \n",
      "Epoch: [5][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.3494(21.1261) Grad: 1.4757  LR: 0.004887  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 20.9061(20.9061) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 21.1261  avg_val_loss: 20.9808  time: 79s\n",
      "Epoch 5 - MAE Score (without expiratory phase): 7.9782\n",
      "Epoch 5 - Save Best Score: 7.9782 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.2730(20.9808) \n",
      "Epoch: [6][0/58] Elapsed 0m 3s (remain 3m 43s) Loss: 20.9156(20.9156) Grad: 0.7464  LR: 0.004834  \n",
      "Epoch: [6][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.9318(21.0271) Grad: 1.7489  LR: 0.004834  \n",
      "Epoch: [6][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.4282(21.1310) Grad: 2.4540  LR: 0.004834  \n",
      "Epoch: [6][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.6869(21.0718) Grad: 1.3271  LR: 0.004834  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.9314(20.9314) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 21.0718  avg_val_loss: 21.0108  time: 79s\n",
      "Epoch 6 - MAE Score (without expiratory phase): 7.8478\n",
      "Epoch 6 - Save Best Score: 7.8478 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.3101(21.0108) \n",
      "Epoch: [7][0/58] Elapsed 0m 3s (remain 3m 37s) Loss: 20.8030(20.8030) Grad: 2.4498  LR: 0.004772  \n",
      "Epoch: [7][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.2773(21.0762) Grad: 0.3962  LR: 0.004772  \n",
      "Epoch: [7][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.8861(21.0325) Grad: 1.3016  LR: 0.004772  \n",
      "Epoch: [7][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.1928(21.0628) Grad: 1.0623  LR: 0.004772  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.9479(20.9479) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 21.0628  avg_val_loss: 21.0311  time: 79s\n",
      "Epoch 7 - MAE Score (without expiratory phase): 7.7503\n",
      "Epoch 7 - Save Best Score: 7.7503 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.3307(21.0311) \n",
      "Epoch: [8][0/58] Elapsed 0m 3s (remain 3m 27s) Loss: 21.5224(21.5224) Grad: 3.6461  LR: 0.004701  \n",
      "Epoch: [8][20/58] Elapsed 0m 26s (remain 0m 46s) Loss: 22.1603(21.0358) Grad: 0.9515  LR: 0.004701  \n",
      "Epoch: [8][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.3012(21.0653) Grad: 3.3173  LR: 0.004701  \n",
      "Epoch: [8][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.3391(21.0260) Grad: 1.7723  LR: 0.004701  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.8516(20.8516) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 21.0260  avg_val_loss: 20.9309  time: 79s\n",
      "Epoch 8 - MAE Score (without expiratory phase): 7.8078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.2210(20.9309) \n",
      "Epoch: [9][0/58] Elapsed 0m 3s (remain 3m 37s) Loss: 20.8290(20.8290) Grad: 1.5314  LR: 0.004621  \n",
      "Epoch: [9][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.0226(21.0622) Grad: 3.5953  LR: 0.004621  \n",
      "Epoch: [9][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.9840(21.0096) Grad: 1.8753  LR: 0.004621  \n",
      "Epoch: [9][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.0327(21.0098) Grad: 0.9997  LR: 0.004621  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.8323(20.8323) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 21.0098  avg_val_loss: 20.9080  time: 80s\n",
      "Epoch 9 - MAE Score (without expiratory phase): 7.9107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 20.1947(20.9080) \n",
      "Epoch: [10][0/58] Elapsed 0m 3s (remain 3m 39s) Loss: 21.3776(21.3776) Grad: 0.9241  LR: 0.004532  \n",
      "Epoch: [10][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.9752(20.9883) Grad: 0.9011  LR: 0.004532  \n",
      "Epoch: [10][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.8702(20.9930) Grad: 1.5715  LR: 0.004532  \n",
      "Epoch: [10][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.7825(20.9991) Grad: 0.4271  LR: 0.004532  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 20.8458(20.8458) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 20.9991  avg_val_loss: 20.9126  time: 80s\n",
      "Epoch 10 - MAE Score (without expiratory phase): 8.0863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 20.2038(20.9126) \n",
      "Epoch: [11][0/58] Elapsed 0m 3s (remain 3m 30s) Loss: 20.6944(20.6944) Grad: 2.3457  LR: 0.004436  \n",
      "Epoch: [11][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.8930(21.0794) Grad: 1.2595  LR: 0.004436  \n",
      "Epoch: [11][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.0099(21.0196) Grad: 0.7539  LR: 0.004436  \n",
      "Epoch: [11][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.9626(20.9908) Grad: 2.6492  LR: 0.004436  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 43s) Loss: 20.8040(20.8040) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 20.9908  avg_val_loss: 20.8783  time: 79s\n",
      "Epoch 11 - MAE Score (without expiratory phase): 7.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.1722(20.8783) \n",
      "Epoch: [12][0/58] Elapsed 0m 3s (remain 3m 38s) Loss: 20.1557(20.1557) Grad: 2.2051  LR: 0.004332  \n",
      "Epoch: [12][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.9394(20.9579) Grad: 4.0320  LR: 0.004332  \n",
      "Epoch: [12][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.8054(20.9647) Grad: 3.2851  LR: 0.004332  \n",
      "Epoch: [12][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.9328(20.9721) Grad: 0.9337  LR: 0.004332  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.9053(20.9053) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - avg_train_loss: 20.9721  avg_val_loss: 20.9580  time: 79s\n",
      "Epoch 12 - MAE Score (without expiratory phase): 8.4191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.2595(20.9580) \n",
      "Epoch: [13][0/58] Elapsed 0m 3s (remain 3m 33s) Loss: 21.4237(21.4237) Grad: 5.6781  LR: 0.004221  \n",
      "Epoch: [13][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.2211(21.0334) Grad: 3.1171  LR: 0.004221  \n",
      "Epoch: [13][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 19.4693(20.9842) Grad: 0.6967  LR: 0.004221  \n",
      "Epoch: [13][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.1439(20.9914) Grad: 2.5056  LR: 0.004221  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 20.7871(20.7871) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - avg_train_loss: 20.9914  avg_val_loss: 20.8645  time: 79s\n",
      "Epoch 13 - MAE Score (without expiratory phase): 7.8646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.1544(20.8645) \n",
      "Epoch: [14][0/58] Elapsed 0m 3s (remain 3m 34s) Loss: 21.3332(21.3332) Grad: 2.0209  LR: 0.004103  \n",
      "Epoch: [14][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.1114(20.8289) Grad: 1.2751  LR: 0.004103  \n",
      "Epoch: [14][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.8817(20.9218) Grad: 0.9357  LR: 0.004103  \n",
      "Epoch: [14][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.0579(20.9512) Grad: 1.2250  LR: 0.004103  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 21.0919(21.0919) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - avg_train_loss: 20.9512  avg_val_loss: 21.1786  time: 79s\n",
      "Epoch 14 - MAE Score (without expiratory phase): 7.2717\n",
      "Epoch 14 - Save Best Score: 7.2717 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.4648(21.1786) \n",
      "Epoch: [15][0/58] Elapsed 0m 3s (remain 3m 37s) Loss: 21.1728(21.1728) Grad: 8.3919  LR: 0.003979  \n",
      "Epoch: [15][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.1385(21.0750) Grad: 4.4770  LR: 0.003979  \n",
      "Epoch: [15][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.8654(21.0113) Grad: 0.2763  LR: 0.003979  \n",
      "Epoch: [15][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.7349(20.9608) Grad: 2.1860  LR: 0.003979  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.7517(20.7517) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - avg_train_loss: 20.9608  avg_val_loss: 20.8224  time: 79s\n",
      "Epoch 15 - MAE Score (without expiratory phase): 8.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.1130(20.8224) \n",
      "Epoch: [16][0/58] Elapsed 0m 3s (remain 3m 40s) Loss: 21.0306(21.0306) Grad: 1.4272  LR: 0.003849  \n",
      "Epoch: [16][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.0090(20.9201) Grad: 0.3367  LR: 0.003849  \n",
      "Epoch: [16][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.2610(20.9025) Grad: 2.8110  LR: 0.003849  \n",
      "Epoch: [16][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.2311(20.9339) Grad: 2.0403  LR: 0.003849  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 20.8021(20.8021) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - avg_train_loss: 20.9339  avg_val_loss: 20.8652  time: 80s\n",
      "Epoch 16 - MAE Score (without expiratory phase): 8.1717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 20.1585(20.8652) \n",
      "Epoch: [17][0/58] Elapsed 0m 3s (remain 3m 33s) Loss: 20.8591(20.8591) Grad: 4.7776  LR: 0.003714  \n",
      "Epoch: [17][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.5025(20.8974) Grad: 2.8719  LR: 0.003714  \n",
      "Epoch: [17][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.5998(20.9100) Grad: 3.8684  LR: 0.003714  \n",
      "Epoch: [17][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.5342(20.9226) Grad: 0.6455  LR: 0.003714  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 20.7349(20.7349) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - avg_train_loss: 20.9226  avg_val_loss: 20.8131  time: 79s\n",
      "Epoch 17 - MAE Score (without expiratory phase): 7.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.1003(20.8131) \n",
      "Epoch: [18][0/58] Elapsed 0m 3s (remain 3m 29s) Loss: 20.8694(20.8694) Grad: 1.3048  LR: 0.003574  \n",
      "Epoch: [18][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.7673(20.9204) Grad: 0.2907  LR: 0.003574  \n",
      "Epoch: [18][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.8135(20.8939) Grad: 2.1434  LR: 0.003574  \n",
      "Epoch: [18][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.8714(20.9138) Grad: 1.3799  LR: 0.003574  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.7548(20.7548) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - avg_train_loss: 20.9138  avg_val_loss: 20.8365  time: 79s\n",
      "Epoch 18 - MAE Score (without expiratory phase): 7.7628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.1265(20.8365) \n",
      "Epoch: [19][0/58] Elapsed 0m 3s (remain 3m 37s) Loss: 20.9325(20.9325) Grad: 1.9934  LR: 0.003430  \n",
      "Epoch: [19][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.9897(20.9732) Grad: 1.0523  LR: 0.003430  \n",
      "Epoch: [19][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.0319(20.8807) Grad: 0.9303  LR: 0.003430  \n",
      "Epoch: [19][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.4556(20.9638) Grad: 6.4718  LR: 0.003430  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 43s) Loss: 21.1150(21.1150) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - avg_train_loss: 20.9638  avg_val_loss: 21.2028  time: 79s\n",
      "Epoch 19 - MAE Score (without expiratory phase): 7.3979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.5003(21.2028) \n",
      "Epoch: [20][0/58] Elapsed 0m 3s (remain 3m 34s) Loss: 21.3720(21.3720) Grad: 8.3870  LR: 0.003282  \n",
      "Epoch: [20][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.3831(20.9295) Grad: 1.1745  LR: 0.003282  \n",
      "Epoch: [20][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.1218(20.9877) Grad: 1.9910  LR: 0.003282  \n",
      "Epoch: [20][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.1373(20.9521) Grad: 3.1255  LR: 0.003282  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 20.7488(20.7488) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - avg_train_loss: 20.9521  avg_val_loss: 20.8246  time: 79s\n",
      "Epoch 20 - MAE Score (without expiratory phase): 7.9007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.1155(20.8246) \n",
      "Epoch: [21][0/58] Elapsed 0m 3s (remain 3m 28s) Loss: 20.3874(20.3874) Grad: 1.7027  LR: 0.003132  \n",
      "Epoch: [21][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.9269(20.9758) Grad: 1.3846  LR: 0.003132  \n",
      "Epoch: [21][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.5066(20.9071) Grad: 3.0074  LR: 0.003132  \n",
      "Epoch: [21][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.7430(20.9299) Grad: 8.0936  LR: 0.003132  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 40s) Loss: 20.7450(20.7450) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - avg_train_loss: 20.9299  avg_val_loss: 20.8271  time: 79s\n",
      "Epoch 21 - MAE Score (without expiratory phase): 7.7698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.1145(20.8271) \n",
      "Epoch: [22][0/58] Elapsed 0m 3s (remain 3m 33s) Loss: 20.3776(20.3776) Grad: 3.8142  LR: 0.002978  \n",
      "Epoch: [22][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.6345(20.8896) Grad: 3.7596  LR: 0.002978  \n",
      "Epoch: [22][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.6550(20.9318) Grad: 4.1417  LR: 0.002978  \n",
      "Epoch: [22][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.9945(20.9441) Grad: 0.2900  LR: 0.002978  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 43s) Loss: 20.7734(20.7734) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - avg_train_loss: 20.9441  avg_val_loss: 20.8607  time: 80s\n",
      "Epoch 22 - MAE Score (without expiratory phase): 7.5917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 20.1453(20.8607) \n",
      "Epoch: [23][0/58] Elapsed 0m 3s (remain 3m 29s) Loss: 21.1164(21.1164) Grad: 2.6059  LR: 0.002823  \n",
      "Epoch: [23][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.0173(20.8441) Grad: 1.3681  LR: 0.002823  \n",
      "Epoch: [23][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.6222(20.8895) Grad: 1.5110  LR: 0.002823  \n",
      "Epoch: [23][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.8334(20.8978) Grad: 0.2943  LR: 0.002823  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.7446(20.7446) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - avg_train_loss: 20.8978  avg_val_loss: 20.8227  time: 79s\n",
      "Epoch 23 - MAE Score (without expiratory phase): 7.8476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.1134(20.8227) \n",
      "Epoch: [24][0/58] Elapsed 0m 3s (remain 3m 32s) Loss: 20.5140(20.5140) Grad: 2.0465  LR: 0.002667  \n",
      "Epoch: [24][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.7900(20.7553) Grad: 0.1525  LR: 0.002667  \n",
      "Epoch: [24][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.3914(20.8466) Grad: 2.7000  LR: 0.002667  \n",
      "Epoch: [24][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.1398(20.8923) Grad: 3.0802  LR: 0.002667  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.7328(20.7328) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - avg_train_loss: 20.8923  avg_val_loss: 20.8100  time: 79s\n",
      "Epoch 24 - MAE Score (without expiratory phase): 7.8970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.0992(20.8100) \n",
      "Epoch: [25][0/58] Elapsed 0m 3s (remain 3m 44s) Loss: 20.8083(20.8083) Grad: 0.3963  LR: 0.002510  \n",
      "Epoch: [25][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.3091(20.9243) Grad: 2.2544  LR: 0.002510  \n",
      "Epoch: [25][40/58] Elapsed 0m 50s (remain 0m 20s) Loss: 20.7244(20.7922) Grad: 5.8833  LR: 0.002510  \n",
      "Epoch: [25][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.4836(20.6506) Grad: 22.5471  LR: 0.002510  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.3176(20.3176) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - avg_train_loss: 20.6506  avg_val_loss: 20.3538  time: 80s\n",
      "Epoch 25 - MAE Score (without expiratory phase): 8.7034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 19.6579(20.3538) \n",
      "Epoch: [26][0/58] Elapsed 0m 3s (remain 3m 31s) Loss: 20.4149(20.4149) Grad: 24.5267  LR: 0.002353  \n",
      "Epoch: [26][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 19.5125(20.1638) Grad: 18.9987  LR: 0.002353  \n",
      "Epoch: [26][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.1810(20.8646) Grad: 4.6862  LR: 0.002353  \n",
      "Epoch: [26][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.5821(21.0660) Grad: 0.3257  LR: 0.002353  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 21.1839(21.1839) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - avg_train_loss: 21.0660  avg_val_loss: 21.2483  time: 79s\n",
      "Epoch 26 - MAE Score (without expiratory phase): 8.3176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.5640(21.2483) \n",
      "Epoch: [27][0/58] Elapsed 0m 3s (remain 3m 41s) Loss: 21.5537(21.5537) Grad: 1.7437  LR: 0.002196  \n",
      "Epoch: [27][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 21.5823(21.2334) Grad: 0.3356  LR: 0.002196  \n",
      "Epoch: [27][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.1599(21.2386) Grad: 0.4582  LR: 0.002196  \n",
      "Epoch: [27][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.8663(21.1908) Grad: 0.2462  LR: 0.002196  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 20.8786(20.8786) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 - avg_train_loss: 21.1908  avg_val_loss: 20.9439  time: 79s\n",
      "Epoch 27 - MAE Score (without expiratory phase): 8.1970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 20.2461(20.9439) \n",
      "Epoch: [28][0/58] Elapsed 0m 3s (remain 3m 40s) Loss: 21.6297(21.6297) Grad: 1.3186  LR: 0.002041  \n",
      "Epoch: [28][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.4735(20.9207) Grad: 0.6244  LR: 0.002041  \n",
      "Epoch: [28][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 21.0980(20.9790) Grad: 0.9584  LR: 0.002041  \n",
      "Epoch: [28][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 21.4504(20.9519) Grad: 2.5159  LR: 0.002041  \n",
      "EVAL: [0/15] Elapsed 0m 2s (remain 0m 41s) Loss: 20.6182(20.6182) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 - avg_train_loss: 20.9519  avg_val_loss: 20.6888  time: 80s\n",
      "Epoch 28 - MAE Score (without expiratory phase): 8.0403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 9s (remain 0m 0s) Loss: 19.9853(20.6888) \n",
      "Epoch: [29][0/58] Elapsed 0m 3s (remain 3m 30s) Loss: 21.2745(21.2745) Grad: 1.7291  LR: 0.001888  \n",
      "Epoch: [29][20/58] Elapsed 0m 26s (remain 0m 47s) Loss: 20.8247(20.9054) Grad: 1.4789  LR: 0.001888  \n",
      "Epoch: [29][40/58] Elapsed 0m 49s (remain 0m 20s) Loss: 20.6674(20.7815) Grad: 3.3630  LR: 0.001888  \n",
      "Epoch: [29][57/58] Elapsed 1m 9s (remain 0m 0s) Loss: 20.1073(20.6381) Grad: 0.9672  LR: 0.001888  \n",
      "EVAL: [0/15] Elapsed 0m 3s (remain 0m 42s) Loss: 20.2573(20.2573) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 - avg_train_loss: 20.6381  avg_val_loss: 20.3190  time: 80s\n",
      "Epoch 29 - MAE Score (without expiratory phase): 8.1701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [14/15] Elapsed 0m 10s (remain 0m 0s) Loss: 19.6126(20.3190) \n",
      "Epoch: [30][0/58] Elapsed 0m 3s (remain 3m 26s) Loss: 20.8846(20.8846) Grad: 13.4377  LR: 0.001737  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
