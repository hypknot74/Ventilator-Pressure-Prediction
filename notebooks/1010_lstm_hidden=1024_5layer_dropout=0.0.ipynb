{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6526ae-d074-4bf5-a398-a0757bb96037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3090e9cc-79ea-49fe-951e-014d0cabdeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "EXP_NAME='1010_lstm_hidden=1024_5layer_dropout=0.0'\n",
    "\n",
    "DATA_DIR = \"../input/ventilator-pressure-prediction/\"\n",
    "\n",
    "OUTPUT_DIR = f'./results/{EXP_NAME}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c869b52-21c3-4379-ad34-3742feed0436",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd9b558-02d5-463e-88d7-6c2abf835763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    experiment_name=EXP_NAME\n",
    "    competition='ventilator'\n",
    "    apex=True\n",
    "    print_freq=1000\n",
    "    num_workers=4\n",
    "    model_name='lstm'\n",
    "    scheduler='CosineAnnealingWarmRestarts' # ['linear', 'cosine', 'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    batch_scheduler=False\n",
    "    #num_warmup_steps=100 # ['linear', 'cosine']\n",
    "    #num_cycles=0.5 # 'cosine'\n",
    "    factor=0.995 # ReduceLROnPlateau\n",
    "    patience=10 # ReduceLROnPlateau\n",
    "    eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=50 # CosineAnnealingLR\n",
    "    T_0=20 # CosineAnnealingWarmRestarts\n",
    "    epochs=400\n",
    "    max_grad_norm=1000\n",
    "    gradient_accumulation_steps=1\n",
    "    hidden_size=1024\n",
    "    lr=1e-3\n",
    "    min_lr=1e-5\n",
    "    weight_decay=1e-6\n",
    "    batch_size=256\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    cate_seq_cols=[]\n",
    "    cont_seq_cols=['R', 'C', 'time_step', 'u_in', 'u_out']\n",
    "    train=True\n",
    "    inference=True\n",
    "    debug=False\n",
    "\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold=[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafe76b-c184-4572-b9e6-60c75e8566a7",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb48c0c6-056e-4d6a-b57e-eb125436de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#if CFG.apex:\n",
    "#    from apex import amp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889b437-33b9-420c-bd6e-e3dfea18814d",
   "metadata": {},
   "source": [
    "# wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2c8248-73c8-463d-8b54-cbaaea65405a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhypknot\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public/runs/20j59xca\" target=\"_blank\">classic-voice-53</a></strong> to <a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "import wandb\n",
    "\n",
    "# try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "#     wandb.login(key=secret_value_0)\n",
    "#     anony = None\n",
    "# except:\n",
    "#     anony = \"must\"\n",
    "#     print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "anony=None # not for kaggle kernel\n",
    "    \n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "run = wandb.init(project=\"Ventilator-Pressure-Public\", \n",
    "                 # name=CFG.model_name,\n",
    "                 config=class2dict(CFG),\n",
    "                 group=CFG.experiment_name,\n",
    "                 job_type=\"train\",\n",
    "                 anonymous=anony)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed9123-6a9b-48b1-ba69-16a5232abc8c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30e1f12-d9f4-4155-96b9-549830918086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_trues, y_preds):\n",
    "    score = mean_absolute_error(y_trues, y_preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything()\n",
    "\n",
    "def decorate(s: str, decoration=None):\n",
    "    if decoration is None:\n",
    "        decoration = '★' * 20\n",
    "\n",
    "    return ' '.join([decoration, str(s), decoration])\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' ', verbose=0):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        if self.verbose is None:\n",
    "            return\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e67c7-9ec3-40a5-accf-ec78bad7b1e6",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5473c8e-d8a0-4caf-a1bf-fcb7e6417831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id   R   C  time_step       u_in  u_out   pressure\n",
       "0   1          1  20  50   0.000000   0.083334      0   5.837492\n",
       "1   2          1  20  50   0.033652  18.383041      0   5.907794\n",
       "2   3          1  20  50   0.067514  22.509278      0   7.876254\n",
       "3   4          1  20  50   0.101542  22.808822      0  11.742872\n",
       "4   5          1  20  50   0.135756  25.355850      0  12.234987"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R   C  time_step       u_in  u_out\n",
       "0   1          0  5  20   0.000000   0.000000      0\n",
       "1   2          0  5  20   0.031904   7.515046      0\n",
       "2   3          0  5  20   0.063827  14.651675      0\n",
       "3   4          0  5  20   0.095751  21.230610      0\n",
       "4   5          0  5  20   0.127644  26.320956      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pressure\n",
       "0   1         0\n",
       "1   2         0\n",
       "2   3         0\n",
       "3   4         0\n",
       "4   5         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv(DATA_DIR + 'train.csv')\n",
    "if CFG.debug:\n",
    "    train = train[:80*5000]\n",
    "test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(sub.head())\n",
    "\n",
    "unique_pressures = train[\"pressure\"].unique()\n",
    "sorted_pressures = np.sort(unique_pressures)\n",
    "total_pressures_len = len(sorted_pressures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2894d-a8c0-4dd8-b442-3f6b6a2a1740",
   "metadata": {},
   "source": [
    "# create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e894260-32d0-4b9d-a9b6-fd7daf9bf609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractBaseBlock:\n",
    "    def fit(self, input_df: pd.DataFrame, y=None):\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def transform(self, input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class AddMultiplyingDividing(AbstractBaseBlock):\n",
    "    def transform(self, input_df):\n",
    "        input_df['area'] = input_df['time_step'] * input_df['u_in']\n",
    "        input_df['area'] = input_df.groupby('breath_id')['area'].cumsum()\n",
    "        input_df['cross'] = input_df['u_in']*input_df['u_out']\n",
    "        input_df['cross2'] = input_df['time_step']*input_df['u_out']\n",
    "        input_df['u_in_cumsum'] = (input_df['u_in']).groupby(input_df['breath_id']).cumsum()\n",
    "        input_df['one'] = 1\n",
    "        input_df['count'] = (input_df['one']).groupby(input_df['breath_id']).cumsum()\n",
    "        input_df['u_in_cummean'] = input_df['u_in_cumsum'] / input_df['count']\n",
    "        input_df = input_df.merge(\n",
    "            input_df[input_df[\"u_out\"]==0].groupby('breath_id')['u_in'].agg([\"mean\", \"std\", \"max\"]).add_prefix(\"u_out0_\").reset_index(),\n",
    "            on=\"breath_id\"\n",
    "        )\n",
    "        input_df = input_df.merge(\n",
    "            input_df[input_df[\"u_out\"]==1].groupby('breath_id')['u_in'].agg([\"mean\", \"std\", \"max\"]).add_prefix(\"u_out1_\").reset_index(),\n",
    "            on=\"breath_id\"\n",
    "        )\n",
    "\n",
    "        output_df = pd.DataFrame(\n",
    "            {\n",
    "                \"area\": input_df['area'],\n",
    "                #\"cross\": input_df['cross'],\n",
    "                #\"cross2\": input_df['cross2'],\n",
    "                \"u_in_cumsum\": input_df['u_in_cumsum'],\n",
    "                \"u_in_cummean\": input_df['u_in_cummean'],\n",
    "                \"u_out0_mean\": input_df['u_out0_mean'],\n",
    "                \"u_out0_max\": input_df['u_out0_max'],\n",
    "                \"u_out0_max\": input_df['u_out0_std'],\n",
    "                \"u_out1_mean\": input_df['u_out1_mean'],\n",
    "                \"u_out1_max\": input_df['u_out1_max'],\n",
    "                \"u_out1_max\": input_df['u_out1_std'],\n",
    "            }\n",
    "        )\n",
    "        CFG.cont_seq_cols += output_df.add_suffix(f'@{self.__class__.__name__}').columns.tolist()\n",
    "        return output_df\n",
    "\n",
    "\n",
    "class RCDummry(AbstractBaseBlock):\n",
    "    def transform(self, input_df):\n",
    "        input_df['R_dummy'] = input_df['R'].astype(str)\n",
    "        input_df['C_dummy'] = input_df['C'].astype(str)\n",
    "        #input_df['RC_dummy'] = input_df['R_dummy'] + input_df['C_dummy']\n",
    "        output_df = pd.get_dummies(input_df[[\"R_dummy\", \"C_dummy\"]])\n",
    "        CFG.cont_seq_cols += output_df.add_suffix(f'@{self.__class__.__name__}').columns.tolist()\n",
    "        return output_df\n",
    "\n",
    "\n",
    "class AddBreathTimeAndUInTime(AbstractBaseBlock):\n",
    "    def transform(self, input_df):\n",
    "        output_df = pd.DataFrame(\n",
    "            {\n",
    "                \"breath_time\": input_df['time_step'] - input_df['time_step'].shift(1),\n",
    "                \"u_in_time\": input_df['u_in'] - input_df['u_in'].shift(1)\n",
    "            }\n",
    "        )\n",
    "        output_df.loc[input_df['time_step'] == 0, 'breath_time'] = output_df['breath_time'].mean()\n",
    "        output_df.loc[input_df['time_step'] == 0, 'u_in_time'] = output_df['u_in_time'].mean()\n",
    "        CFG.cont_seq_cols += output_df.add_suffix(f'@{self.__class__.__name__}').columns.tolist()\n",
    "        return output_df\n",
    "\n",
    "class LagFeatures(AbstractBaseBlock):\n",
    "    def transform(self, input_df):\n",
    "        output_df = pd.DataFrame(\n",
    "            {\n",
    "                \"u_in_lag1\": input_df.groupby(\"breath_id\")[\"u_in\"].shift(1).fillna(0),\n",
    "                \"u_in_lag2\": input_df.groupby(\"breath_id\")[\"u_in\"].shift(2).fillna(0),\n",
    "                \"u_in_lag3\": input_df.groupby(\"breath_id\")[\"u_in\"].shift(3).fillna(0),\n",
    "                \"u_in_lag4\": input_df.groupby(\"breath_id\")[\"u_in\"].shift(4).fillna(0),\n",
    "                \"u_in_lag-1\": input_df.groupby(\"breath_id\")[\"u_in\"].shift(-1).fillna(0),\n",
    "                \"u_in_lag-2\": input_df.groupby(\"breath_id\")[\"u_in\"].shift(-2).fillna(0),\n",
    "                \"u_in_lag-3\": input_df.groupby(\"breath_id\")[\"u_in\"].shift(-3).fillna(0),\n",
    "                \"u_in_lag-4\": input_df.groupby(\"breath_id\")[\"u_in\"].shift(-4).fillna(0),\n",
    "                \"u_out_lag1\": input_df.groupby(\"breath_id\")[\"u_out\"].shift(1).fillna(0),\n",
    "                \"u_out_lag2\": input_df.groupby(\"breath_id\")[\"u_out\"].shift(2).fillna(0),\n",
    "                \"u_out_lag3\": input_df.groupby(\"breath_id\")[\"u_out\"].shift(3).fillna(0),\n",
    "                \"u_out_lag4\": input_df.groupby(\"breath_id\")[\"u_out\"].shift(4).fillna(0),\n",
    "                #\"u_out_lag-1\": input_df.groupby(\"breath_id\")[\"u_out\"].shift(-1).fillna(0),\n",
    "                #\"u_out_lag-2\": input_df.groupby(\"breath_id\")[\"u_out\"].shift(-2).fillna(0),\n",
    "                #\"u_out_lag-3\": input_df.groupby(\"breath_id\")[\"u_out\"].shift(-3).fillna(0),\n",
    "                #\"u_out_lag-4\": input_df.groupby(\"breath_id\")[\"u_out\"].shift(-4).fillna(0),\n",
    "            }\n",
    "        )\n",
    "        output_df[\"u_in_lag1_diff\"] = output_df[\"u_in_lag1\"] - input_df[\"u_in\"]\n",
    "        output_df[\"u_in_lag2_diff\"] = output_df[\"u_in_lag2\"] - input_df[\"u_in\"]\n",
    "        output_df[\"u_in_lag3_diff\"] = output_df[\"u_in_lag3\"] - input_df[\"u_in\"]\n",
    "        output_df[\"u_in_lag4_diff\"] = output_df[\"u_in_lag4\"] - input_df[\"u_in\"]\n",
    "\n",
    "        output_df[\"u_in_rolling_mean2\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(2).mean()[\"u_in\"].reset_index(drop=True)\n",
    "        output_df[\"u_in_rolling_mean4\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(4).mean()[\"u_in\"].reset_index(drop=True)\n",
    "        output_df[\"u_in_rolling_mean10\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(10).mean()[\"u_in\"].reset_index(drop=True)\n",
    "        if not CFG.debug:\n",
    "            output_df[\"u_in_rolling_max2\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(2).max()[\"u_in\"].reset_index(drop=True)\n",
    "            output_df[\"u_in_rolling_max4\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(4).max()[\"u_in\"].reset_index(drop=True)\n",
    "            output_df[\"u_in_rolling_max10\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(10).max()[\"u_in\"].reset_index(drop=True)\n",
    "            output_df[\"u_in_rolling_min2\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(2).min()[\"u_in\"].reset_index(drop=True)\n",
    "            output_df[\"u_in_rolling_min4\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(4).min()[\"u_in\"].reset_index(drop=True)\n",
    "            output_df[\"u_in_rolling_min10\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(10).min()[\"u_in\"].reset_index(drop=True)\n",
    "            output_df[\"u_in_rolling_std2\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(2).std()[\"u_in\"].reset_index(drop=True)\n",
    "            output_df[\"u_in_rolling_std4\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(4).std()[\"u_in\"].reset_index(drop=True)\n",
    "            output_df[\"u_in_rolling_std10\"] = input_df[[\"breath_id\", \"u_in\"]].groupby(\"breath_id\").rolling(10).std()[\"u_in\"].reset_index(drop=True)\n",
    "        for col in output_df.columns:\n",
    "            output_df[col] = output_df[col].fillna(output_df[col].mean())\n",
    "        CFG.cont_seq_cols += output_df.add_suffix(f'@{self.__class__.__name__}').columns.tolist()\n",
    "        return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3418b5a4-23eb-41dd-933e-05410ff5388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_blocks = [\n",
    "    AddMultiplyingDividing(),\n",
    "    AddBreathTimeAndUInTime(),\n",
    "    RCDummry(),\n",
    "    LagFeatures()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fac73845-a919-4c3a-b854-8cc4b5e5b5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★ start run blocks... ★★★★★★★★★★★★★★★★★★★★\n",
      "out_df shape: (0, 0) \t- <__main__.AddMultiplyingDividing object at 0x7f58e49349d0> 5.753[s]\n",
      "out_df shape: (6036000, 7) \t- <__main__.AddBreathTimeAndUInTime object at 0x7f58e4934a60> 0.279[s]\n",
      "out_df shape: (6036000, 9) \t- <__main__.RCDummry object at 0x7f58e4934520> 10.859[s]\n",
      "out_df shape: (6036000, 15) \t- <__main__.LagFeatures object at 0x7f58e49349a0> 132.370[s]\n",
      "run test=False 151.436[s]\n",
      "out_df shape: (6036000, 43)\n",
      "★★★★★★★★★★★★★★★★★★★★ start run blocks... ★★★★★★★★★★★★★★★★★★★★\n",
      "out_df shape: (0, 0) \t- <__main__.AddMultiplyingDividing object at 0x7f58e49349d0> 3.431[s]\n",
      "out_df shape: (4024000, 7) \t- <__main__.AddBreathTimeAndUInTime object at 0x7f58e4934a60> 0.169[s]\n",
      "out_df shape: (4024000, 9) \t- <__main__.RCDummry object at 0x7f58e4934520> 7.118[s]\n",
      "out_df shape: (4024000, 15) \t- <__main__.LagFeatures object at 0x7f58e49349a0> 88.562[s]\n",
      "run test=True 100.685[s]\n",
      "out_df shape: (4024000, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "      <th>area@AddMultiplyingDividing</th>\n",
       "      <th>u_in_cumsum@AddMultiplyingDividing</th>\n",
       "      <th>u_in_cummean@AddMultiplyingDividing</th>\n",
       "      <th>u_out0_mean@AddMultiplyingDividing</th>\n",
       "      <th>u_out0_max@AddMultiplyingDividing</th>\n",
       "      <th>u_out1_mean@AddMultiplyingDividing</th>\n",
       "      <th>u_out1_max@AddMultiplyingDividing</th>\n",
       "      <th>breath_time@AddBreathTimeAndUInTime</th>\n",
       "      <th>u_in_time@AddBreathTimeAndUInTime</th>\n",
       "      <th>R_dummy_20@RCDummry</th>\n",
       "      <th>R_dummy_5@RCDummry</th>\n",
       "      <th>R_dummy_50@RCDummry</th>\n",
       "      <th>C_dummy_10@RCDummry</th>\n",
       "      <th>C_dummy_20@RCDummry</th>\n",
       "      <th>C_dummy_50@RCDummry</th>\n",
       "      <th>u_in_lag1@LagFeatures</th>\n",
       "      <th>u_in_lag2@LagFeatures</th>\n",
       "      <th>u_in_lag3@LagFeatures</th>\n",
       "      <th>u_in_lag4@LagFeatures</th>\n",
       "      <th>u_in_lag-1@LagFeatures</th>\n",
       "      <th>u_in_lag-2@LagFeatures</th>\n",
       "      <th>u_in_lag-3@LagFeatures</th>\n",
       "      <th>u_in_lag-4@LagFeatures</th>\n",
       "      <th>u_out_lag1@LagFeatures</th>\n",
       "      <th>u_out_lag2@LagFeatures</th>\n",
       "      <th>u_out_lag3@LagFeatures</th>\n",
       "      <th>u_out_lag4@LagFeatures</th>\n",
       "      <th>u_in_lag1_diff@LagFeatures</th>\n",
       "      <th>u_in_lag2_diff@LagFeatures</th>\n",
       "      <th>u_in_lag3_diff@LagFeatures</th>\n",
       "      <th>u_in_lag4_diff@LagFeatures</th>\n",
       "      <th>u_in_rolling_mean2@LagFeatures</th>\n",
       "      <th>u_in_rolling_mean4@LagFeatures</th>\n",
       "      <th>u_in_rolling_mean10@LagFeatures</th>\n",
       "      <th>u_in_rolling_max2@LagFeatures</th>\n",
       "      <th>u_in_rolling_max4@LagFeatures</th>\n",
       "      <th>u_in_rolling_max10@LagFeatures</th>\n",
       "      <th>u_in_rolling_min2@LagFeatures</th>\n",
       "      <th>u_in_rolling_min4@LagFeatures</th>\n",
       "      <th>u_in_rolling_min10@LagFeatures</th>\n",
       "      <th>u_in_rolling_std2@LagFeatures</th>\n",
       "      <th>u_in_rolling_std4@LagFeatures</th>\n",
       "      <th>u_in_rolling_std10@LagFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>22.119824</td>\n",
       "      <td>5.829997</td>\n",
       "      <td>2.961716</td>\n",
       "      <td>2.1621</td>\n",
       "      <td>4.370474e-07</td>\n",
       "      <td>2.318432e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.083334</td>\n",
       "      <td>-0.083334</td>\n",
       "      <td>-0.083334</td>\n",
       "      <td>-0.083334</td>\n",
       "      <td>7.296453</td>\n",
       "      <td>7.122734</td>\n",
       "      <td>6.673223</td>\n",
       "      <td>8.130658</td>\n",
       "      <td>9.024859</td>\n",
       "      <td>10.26289</td>\n",
       "      <td>6.462249</td>\n",
       "      <td>5.530754</td>\n",
       "      <td>4.011267</td>\n",
       "      <td>1.179743</td>\n",
       "      <td>1.644297</td>\n",
       "      <td>2.304005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>18.466375</td>\n",
       "      <td>9.233188</td>\n",
       "      <td>22.119824</td>\n",
       "      <td>5.829997</td>\n",
       "      <td>2.961716</td>\n",
       "      <td>2.1621</td>\n",
       "      <td>3.365231e-02</td>\n",
       "      <td>1.829971e+01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>27.259866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.299707</td>\n",
       "      <td>-18.383041</td>\n",
       "      <td>-18.383041</td>\n",
       "      <td>-18.383041</td>\n",
       "      <td>9.233188</td>\n",
       "      <td>7.122734</td>\n",
       "      <td>6.673223</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>9.024859</td>\n",
       "      <td>10.26289</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>5.530754</td>\n",
       "      <td>4.011267</td>\n",
       "      <td>12.939847</td>\n",
       "      <td>1.644297</td>\n",
       "      <td>2.304005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "      <td>2.138333</td>\n",
       "      <td>40.975653</td>\n",
       "      <td>13.658551</td>\n",
       "      <td>22.119824</td>\n",
       "      <td>5.829997</td>\n",
       "      <td>2.961716</td>\n",
       "      <td>2.1621</td>\n",
       "      <td>3.386211e-02</td>\n",
       "      <td>4.126236e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>27.259866</td>\n",
       "      <td>27.127486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.126236</td>\n",
       "      <td>-22.425944</td>\n",
       "      <td>-22.509278</td>\n",
       "      <td>-22.509278</td>\n",
       "      <td>20.446160</td>\n",
       "      <td>7.122734</td>\n",
       "      <td>6.673223</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>9.024859</td>\n",
       "      <td>10.26289</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>5.530754</td>\n",
       "      <td>4.011267</td>\n",
       "      <td>2.917690</td>\n",
       "      <td>1.644297</td>\n",
       "      <td>2.304005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "      <td>4.454391</td>\n",
       "      <td>63.784476</td>\n",
       "      <td>15.946119</td>\n",
       "      <td>22.119824</td>\n",
       "      <td>5.829997</td>\n",
       "      <td>2.961716</td>\n",
       "      <td>2.1621</td>\n",
       "      <td>3.402781e-02</td>\n",
       "      <td>2.995445e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>27.259866</td>\n",
       "      <td>27.127486</td>\n",
       "      <td>26.807732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.299544</td>\n",
       "      <td>-4.425781</td>\n",
       "      <td>-22.725488</td>\n",
       "      <td>-22.808822</td>\n",
       "      <td>22.659050</td>\n",
       "      <td>15.946119</td>\n",
       "      <td>6.673223</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>10.26289</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>4.011267</td>\n",
       "      <td>0.211810</td>\n",
       "      <td>10.766279</td>\n",
       "      <td>2.304005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "      <td>7.896588</td>\n",
       "      <td>89.140326</td>\n",
       "      <td>17.828065</td>\n",
       "      <td>22.119824</td>\n",
       "      <td>5.829997</td>\n",
       "      <td>2.961716</td>\n",
       "      <td>2.1621</td>\n",
       "      <td>3.421330e-02</td>\n",
       "      <td>2.547028e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>27.259866</td>\n",
       "      <td>27.127486</td>\n",
       "      <td>26.807732</td>\n",
       "      <td>27.864715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.547028</td>\n",
       "      <td>-2.846573</td>\n",
       "      <td>-6.972809</td>\n",
       "      <td>-25.272516</td>\n",
       "      <td>24.082336</td>\n",
       "      <td>22.264248</td>\n",
       "      <td>6.673223</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>10.26289</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>4.011267</td>\n",
       "      <td>1.801021</td>\n",
       "      <td>2.885502</td>\n",
       "      <td>2.304005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id   R   C  time_step       u_in  u_out   pressure  area@AddMultiplyingDividing  u_in_cumsum@AddMultiplyingDividing  u_in_cummean@AddMultiplyingDividing  u_out0_mean@AddMultiplyingDividing  u_out0_max@AddMultiplyingDividing  u_out1_mean@AddMultiplyingDividing  u_out1_max@AddMultiplyingDividing  breath_time@AddBreathTimeAndUInTime  u_in_time@AddBreathTimeAndUInTime  R_dummy_20@RCDummry  R_dummy_5@RCDummry  R_dummy_50@RCDummry  C_dummy_10@RCDummry  C_dummy_20@RCDummry  C_dummy_50@RCDummry  u_in_lag1@LagFeatures  u_in_lag2@LagFeatures  u_in_lag3@LagFeatures  u_in_lag4@LagFeatures  u_in_lag-1@LagFeatures  u_in_lag-2@LagFeatures  u_in_lag-3@LagFeatures  u_in_lag-4@LagFeatures  u_out_lag1@LagFeatures  u_out_lag2@LagFeatures  u_out_lag3@LagFeatures  u_out_lag4@LagFeatures  u_in_lag1_diff@LagFeatures  u_in_lag2_diff@LagFeatures  u_in_lag3_diff@LagFeatures  u_in_lag4_diff@LagFeatures  u_in_rolling_mean2@LagFeatures  u_in_rolling_mean4@LagFeatures  \\\n",
       "0   1          1  20  50   0.000000   0.083334      0   5.837492                     0.000000                            0.083334                             0.083334                           22.119824                           5.829997                            2.961716                             2.1621                         4.370474e-07                       2.318432e-07                    1                   0                    0                    0                    0                    1               0.000000               0.000000               0.000000               0.000000               18.383041               22.509278               22.808822               25.355850                     0.0                     0.0                     0.0                     0.0                   -0.083334                   -0.083334                   -0.083334                   -0.083334                        7.296453                        7.122734   \n",
       "1   2          1  20  50   0.033652  18.383041      0   5.907794                     0.618632                           18.466375                             9.233188                           22.119824                           5.829997                            2.961716                             2.1621                         3.365231e-02                       1.829971e+01                    1                   0                    0                    0                    0                    1               0.083334               0.000000               0.000000               0.000000               22.509278               22.808822               25.355850               27.259866                     0.0                     0.0                     0.0                     0.0                  -18.299707                  -18.383041                  -18.383041                  -18.383041                        9.233188                        7.122734   \n",
       "2   3          1  20  50   0.067514  22.509278      0   7.876254                     2.138333                           40.975653                            13.658551                           22.119824                           5.829997                            2.961716                             2.1621                         3.386211e-02                       4.126236e+00                    1                   0                    0                    0                    0                    1              18.383041               0.083334               0.000000               0.000000               22.808822               25.355850               27.259866               27.127486                     0.0                     0.0                     0.0                     0.0                   -4.126236                  -22.425944                  -22.509278                  -22.509278                       20.446160                        7.122734   \n",
       "3   4          1  20  50   0.101542  22.808822      0  11.742872                     4.454391                           63.784476                            15.946119                           22.119824                           5.829997                            2.961716                             2.1621                         3.402781e-02                       2.995445e-01                    1                   0                    0                    0                    0                    1              22.509278              18.383041               0.083334               0.000000               25.355850               27.259866               27.127486               26.807732                     0.0                     0.0                     0.0                     0.0                   -0.299544                   -4.425781                  -22.725488                  -22.808822                       22.659050                       15.946119   \n",
       "4   5          1  20  50   0.135756  25.355850      0  12.234987                     7.896588                           89.140326                            17.828065                           22.119824                           5.829997                            2.961716                             2.1621                         3.421330e-02                       2.547028e+00                    1                   0                    0                    0                    0                    1              22.808822              22.509278              18.383041               0.083334               27.259866               27.127486               26.807732               27.864715                     0.0                     0.0                     0.0                     0.0                   -2.547028                   -2.846573                   -6.972809                  -25.272516                       24.082336                       22.264248   \n",
       "\n",
       "   u_in_rolling_mean10@LagFeatures  u_in_rolling_max2@LagFeatures  u_in_rolling_max4@LagFeatures  u_in_rolling_max10@LagFeatures  u_in_rolling_min2@LagFeatures  u_in_rolling_min4@LagFeatures  u_in_rolling_min10@LagFeatures  u_in_rolling_std2@LagFeatures  u_in_rolling_std4@LagFeatures  u_in_rolling_std10@LagFeatures  \n",
       "0                         6.673223                       8.130658                       9.024859                        10.26289                       6.462249                       5.530754                        4.011267                       1.179743                       1.644297                        2.304005  \n",
       "1                         6.673223                      18.383041                       9.024859                        10.26289                       0.083334                       5.530754                        4.011267                      12.939847                       1.644297                        2.304005  \n",
       "2                         6.673223                      22.509278                       9.024859                        10.26289                      18.383041                       5.530754                        4.011267                       2.917690                       1.644297                        2.304005  \n",
       "3                         6.673223                      22.808822                      22.808822                        10.26289                      22.509278                       0.083334                        4.011267                       0.211810                      10.766279                        2.304005  \n",
       "4                         6.673223                      25.355850                      25.355850                        10.26289                      22.808822                      18.383041                        4.011267                       1.801021                       2.885502                        2.304005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>area@AddMultiplyingDividing</th>\n",
       "      <th>u_in_cumsum@AddMultiplyingDividing</th>\n",
       "      <th>u_in_cummean@AddMultiplyingDividing</th>\n",
       "      <th>u_out0_mean@AddMultiplyingDividing</th>\n",
       "      <th>u_out0_max@AddMultiplyingDividing</th>\n",
       "      <th>u_out1_mean@AddMultiplyingDividing</th>\n",
       "      <th>u_out1_max@AddMultiplyingDividing</th>\n",
       "      <th>breath_time@AddBreathTimeAndUInTime</th>\n",
       "      <th>u_in_time@AddBreathTimeAndUInTime</th>\n",
       "      <th>R_dummy_20@RCDummry</th>\n",
       "      <th>R_dummy_5@RCDummry</th>\n",
       "      <th>R_dummy_50@RCDummry</th>\n",
       "      <th>C_dummy_10@RCDummry</th>\n",
       "      <th>C_dummy_20@RCDummry</th>\n",
       "      <th>C_dummy_50@RCDummry</th>\n",
       "      <th>u_in_lag1@LagFeatures</th>\n",
       "      <th>u_in_lag2@LagFeatures</th>\n",
       "      <th>u_in_lag3@LagFeatures</th>\n",
       "      <th>u_in_lag4@LagFeatures</th>\n",
       "      <th>u_in_lag-1@LagFeatures</th>\n",
       "      <th>u_in_lag-2@LagFeatures</th>\n",
       "      <th>u_in_lag-3@LagFeatures</th>\n",
       "      <th>u_in_lag-4@LagFeatures</th>\n",
       "      <th>u_out_lag1@LagFeatures</th>\n",
       "      <th>u_out_lag2@LagFeatures</th>\n",
       "      <th>u_out_lag3@LagFeatures</th>\n",
       "      <th>u_out_lag4@LagFeatures</th>\n",
       "      <th>u_in_lag1_diff@LagFeatures</th>\n",
       "      <th>u_in_lag2_diff@LagFeatures</th>\n",
       "      <th>u_in_lag3_diff@LagFeatures</th>\n",
       "      <th>u_in_lag4_diff@LagFeatures</th>\n",
       "      <th>u_in_rolling_mean2@LagFeatures</th>\n",
       "      <th>u_in_rolling_mean4@LagFeatures</th>\n",
       "      <th>u_in_rolling_mean10@LagFeatures</th>\n",
       "      <th>u_in_rolling_max2@LagFeatures</th>\n",
       "      <th>u_in_rolling_max4@LagFeatures</th>\n",
       "      <th>u_in_rolling_max10@LagFeatures</th>\n",
       "      <th>u_in_rolling_min2@LagFeatures</th>\n",
       "      <th>u_in_rolling_min4@LagFeatures</th>\n",
       "      <th>u_in_rolling_min10@LagFeatures</th>\n",
       "      <th>u_in_rolling_std2@LagFeatures</th>\n",
       "      <th>u_in_rolling_std4@LagFeatures</th>\n",
       "      <th>u_in_rolling_std10@LagFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.702022</td>\n",
       "      <td>14.196737</td>\n",
       "      <td>2.763761</td>\n",
       "      <td>2.166618</td>\n",
       "      <td>6.623513e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.312916</td>\n",
       "      <td>7.138082</td>\n",
       "      <td>6.684884</td>\n",
       "      <td>8.146446</td>\n",
       "      <td>9.042205</td>\n",
       "      <td>10.276775</td>\n",
       "      <td>6.479387</td>\n",
       "      <td>5.545624</td>\n",
       "      <td>4.021375</td>\n",
       "      <td>1.178789</td>\n",
       "      <td>1.645458</td>\n",
       "      <td>2.306678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239758</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>3.757523</td>\n",
       "      <td>19.702022</td>\n",
       "      <td>14.196737</td>\n",
       "      <td>2.763761</td>\n",
       "      <td>2.166618</td>\n",
       "      <td>3.190374e-02</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>30.486938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.515046</td>\n",
       "      <td>-7.515046</td>\n",
       "      <td>-7.515046</td>\n",
       "      <td>-7.515046</td>\n",
       "      <td>3.757523</td>\n",
       "      <td>7.138082</td>\n",
       "      <td>6.684884</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>9.042205</td>\n",
       "      <td>10.276775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.545624</td>\n",
       "      <td>4.021375</td>\n",
       "      <td>5.313940</td>\n",
       "      <td>1.645458</td>\n",
       "      <td>2.306678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0</td>\n",
       "      <td>1.174935</td>\n",
       "      <td>22.166721</td>\n",
       "      <td>7.388907</td>\n",
       "      <td>19.702022</td>\n",
       "      <td>14.196737</td>\n",
       "      <td>2.763761</td>\n",
       "      <td>2.166618</td>\n",
       "      <td>3.192353e-02</td>\n",
       "      <td>7.136630</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>30.486938</td>\n",
       "      <td>33.545950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.136630</td>\n",
       "      <td>-14.651675</td>\n",
       "      <td>-14.651675</td>\n",
       "      <td>-14.651675</td>\n",
       "      <td>11.083360</td>\n",
       "      <td>7.138082</td>\n",
       "      <td>6.684884</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>9.042205</td>\n",
       "      <td>10.276775</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>5.545624</td>\n",
       "      <td>4.021375</td>\n",
       "      <td>5.046359</td>\n",
       "      <td>1.645458</td>\n",
       "      <td>2.306678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>0</td>\n",
       "      <td>3.207788</td>\n",
       "      <td>43.397331</td>\n",
       "      <td>10.849333</td>\n",
       "      <td>19.702022</td>\n",
       "      <td>14.196737</td>\n",
       "      <td>2.763761</td>\n",
       "      <td>2.166618</td>\n",
       "      <td>3.192377e-02</td>\n",
       "      <td>6.578935</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>30.486938</td>\n",
       "      <td>33.545950</td>\n",
       "      <td>35.717600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.578935</td>\n",
       "      <td>-13.715564</td>\n",
       "      <td>-21.230610</td>\n",
       "      <td>-21.230610</td>\n",
       "      <td>17.941143</td>\n",
       "      <td>10.849333</td>\n",
       "      <td>6.684884</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>10.276775</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.021375</td>\n",
       "      <td>4.652009</td>\n",
       "      <td>9.147936</td>\n",
       "      <td>2.306678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>0</td>\n",
       "      <td>6.567489</td>\n",
       "      <td>69.718287</td>\n",
       "      <td>13.943657</td>\n",
       "      <td>19.702022</td>\n",
       "      <td>14.196737</td>\n",
       "      <td>2.763761</td>\n",
       "      <td>2.166618</td>\n",
       "      <td>3.189254e-02</td>\n",
       "      <td>5.090346</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.486938</td>\n",
       "      <td>33.545950</td>\n",
       "      <td>35.717600</td>\n",
       "      <td>36.971061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.090346</td>\n",
       "      <td>-11.669281</td>\n",
       "      <td>-18.805911</td>\n",
       "      <td>-26.320956</td>\n",
       "      <td>23.775783</td>\n",
       "      <td>17.429572</td>\n",
       "      <td>6.684884</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>10.276775</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>4.021375</td>\n",
       "      <td>3.599418</td>\n",
       "      <td>8.155144</td>\n",
       "      <td>2.306678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R   C  time_step       u_in  u_out  area@AddMultiplyingDividing  u_in_cumsum@AddMultiplyingDividing  u_in_cummean@AddMultiplyingDividing  u_out0_mean@AddMultiplyingDividing  u_out0_max@AddMultiplyingDividing  u_out1_mean@AddMultiplyingDividing  u_out1_max@AddMultiplyingDividing  breath_time@AddBreathTimeAndUInTime  u_in_time@AddBreathTimeAndUInTime  R_dummy_20@RCDummry  R_dummy_5@RCDummry  R_dummy_50@RCDummry  C_dummy_10@RCDummry  C_dummy_20@RCDummry  C_dummy_50@RCDummry  u_in_lag1@LagFeatures  u_in_lag2@LagFeatures  u_in_lag3@LagFeatures  u_in_lag4@LagFeatures  u_in_lag-1@LagFeatures  u_in_lag-2@LagFeatures  u_in_lag-3@LagFeatures  u_in_lag-4@LagFeatures  u_out_lag1@LagFeatures  u_out_lag2@LagFeatures  u_out_lag3@LagFeatures  u_out_lag4@LagFeatures  u_in_lag1_diff@LagFeatures  u_in_lag2_diff@LagFeatures  u_in_lag3_diff@LagFeatures  u_in_lag4_diff@LagFeatures  u_in_rolling_mean2@LagFeatures  u_in_rolling_mean4@LagFeatures  u_in_rolling_mean10@LagFeatures  \\\n",
       "0   1          0  5  20   0.000000   0.000000      0                     0.000000                            0.000000                             0.000000                           19.702022                          14.196737                            2.763761                           2.166618                         6.623513e-07                           0.000001                    0                   1                    0                    0                    1                    0               0.000000               0.000000               0.000000                    0.0                7.515046               14.651675               21.230610               26.320956                     0.0                     0.0                     0.0                     0.0                    0.000000                    0.000000                    0.000000                    0.000000                        7.312916                        7.138082                         6.684884   \n",
       "1   2          0  5  20   0.031904   7.515046      0                     0.239758                            7.515046                             3.757523                           19.702022                          14.196737                            2.763761                           2.166618                         3.190374e-02                           7.515046                    0                   1                    0                    0                    1                    0               0.000000               0.000000               0.000000                    0.0               14.651675               21.230610               26.320956               30.486938                     0.0                     0.0                     0.0                     0.0                   -7.515046                   -7.515046                   -7.515046                   -7.515046                        3.757523                        7.138082                         6.684884   \n",
       "2   3          0  5  20   0.063827  14.651675      0                     1.174935                           22.166721                             7.388907                           19.702022                          14.196737                            2.763761                           2.166618                         3.192353e-02                           7.136630                    0                   1                    0                    0                    1                    0               7.515046               0.000000               0.000000                    0.0               21.230610               26.320956               30.486938               33.545950                     0.0                     0.0                     0.0                     0.0                   -7.136630                  -14.651675                  -14.651675                  -14.651675                       11.083360                        7.138082                         6.684884   \n",
       "3   4          0  5  20   0.095751  21.230610      0                     3.207788                           43.397331                            10.849333                           19.702022                          14.196737                            2.763761                           2.166618                         3.192377e-02                           6.578935                    0                   1                    0                    0                    1                    0              14.651675               7.515046               0.000000                    0.0               26.320956               30.486938               33.545950               35.717600                     0.0                     0.0                     0.0                     0.0                   -6.578935                  -13.715564                  -21.230610                  -21.230610                       17.941143                       10.849333                         6.684884   \n",
       "4   5          0  5  20   0.127644  26.320956      0                     6.567489                           69.718287                            13.943657                           19.702022                          14.196737                            2.763761                           2.166618                         3.189254e-02                           5.090346                    0                   1                    0                    0                    1                    0              21.230610              14.651675               7.515046                    0.0               30.486938               33.545950               35.717600               36.971061                     0.0                     0.0                     0.0                     0.0                   -5.090346                  -11.669281                  -18.805911                  -26.320956                       23.775783                       17.429572                         6.684884   \n",
       "\n",
       "   u_in_rolling_max2@LagFeatures  u_in_rolling_max4@LagFeatures  u_in_rolling_max10@LagFeatures  u_in_rolling_min2@LagFeatures  u_in_rolling_min4@LagFeatures  u_in_rolling_min10@LagFeatures  u_in_rolling_std2@LagFeatures  u_in_rolling_std4@LagFeatures  u_in_rolling_std10@LagFeatures  \n",
       "0                       8.146446                       9.042205                       10.276775                       6.479387                       5.545624                        4.021375                       1.178789                       1.645458                        2.306678  \n",
       "1                       7.515046                       9.042205                       10.276775                       0.000000                       5.545624                        4.021375                       5.313940                       1.645458                        2.306678  \n",
       "2                      14.651675                       9.042205                       10.276775                       7.515046                       5.545624                        4.021375                       5.046359                       1.645458                        2.306678  \n",
       "3                      21.230610                      21.230610                       10.276775                      14.651675                       0.000000                        4.021375                       4.652009                       9.147936                        2.306678  \n",
       "4                      26.320956                      26.320956                       10.276775                      21.230610                       7.515046                        4.021375                       3.599418                       8.155144                        2.306678  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_blocks(input_df, blocks, y=None, test=False):\n",
    "    out_df = pd.DataFrame()\n",
    "\n",
    "    print(decorate('start run blocks...'))\n",
    "\n",
    "    with Timer(prefix='run test={}'.format(test)):\n",
    "        for block in feature_blocks:\n",
    "            with Timer(prefix='out_df shape: {} \\t- {}'.format(out_df.shape, str(block))):\n",
    "                if not test:\n",
    "                    out_i = block.fit(input_df.copy(), y=y)\n",
    "                else:\n",
    "                    out_i = block.transform(input_df.copy())\n",
    "\n",
    "            assert len(input_df) == len(out_i), block\n",
    "            name = block.__class__.__name__\n",
    "            out_df = pd.concat([out_df, out_i.add_suffix(f'@{name}')], axis=1)\n",
    "    print(f\"out_df shape: {out_df.shape}\")\n",
    "\n",
    "    return pd.concat([input_df, out_df], axis=1)\n",
    "\n",
    "train = run_blocks(train, blocks=feature_blocks)\n",
    "test = run_blocks(test, blocks=feature_blocks, test=True)\n",
    "CFG.cont_seq_cols = list(set(CFG.cont_seq_cols))\n",
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480b081-f985-4f16-bb51-5748f27d437c",
   "metadata": {},
   "source": [
    "# normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9b5117-dfdf-4a38-ad1e-1c16b60e1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col_order = [\"u_out\"] + train.columns.drop(\"u_out\").tolist()\n",
    "test_col_order = [\"u_out\"] + test.columns.drop(\"u_out\").tolist()\n",
    "train = train[train_col_order]\n",
    "test = test[test_col_order]\n",
    "# scaler = RobustScaler()\n",
    "# scaler_targets = [col for col in CFG.cont_seq_cols if col != \"u_out\"]\n",
    "# print(f\"Apply Standerd Scaler these columns: {scaler_targets}\")\n",
    "# for scaler_target in tqdm(scaler_targets):\n",
    "#     scaler.fit(train.loc[:,[scaler_target]])\n",
    "#     train.loc[:,[scaler_target]] = scaler.transform(train.loc[:,[scaler_target]])\n",
    "#     test.loc[:,[scaler_target]] = scaler.transform(test.loc[:,[scaler_target]])\n",
    "# display(train.head())\n",
    "# display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf89c15-d112-42b2-92f6-9135dbbe7177",
   "metadata": {},
   "source": [
    "# reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf170ebc-296b-4e1e-8ef9-2b31eb771596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "(6036000, 48)\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(set(train.drop([\"id\", \"breath_id\", \"pressure\"], axis=1).columns) - set(CFG.cont_seq_cols))\n",
    "print(train.drop([\"id\", \"breath_id\", \"pressure\"], axis=1).shape)\n",
    "print(len(CFG.cont_seq_cols))\n",
    "\n",
    "X = np.float32(train.drop([\"id\", \"breath_id\", \"pressure\"], axis=1)).reshape(-1, 80, len(CFG.cont_seq_cols))\n",
    "y = np.float32(train[\"pressure\"]).reshape(-1, 80, 1)\n",
    "X_test = np.float32(test.drop([\"id\", \"breath_id\"], axis=1)).reshape(-1, 80, len(CFG.cont_seq_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd6dd6-27c0-4499-a1f4-8ac582238df7",
   "metadata": {},
   "source": [
    "# cv split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9e8779-c77b-457c-8d65-63888cb98327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "# Fold = GroupKFold(n_splits=5)\n",
    "# groups = train['breath_id'].values\n",
    "# for n, (train_index, val_index) in enumerate(Fold.split(train, train['pressure'], groups)):\n",
    "#     train.loc[val_index, 'fold'] = int(n)\n",
    "# train['fold'] = train['fold'].astype(int)\n",
    "# print(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed2f72-9b32-472f-a32f-bfab28b02e0b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "348def8c-85cc-4bba-96dd-4c068795ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "# class TrainDataset(Dataset):\n",
    "#     def __init__(self, df):\n",
    "#         self.df = df\n",
    "#         self.groups = df.groupby('breath_id').groups\n",
    "#         self.keys = list(self.groups.keys())\n",
    "#         \n",
    "#     def __len__(self):\n",
    "#         return len(self.groups)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         indexes = self.groups[self.keys[idx]]\n",
    "#         df = self.df.iloc[indexes]\n",
    "#         cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n",
    "#         u_out = torch.LongTensor(df['u_out'].values)\n",
    "#         label = torch.FloatTensor(df['pressure'].values)\n",
    "#         return cont_seq_x, u_out, label\n",
    "#     \n",
    "# \n",
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, df):\n",
    "#         self.df = df\n",
    "#         self.groups = df.groupby('breath_id').groups\n",
    "#         self.keys = list(self.groups.keys())\n",
    "#         \n",
    "#     def __len__(self):\n",
    "#         return len(self.groups)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         indexes = self.groups[self.keys[idx]]\n",
    "#         df = self.df.iloc[indexes]\n",
    "#         cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n",
    "#         return cont_seq_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad8259-e25d-4455-ba22-f23326b4f656",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "231f1614-9a8f-4db3-b8cf-177807cc1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Loss_masked(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, preds, y, u_out):\n",
    "\n",
    "        mask = 1 - u_out\n",
    "        mae = torch.abs(mask * (y - preds))\n",
    "        mae = torch.sum(mae) / torch.sum(mask)\n",
    "\n",
    "        return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35dbb6-3ce0-4a88-a7fd-2c7708f9838a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30daacd7-cb5b-40cc-8be2-5d29a7f52877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LSTM(1024, 512, batch_first=True, bidirectional=True)\n",
      "init LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
      "init LSTM(512, 128, batch_first=True, bidirectional=True)\n",
      "init LSTM(256, 64, batch_first=True, bidirectional=True)\n",
      "init LSTM(128, 32, batch_first=True, bidirectional=True)\n",
      "CustomModel(\n",
      "  (seq_emb): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=1024, bias=True)\n",
      "    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU()\n",
      "  )\n",
      "  (lstm1): LSTM(1024, 512, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
      "  (lstm3): LSTM(512, 128, batch_first=True, bidirectional=True)\n",
      "  (lstm4): LSTM(256, 64, batch_first=True, bidirectional=True)\n",
      "  (lstm5): LSTM(128, 32, batch_first=True, bidirectional=True)\n",
      "  (head): Sequential(\n",
      "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): GELU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.hidden_size = cfg.hidden_size\n",
    "        self.seq_emb = nn.Sequential(\n",
    "            nn.Linear(len(cfg.cont_seq_cols), self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(0.1),\n",
    "        )\n",
    "        self.lstm1 = nn.LSTM(self.hidden_size, self.hidden_size//2, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_size//2 * 2, self.hidden_size//4, batch_first=True, bidirectional=True)\n",
    "        self.lstm3 = nn.LSTM(self.hidden_size//4 * 2, self.hidden_size//8, batch_first=True, bidirectional=True)\n",
    "        self.lstm4 = nn.LSTM(self.hidden_size//8 * 2, self.hidden_size//16, batch_first=True, bidirectional=True)\n",
    "        self.lstm5 = nn.LSTM(self.hidden_size//16 * 2, self.hidden_size//32, batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Sequential(\n",
    "            # nn.Linear(self.hidden_size//8 * 2, self.hidden_size//8 * 2),\n",
    "            nn.LayerNorm(self.hidden_size//32 * 2),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(0.),\n",
    "            nn.Linear(self.hidden_size//32 * 2, 1),\n",
    "        )\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.LSTM):\n",
    "                print(f'init {m}')\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        nn.init.normal_(param.data)\n",
    "            elif isinstance(m, nn.GRU):\n",
    "                print(f\"init {m}\")\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        init.normal_(param.data)\n",
    "\n",
    "    def forward(self, cont_seq_x):\n",
    "        bs = cont_seq_x.size(0)\n",
    "        seq_emb = self.seq_emb(cont_seq_x)\n",
    "        seq_emb, _ = self.lstm1(seq_emb)\n",
    "        seq_emb, _ = self.lstm2(seq_emb)\n",
    "        seq_emb, _ = self.lstm3(seq_emb)\n",
    "        seq_emb, _ = self.lstm4(seq_emb)\n",
    "        seq_emb, _ = self.lstm5(seq_emb)\n",
    "        output = self.head(seq_emb)#.view(bs, -1)\n",
    "        return output\n",
    "print(CustomModel(CFG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd76d6-fe03-40ee-b27b-7df4a2bbab36",
   "metadata": {},
   "source": [
    "# helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e1185c-1c79-4240-9022-4c80a5de62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# helper function\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time()\n",
    "    for step, (inputs, y) in enumerate(train_loader):\n",
    "        inputs, y = inputs.to(device), y.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "        with autocast():\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, y, inputs[:,:,0].reshape(-1,80,1))\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if CFG.apex:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            if CFG.apex:\n",
    "                scaler.step(optimizer)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            lr = 0\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "                lr = scheduler.get_lr()[0]\n",
    "        if CFG.apex:\n",
    "            scaler.update()\n",
    "        end = time()\n",
    "        wandb.log({f\"[fold{fold}] loss\": losses.val, \n",
    "                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = end = time()\n",
    "    for step, (inputs, y) in enumerate(valid_loader):\n",
    "        inputs, y = inputs.to(device), y.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "        with torch.no_grad():\n",
    "            pred = model(inputs)\n",
    "        loss = criterion(pred, y, inputs[:,:,0].reshape(-1,80,1))\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        end = time()\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for step, (cont_seq_x) in tk0:\n",
    "        cont_seq_x = cont_seq_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cont_seq_x)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds\n",
    "\n",
    "def find_nearest(prediction):\n",
    "    '''\n",
    "    予測値は離散値であるため、学習データにある最も近い離散値に置き換える\n",
    "    '''\n",
    "    insert_idx = np.searchsorted(sorted_pressures, prediction)\n",
    "    if insert_idx == total_pressures_len:\n",
    "        # If the predicted value is bigger than the highest pressure in the train dataset,\n",
    "        # return the max value.\n",
    "        return sorted_pressures[-1]\n",
    "    elif insert_idx == 0:\n",
    "        # Same control but for the lower bound.\n",
    "        return sorted_pressures[0]\n",
    "    lower_val = sorted_pressures[insert_idx - 1]\n",
    "    upper_val = sorted_pressures[insert_idx]\n",
    "    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af77e2d-2ded-44c5-ad5a-069a81f7f3d6",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "487dd41a-ec3f-4cfc-8f20-7cc012c33556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      2,      3, ..., 125743, 125745, 125749])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"breath_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4697430b-06c7-482c-af27-31db3f6f7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold, trn_idx, val_idx):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    #trn_idx = folds[folds['fold'] != fold].index\n",
    "    #val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = X[trn_idx]\n",
    "    valid_folds = X[val_idx]\n",
    "    groups = train[\"breath_id\"].unique()[val_idx]\n",
    "    oof_folds = train[train[\"breath_id\"].isin(groups)].reset_index(drop=True)\n",
    "    y_train = y[trn_idx]\n",
    "    y_true = y[val_idx]\n",
    "\n",
    "    # train_dataset = TrainDataset(train_folds)\n",
    "    # valid_dataset = TrainDataset(valid_folds)\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(train_folds),\n",
    "        torch.from_numpy(y_train)\n",
    "    )\n",
    "    valid_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(valid_folds),\n",
    "        torch.from_numpy(y_true)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.0008, eps=1e-08)\n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif CFG.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=CFG.num_cycles\n",
    "            )\n",
    "        elif CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    #if CFG.apex:\n",
    "    #    model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = L1Loss_masked()\n",
    "\n",
    "    best_score = np.inf\n",
    "\n",
    "    avg_losses = []\n",
    "    avg_val_losses = []\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "        #avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, None, device)\n",
    "        avg_losses.append(avg_loss)\n",
    "        \n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        avg_val_losses.append(avg_val_loss)\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = avg_val_loss #get_score(y_true[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "\n",
    "        elapsed = time() - start_time\n",
    "        \n",
    "        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                   f\"[fold{fold}] score\": score})\n",
    "\n",
    "        best_notice = \"\"\n",
    "        if score < best_score:\n",
    "            best_notice = \"Best Score\"\n",
    "            best_score = score\n",
    "            # LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f\"fold{fold}_best.pth\")\n",
    "    \n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s, lr: {optimizer.param_groups[0][\"lr\"]:.5f}, MAE Score: {score:.4f}, {best_notice}')\n",
    "\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.plot(avg_losses, label=\"Train Loss\")\n",
    "    plt.plot(avg_val_losses, label=\"Train Loss\")\n",
    "    plt.title(f\"Fold {fold + 1} - Best score {best_score:.4f}\", size=18)\n",
    "    plt.show()\n",
    "\n",
    "    preds = torch.load(OUTPUT_DIR+f\"fold{fold}_best.pth\", map_location=torch.device('cpu'))['preds']\n",
    "    oof_folds['preds'] = preds.flatten()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return oof_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d9dc8-48e0-48af-94ae-891b83c01544",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c61d23-e3c8-4ac5-b98d-5f8adfecb26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare: 1.train 2.test\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df['pressure'].values\n",
    "        non_expiratory_phase_val_idx = result_df[result_df['u_out'] == 0].index # The expiratory phase is not scored\n",
    "        score = get_score(labels[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "        LOGGER.info(f'Score (without expiratory phase): {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        kfold = KFold(n_splits=CFG.n_fold, random_state=42, shuffle=True)\n",
    "        for fold, (trn_idx, val_idx) in enumerate(kfold.split(X=X, y=y)):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(X, fold, trn_idx, val_idx)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "        for i, breath_id in enumerate(oof_df[\"breath_id\"].unique()):\n",
    "            oof_df[oof_df[\"breath_id\"]==breath_id].plot(x=\"time_step\", y=[\"preds\", \"pressure\", \"u_out\"], figsize=(16, 5))\n",
    "            plt.show()\n",
    "            if i == 10:\n",
    "                break\n",
    "    \n",
    "    if CFG.inference:\n",
    "        test_loader = torch.utils.data.DataLoader(X_test, batch_size=512, shuffle=False, pin_memory=True)\n",
    "        #test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size * 2, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
    "        for fold in CFG.trn_fold:\n",
    "            model = CustomModel(CFG)\n",
    "            path = OUTPUT_DIR+f\"fold{fold}_best.pth\"\n",
    "            state = torch.load(path, map_location=torch.device('cpu'))\n",
    "            model.load_state_dict(state['model'])\n",
    "            predictions = inference_fn(test_loader, model, device)\n",
    "            test[f'fold{fold}'] = predictions\n",
    "            del state, predictions; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        # submission\n",
    "        test['pressure'] = test[[f'fold{fold}' for fold in CFG.trn_fold]].mean(1)\n",
    "        test['pressure'] = test['pressure'].apply(find_nearest)\n",
    "        test[['id', 'pressure']+[f'fold{fold}' for fold in CFG.trn_fold]].to_csv(OUTPUT_DIR+'raw_submission_mean.csv', index=False)\n",
    "        test[['id', 'pressure']].to_csv(OUTPUT_DIR+'submission_mean.csv', index=False)\n",
    "        \n",
    "        test['pressure'] = test[[f'fold{fold}' for fold in CFG.trn_fold]].median(1)\n",
    "        test['pressure'] = test['pressure'].apply(find_nearest)\n",
    "        test[['id', 'pressure']+[f'fold{fold}' for fold in CFG.trn_fold]].to_csv(OUTPUT_DIR+'raw_submission_median.csv', index=False)\n",
    "        test[['id', 'pressure']].to_csv(OUTPUT_DIR+'submission_median.csv', index=False)\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1960c-990b-4a2b-abc1-25e6f70b92f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LSTM(1024, 512, batch_first=True, bidirectional=True)\n",
      "init LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
      "init LSTM(512, 128, batch_first=True, bidirectional=True)\n",
      "init LSTM(256, 64, batch_first=True, bidirectional=True)\n",
      "init LSTM(128, 32, batch_first=True, bidirectional=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 10.6084  avg_val_loss: 5.8720  time: 21s, lr: 0.00099, MAE Score: 5.8720, Best Score\n",
      "Epoch 2 - avg_train_loss: 3.7477  avg_val_loss: 2.5775  time: 21s, lr: 0.00098, MAE Score: 2.5775, Best Score\n",
      "Epoch 3 - avg_train_loss: 2.0132  avg_val_loss: 1.7435  time: 21s, lr: 0.00095, MAE Score: 1.7435, Best Score\n",
      "Epoch 4 - avg_train_loss: 1.5138  avg_val_loss: 1.5027  time: 22s, lr: 0.00091, MAE Score: 1.5027, Best Score\n",
      "Epoch 5 - avg_train_loss: 1.3095  avg_val_loss: 1.2920  time: 21s, lr: 0.00086, MAE Score: 1.2920, Best Score\n",
      "Epoch 6 - avg_train_loss: 1.1459  avg_val_loss: 1.0735  time: 21s, lr: 0.00080, MAE Score: 1.0735, Best Score\n",
      "Epoch 7 - avg_train_loss: 1.0398  avg_val_loss: 1.0974  time: 21s, lr: 0.00073, MAE Score: 1.0974, \n",
      "Epoch 8 - avg_train_loss: 0.9427  avg_val_loss: 0.8891  time: 21s, lr: 0.00066, MAE Score: 0.8891, Best Score\n",
      "Epoch 9 - avg_train_loss: 0.8471  avg_val_loss: 0.7997  time: 21s, lr: 0.00058, MAE Score: 0.7997, Best Score\n",
      "Epoch 10 - avg_train_loss: 0.7675  avg_val_loss: 0.7452  time: 21s, lr: 0.00051, MAE Score: 0.7452, Best Score\n",
      "Epoch 11 - avg_train_loss: 0.7265  avg_val_loss: 0.7483  time: 21s, lr: 0.00043, MAE Score: 0.7483, \n",
      "Epoch 12 - avg_train_loss: 0.6941  avg_val_loss: 0.7056  time: 21s, lr: 0.00035, MAE Score: 0.7056, Best Score\n",
      "Epoch 13 - avg_train_loss: 0.6607  avg_val_loss: 0.6814  time: 21s, lr: 0.00028, MAE Score: 0.6814, Best Score\n",
      "Epoch 14 - avg_train_loss: 0.6345  avg_val_loss: 0.6230  time: 21s, lr: 0.00021, MAE Score: 0.6230, Best Score\n",
      "Epoch 15 - avg_train_loss: 0.5984  avg_val_loss: 0.6096  time: 21s, lr: 0.00015, MAE Score: 0.6096, Best Score\n",
      "Epoch 16 - avg_train_loss: 0.5764  avg_val_loss: 0.5842  time: 21s, lr: 0.00010, MAE Score: 0.5842, Best Score\n",
      "Epoch 17 - avg_train_loss: 0.5551  avg_val_loss: 0.5723  time: 21s, lr: 0.00006, MAE Score: 0.5723, Best Score\n",
      "Epoch 18 - avg_train_loss: 0.5328  avg_val_loss: 0.5549  time: 21s, lr: 0.00003, MAE Score: 0.5549, Best Score\n",
      "Epoch 19 - avg_train_loss: 0.5249  avg_val_loss: 0.5512  time: 21s, lr: 0.00002, MAE Score: 0.5512, Best Score\n",
      "Epoch 20 - avg_train_loss: 0.5189  avg_val_loss: 0.5449  time: 21s, lr: 0.00100, MAE Score: 0.5449, Best Score\n",
      "Epoch 21 - avg_train_loss: 0.8793  avg_val_loss: 0.9230  time: 21s, lr: 0.00099, MAE Score: 0.9230, \n",
      "Epoch 22 - avg_train_loss: 0.8653  avg_val_loss: 0.7618  time: 21s, lr: 0.00098, MAE Score: 0.7618, \n",
      "Epoch 23 - avg_train_loss: 0.7958  avg_val_loss: 0.7454  time: 21s, lr: 0.00095, MAE Score: 0.7454, \n",
      "Epoch 24 - avg_train_loss: 0.7147  avg_val_loss: 0.7123  time: 22s, lr: 0.00091, MAE Score: 0.7123, \n",
      "Epoch 25 - avg_train_loss: 0.6744  avg_val_loss: 0.6412  time: 21s, lr: 0.00086, MAE Score: 0.6412, \n",
      "Epoch 26 - avg_train_loss: 0.6477  avg_val_loss: 0.6924  time: 21s, lr: 0.00080, MAE Score: 0.6924, \n",
      "Epoch 27 - avg_train_loss: 0.6092  avg_val_loss: 0.5714  time: 21s, lr: 0.00073, MAE Score: 0.5714, \n",
      "Epoch 28 - avg_train_loss: 0.5682  avg_val_loss: 0.6308  time: 22s, lr: 0.00066, MAE Score: 0.6308, \n",
      "Epoch 29 - avg_train_loss: 0.5553  avg_val_loss: 0.5223  time: 21s, lr: 0.00058, MAE Score: 0.5223, Best Score\n",
      "Epoch 30 - avg_train_loss: 0.4693  avg_val_loss: 0.4638  time: 21s, lr: 0.00051, MAE Score: 0.4638, Best Score\n",
      "Epoch 31 - avg_train_loss: 0.4441  avg_val_loss: 0.4525  time: 21s, lr: 0.00043, MAE Score: 0.4525, Best Score\n",
      "Epoch 32 - avg_train_loss: 0.4268  avg_val_loss: 0.4406  time: 21s, lr: 0.00035, MAE Score: 0.4406, Best Score\n",
      "Epoch 33 - avg_train_loss: 0.4232  avg_val_loss: 0.4494  time: 21s, lr: 0.00028, MAE Score: 0.4494, \n",
      "Epoch 34 - avg_train_loss: 0.4221  avg_val_loss: 0.4296  time: 21s, lr: 0.00021, MAE Score: 0.4296, Best Score\n",
      "Epoch 35 - avg_train_loss: 0.3923  avg_val_loss: 0.4030  time: 21s, lr: 0.00015, MAE Score: 0.4030, Best Score\n",
      "Epoch 36 - avg_train_loss: 0.3674  avg_val_loss: 0.3910  time: 21s, lr: 0.00010, MAE Score: 0.3910, Best Score\n",
      "Epoch 37 - avg_train_loss: 0.3501  avg_val_loss: 0.3783  time: 21s, lr: 0.00006, MAE Score: 0.3783, Best Score\n",
      "Epoch 38 - avg_train_loss: 0.3359  avg_val_loss: 0.3711  time: 21s, lr: 0.00003, MAE Score: 0.3711, Best Score\n",
      "Epoch 39 - avg_train_loss: 0.3249  avg_val_loss: 0.3627  time: 21s, lr: 0.00002, MAE Score: 0.3627, Best Score\n",
      "Epoch 40 - avg_train_loss: 0.3185  avg_val_loss: 0.3605  time: 21s, lr: 0.00100, MAE Score: 0.3605, Best Score\n",
      "Epoch 41 - avg_train_loss: 0.5294  avg_val_loss: 0.5438  time: 21s, lr: 0.00099, MAE Score: 0.5438, \n",
      "Epoch 42 - avg_train_loss: 0.4313  avg_val_loss: 0.4413  time: 21s, lr: 0.00098, MAE Score: 0.4413, \n",
      "Epoch 43 - avg_train_loss: 0.4546  avg_val_loss: 0.6484  time: 21s, lr: 0.00095, MAE Score: 0.6484, \n",
      "Epoch 44 - avg_train_loss: 0.5119  avg_val_loss: 0.4819  time: 21s, lr: 0.00091, MAE Score: 0.4819, \n",
      "Epoch 45 - avg_train_loss: 0.4944  avg_val_loss: 0.5392  time: 21s, lr: 0.00086, MAE Score: 0.5392, \n",
      "Epoch 46 - avg_train_loss: 0.4853  avg_val_loss: 0.4381  time: 21s, lr: 0.00080, MAE Score: 0.4381, \n",
      "Epoch 47 - avg_train_loss: 0.4312  avg_val_loss: 0.4649  time: 21s, lr: 0.00073, MAE Score: 0.4649, \n",
      "Epoch 48 - avg_train_loss: 0.4261  avg_val_loss: 0.5026  time: 21s, lr: 0.00066, MAE Score: 0.5026, \n",
      "Epoch 49 - avg_train_loss: 0.4137  avg_val_loss: 0.4728  time: 21s, lr: 0.00058, MAE Score: 0.4728, \n",
      "Epoch 50 - avg_train_loss: 0.3948  avg_val_loss: 0.4009  time: 21s, lr: 0.00051, MAE Score: 0.4009, \n",
      "Epoch 51 - avg_train_loss: 0.3674  avg_val_loss: 0.3530  time: 21s, lr: 0.00043, MAE Score: 0.3530, Best Score\n",
      "Epoch 52 - avg_train_loss: 0.3233  avg_val_loss: 0.3614  time: 21s, lr: 0.00035, MAE Score: 0.3614, \n",
      "Epoch 53 - avg_train_loss: 0.3343  avg_val_loss: 0.3750  time: 21s, lr: 0.00028, MAE Score: 0.3750, \n",
      "Epoch 54 - avg_train_loss: 0.3163  avg_val_loss: 0.3404  time: 21s, lr: 0.00021, MAE Score: 0.3404, Best Score\n",
      "Epoch 55 - avg_train_loss: 0.2952  avg_val_loss: 0.3219  time: 21s, lr: 0.00015, MAE Score: 0.3219, Best Score\n",
      "Epoch 56 - avg_train_loss: 0.2788  avg_val_loss: 0.3167  time: 21s, lr: 0.00010, MAE Score: 0.3167, Best Score\n",
      "Epoch 57 - avg_train_loss: 0.2670  avg_val_loss: 0.3064  time: 21s, lr: 0.00006, MAE Score: 0.3064, Best Score\n",
      "Epoch 58 - avg_train_loss: 0.2572  avg_val_loss: 0.3003  time: 21s, lr: 0.00003, MAE Score: 0.3003, Best Score\n",
      "Epoch 59 - avg_train_loss: 0.2495  avg_val_loss: 0.2966  time: 21s, lr: 0.00002, MAE Score: 0.2966, Best Score\n",
      "Epoch 60 - avg_train_loss: 0.2447  avg_val_loss: 0.2953  time: 21s, lr: 0.00100, MAE Score: 0.2953, Best Score\n",
      "Epoch 61 - avg_train_loss: 0.4163  avg_val_loss: 0.4443  time: 21s, lr: 0.00099, MAE Score: 0.4443, \n",
      "Epoch 62 - avg_train_loss: 0.4184  avg_val_loss: 0.4596  time: 21s, lr: 0.00098, MAE Score: 0.4596, \n",
      "Epoch 63 - avg_train_loss: 0.4145  avg_val_loss: 0.4182  time: 21s, lr: 0.00095, MAE Score: 0.4182, \n",
      "Epoch 64 - avg_train_loss: 0.5086  avg_val_loss: 0.8547  time: 21s, lr: 0.00091, MAE Score: 0.8547, \n",
      "Epoch 65 - avg_train_loss: 0.5240  avg_val_loss: 0.5174  time: 21s, lr: 0.00086, MAE Score: 0.5174, \n",
      "Epoch 66 - avg_train_loss: 0.4745  avg_val_loss: 0.4314  time: 21s, lr: 0.00080, MAE Score: 0.4314, \n",
      "Epoch 67 - avg_train_loss: 0.4212  avg_val_loss: 0.4174  time: 21s, lr: 0.00073, MAE Score: 0.4174, \n",
      "Epoch 68 - avg_train_loss: 0.3855  avg_val_loss: 0.3975  time: 21s, lr: 0.00066, MAE Score: 0.3975, \n",
      "Epoch 69 - avg_train_loss: 0.3642  avg_val_loss: 0.3963  time: 21s, lr: 0.00058, MAE Score: 0.3963, \n",
      "Epoch 70 - avg_train_loss: 0.3411  avg_val_loss: 0.3667  time: 21s, lr: 0.00051, MAE Score: 0.3667, \n",
      "Epoch 71 - avg_train_loss: 0.3160  avg_val_loss: 0.3479  time: 21s, lr: 0.00043, MAE Score: 0.3479, \n",
      "Epoch 72 - avg_train_loss: 0.2950  avg_val_loss: 0.3106  time: 21s, lr: 0.00035, MAE Score: 0.3106, \n",
      "Epoch 73 - avg_train_loss: 0.2585  avg_val_loss: 0.2983  time: 21s, lr: 0.00028, MAE Score: 0.2983, \n",
      "Epoch 74 - avg_train_loss: 0.2485  avg_val_loss: 0.2830  time: 21s, lr: 0.00021, MAE Score: 0.2830, Best Score\n",
      "Epoch 75 - avg_train_loss: 0.2385  avg_val_loss: 0.2853  time: 21s, lr: 0.00015, MAE Score: 0.2853, \n",
      "Epoch 76 - avg_train_loss: 0.2307  avg_val_loss: 0.2738  time: 21s, lr: 0.00010, MAE Score: 0.2738, Best Score\n",
      "Epoch 77 - avg_train_loss: 0.2227  avg_val_loss: 0.2704  time: 21s, lr: 0.00006, MAE Score: 0.2704, Best Score\n",
      "Epoch 78 - avg_train_loss: 0.2169  avg_val_loss: 0.2657  time: 21s, lr: 0.00003, MAE Score: 0.2657, Best Score\n",
      "Epoch 79 - avg_train_loss: 0.2120  avg_val_loss: 0.2653  time: 21s, lr: 0.00002, MAE Score: 0.2653, Best Score\n",
      "Epoch 80 - avg_train_loss: 0.2087  avg_val_loss: 0.2630  time: 21s, lr: 0.00100, MAE Score: 0.2630, Best Score\n",
      "Epoch 81 - avg_train_loss: 0.2962  avg_val_loss: 0.3028  time: 21s, lr: 0.00099, MAE Score: 0.3028, \n",
      "Epoch 82 - avg_train_loss: 0.4006  avg_val_loss: 0.4915  time: 21s, lr: 0.00098, MAE Score: 0.4915, \n",
      "Epoch 83 - avg_train_loss: 0.4527  avg_val_loss: 0.5195  time: 21s, lr: 0.00095, MAE Score: 0.5195, \n",
      "Epoch 84 - avg_train_loss: 0.4221  avg_val_loss: 0.4212  time: 21s, lr: 0.00091, MAE Score: 0.4212, \n",
      "Epoch 85 - avg_train_loss: 0.3913  avg_val_loss: 0.5798  time: 21s, lr: 0.00086, MAE Score: 0.5798, \n",
      "Epoch 86 - avg_train_loss: 0.3733  avg_val_loss: 0.3737  time: 21s, lr: 0.00080, MAE Score: 0.3737, \n",
      "Epoch 87 - avg_train_loss: 0.3391  avg_val_loss: 0.3849  time: 21s, lr: 0.00073, MAE Score: 0.3849, \n",
      "Epoch 88 - avg_train_loss: 0.3236  avg_val_loss: 0.3388  time: 21s, lr: 0.00066, MAE Score: 0.3388, \n",
      "Epoch 89 - avg_train_loss: 0.3071  avg_val_loss: 0.3529  time: 21s, lr: 0.00058, MAE Score: 0.3529, \n",
      "Epoch 90 - avg_train_loss: 0.2838  avg_val_loss: 0.2883  time: 21s, lr: 0.00051, MAE Score: 0.2883, \n",
      "Epoch 91 - avg_train_loss: 0.2428  avg_val_loss: 0.2813  time: 21s, lr: 0.00043, MAE Score: 0.2813, \n",
      "Epoch 92 - avg_train_loss: 0.2297  avg_val_loss: 0.2671  time: 21s, lr: 0.00035, MAE Score: 0.2671, \n",
      "Epoch 93 - avg_train_loss: 0.2205  avg_val_loss: 0.2667  time: 21s, lr: 0.00028, MAE Score: 0.2667, \n",
      "Epoch 94 - avg_train_loss: 0.2142  avg_val_loss: 0.2566  time: 21s, lr: 0.00021, MAE Score: 0.2566, Best Score\n",
      "Epoch 95 - avg_train_loss: 0.2062  avg_val_loss: 0.2605  time: 21s, lr: 0.00015, MAE Score: 0.2605, \n",
      "Epoch 96 - avg_train_loss: 0.2013  avg_val_loss: 0.2563  time: 21s, lr: 0.00010, MAE Score: 0.2563, Best Score\n",
      "Epoch 97 - avg_train_loss: 0.1986  avg_val_loss: 0.2496  time: 21s, lr: 0.00006, MAE Score: 0.2496, Best Score\n",
      "Epoch 98 - avg_train_loss: 0.1894  avg_val_loss: 0.2462  time: 21s, lr: 0.00003, MAE Score: 0.2462, Best Score\n",
      "Epoch 99 - avg_train_loss: 0.1833  avg_val_loss: 0.2432  time: 21s, lr: 0.00002, MAE Score: 0.2432, Best Score\n",
      "Epoch 100 - avg_train_loss: 0.1794  avg_val_loss: 0.2411  time: 21s, lr: 0.00100, MAE Score: 0.2411, Best Score\n",
      "Epoch 101 - avg_train_loss: 0.3206  avg_val_loss: 0.3264  time: 21s, lr: 0.00099, MAE Score: 0.3264, \n",
      "Epoch 102 - avg_train_loss: 0.2911  avg_val_loss: 0.3348  time: 21s, lr: 0.00098, MAE Score: 0.3348, \n",
      "Epoch 103 - avg_train_loss: 0.3033  avg_val_loss: 0.3319  time: 21s, lr: 0.00095, MAE Score: 0.3319, \n",
      "Epoch 104 - avg_train_loss: 0.3040  avg_val_loss: 0.3156  time: 21s, lr: 0.00091, MAE Score: 0.3156, \n",
      "Epoch 105 - avg_train_loss: 0.2488  avg_val_loss: 0.2840  time: 21s, lr: 0.00086, MAE Score: 0.2840, \n",
      "Epoch 106 - avg_train_loss: 0.2348  avg_val_loss: 0.2857  time: 21s, lr: 0.00080, MAE Score: 0.2857, \n",
      "Epoch 107 - avg_train_loss: 0.2315  avg_val_loss: 0.3060  time: 21s, lr: 0.00073, MAE Score: 0.3060, \n",
      "Epoch 108 - avg_train_loss: 0.2380  avg_val_loss: 0.3059  time: 21s, lr: 0.00066, MAE Score: 0.3059, \n",
      "Epoch 109 - avg_train_loss: 0.2223  avg_val_loss: 0.2652  time: 21s, lr: 0.00058, MAE Score: 0.2652, \n",
      "Epoch 110 - avg_train_loss: 0.2190  avg_val_loss: 0.2762  time: 21s, lr: 0.00051, MAE Score: 0.2762, \n",
      "Epoch 111 - avg_train_loss: 0.2074  avg_val_loss: 0.2562  time: 21s, lr: 0.00043, MAE Score: 0.2562, \n",
      "Epoch 112 - avg_train_loss: 0.2007  avg_val_loss: 0.2552  time: 21s, lr: 0.00035, MAE Score: 0.2552, \n",
      "Epoch 113 - avg_train_loss: 0.1913  avg_val_loss: 0.2538  time: 21s, lr: 0.00028, MAE Score: 0.2538, \n",
      "Epoch 114 - avg_train_loss: 0.1848  avg_val_loss: 0.2474  time: 21s, lr: 0.00021, MAE Score: 0.2474, \n",
      "Epoch 115 - avg_train_loss: 0.1771  avg_val_loss: 0.2387  time: 21s, lr: 0.00015, MAE Score: 0.2387, Best Score\n",
      "Epoch 116 - avg_train_loss: 0.1708  avg_val_loss: 0.2343  time: 21s, lr: 0.00010, MAE Score: 0.2343, Best Score\n",
      "Epoch 117 - avg_train_loss: 0.1640  avg_val_loss: 0.2277  time: 21s, lr: 0.00006, MAE Score: 0.2277, Best Score\n",
      "Epoch 118 - avg_train_loss: 0.1594  avg_val_loss: 0.2229  time: 21s, lr: 0.00003, MAE Score: 0.2229, Best Score\n",
      "Epoch 119 - avg_train_loss: 0.1559  avg_val_loss: 0.2218  time: 21s, lr: 0.00002, MAE Score: 0.2218, Best Score\n",
      "Epoch 120 - avg_train_loss: 0.1533  avg_val_loss: 0.2219  time: 21s, lr: 0.00100, MAE Score: 0.2219, \n",
      "Epoch 121 - avg_train_loss: 0.2508  avg_val_loss: 0.4894  time: 21s, lr: 0.00099, MAE Score: 0.4894, \n",
      "Epoch 122 - avg_train_loss: 0.3743  avg_val_loss: 0.5211  time: 21s, lr: 0.00098, MAE Score: 0.5211, \n",
      "Epoch 123 - avg_train_loss: 0.3756  avg_val_loss: 0.3887  time: 20s, lr: 0.00095, MAE Score: 0.3887, \n",
      "Epoch 124 - avg_train_loss: 0.3474  avg_val_loss: 0.3476  time: 21s, lr: 0.00091, MAE Score: 0.3476, \n",
      "Epoch 125 - avg_train_loss: 0.3332  avg_val_loss: 0.3405  time: 21s, lr: 0.00086, MAE Score: 0.3405, \n",
      "Epoch 126 - avg_train_loss: 0.3009  avg_val_loss: 0.3415  time: 21s, lr: 0.00080, MAE Score: 0.3415, \n",
      "Epoch 127 - avg_train_loss: 0.2808  avg_val_loss: 0.3018  time: 21s, lr: 0.00073, MAE Score: 0.3018, \n",
      "Epoch 128 - avg_train_loss: 0.2600  avg_val_loss: 0.3097  time: 21s, lr: 0.00066, MAE Score: 0.3097, \n",
      "Epoch 129 - avg_train_loss: 0.2440  avg_val_loss: 0.3495  time: 21s, lr: 0.00058, MAE Score: 0.3495, \n",
      "Epoch 130 - avg_train_loss: 0.2855  avg_val_loss: 0.3138  time: 21s, lr: 0.00051, MAE Score: 0.3138, \n",
      "Epoch 131 - avg_train_loss: 0.2530  avg_val_loss: 0.2716  time: 21s, lr: 0.00043, MAE Score: 0.2716, \n",
      "Epoch 132 - avg_train_loss: 0.2315  avg_val_loss: 0.2580  time: 21s, lr: 0.00035, MAE Score: 0.2580, \n",
      "Epoch 133 - avg_train_loss: 0.2024  avg_val_loss: 0.2494  time: 21s, lr: 0.00028, MAE Score: 0.2494, \n",
      "Epoch 134 - avg_train_loss: 0.1900  avg_val_loss: 0.2465  time: 21s, lr: 0.00021, MAE Score: 0.2465, \n",
      "Epoch 135 - avg_train_loss: 0.1786  avg_val_loss: 0.2369  time: 21s, lr: 0.00015, MAE Score: 0.2369, \n",
      "Epoch 136 - avg_train_loss: 0.1673  avg_val_loss: 0.2291  time: 21s, lr: 0.00010, MAE Score: 0.2291, \n",
      "Epoch 137 - avg_train_loss: 0.1588  avg_val_loss: 0.2231  time: 21s, lr: 0.00006, MAE Score: 0.2231, \n",
      "Epoch 138 - avg_train_loss: 0.1522  avg_val_loss: 0.2169  time: 21s, lr: 0.00003, MAE Score: 0.2169, Best Score\n",
      "Epoch 139 - avg_train_loss: 0.1476  avg_val_loss: 0.2159  time: 21s, lr: 0.00002, MAE Score: 0.2159, Best Score\n",
      "Epoch 140 - avg_train_loss: 0.1460  avg_val_loss: 0.2154  time: 21s, lr: 0.00100, MAE Score: 0.2154, Best Score\n",
      "Epoch 141 - avg_train_loss: 0.2080  avg_val_loss: 0.2690  time: 21s, lr: 0.00099, MAE Score: 0.2690, \n",
      "Epoch 142 - avg_train_loss: 0.2099  avg_val_loss: 0.2649  time: 21s, lr: 0.00098, MAE Score: 0.2649, \n",
      "Epoch 143 - avg_train_loss: 0.2070  avg_val_loss: 0.2568  time: 21s, lr: 0.00095, MAE Score: 0.2568, \n",
      "Epoch 144 - avg_train_loss: 0.2198  avg_val_loss: 0.2664  time: 21s, lr: 0.00091, MAE Score: 0.2664, \n",
      "Epoch 145 - avg_train_loss: 0.2120  avg_val_loss: 0.2749  time: 21s, lr: 0.00086, MAE Score: 0.2749, \n",
      "Epoch 146 - avg_train_loss: 0.2120  avg_val_loss: 0.2352  time: 21s, lr: 0.00080, MAE Score: 0.2352, \n",
      "Epoch 147 - avg_train_loss: 0.1773  avg_val_loss: 0.2396  time: 21s, lr: 0.00073, MAE Score: 0.2396, \n",
      "Epoch 148 - avg_train_loss: 0.1721  avg_val_loss: 0.2324  time: 21s, lr: 0.00066, MAE Score: 0.2324, \n",
      "Epoch 149 - avg_train_loss: 0.1674  avg_val_loss: 0.2399  time: 21s, lr: 0.00058, MAE Score: 0.2399, \n",
      "Epoch 150 - avg_train_loss: 0.1642  avg_val_loss: 0.2244  time: 21s, lr: 0.00051, MAE Score: 0.2244, \n",
      "Epoch 151 - avg_train_loss: 0.1616  avg_val_loss: 0.2289  time: 21s, lr: 0.00043, MAE Score: 0.2289, \n",
      "Epoch 152 - avg_train_loss: 0.1723  avg_val_loss: 0.2487  time: 21s, lr: 0.00035, MAE Score: 0.2487, \n",
      "Epoch 153 - avg_train_loss: 0.1685  avg_val_loss: 0.2344  time: 21s, lr: 0.00028, MAE Score: 0.2344, \n",
      "Epoch 154 - avg_train_loss: 0.1575  avg_val_loss: 0.2231  time: 21s, lr: 0.00021, MAE Score: 0.2231, \n",
      "Epoch 155 - avg_train_loss: 0.1494  avg_val_loss: 0.2143  time: 21s, lr: 0.00015, MAE Score: 0.2143, Best Score\n",
      "Epoch 156 - avg_train_loss: 0.1423  avg_val_loss: 0.2136  time: 21s, lr: 0.00010, MAE Score: 0.2136, Best Score\n",
      "Epoch 157 - avg_train_loss: 0.1360  avg_val_loss: 0.2091  time: 21s, lr: 0.00006, MAE Score: 0.2091, Best Score\n",
      "Epoch 158 - avg_train_loss: 0.1308  avg_val_loss: 0.2091  time: 21s, lr: 0.00003, MAE Score: 0.2091, Best Score\n",
      "Epoch 159 - avg_train_loss: 0.1277  avg_val_loss: 0.2069  time: 21s, lr: 0.00002, MAE Score: 0.2069, Best Score\n",
      "Epoch 160 - avg_train_loss: 0.1251  avg_val_loss: 0.2058  time: 21s, lr: 0.00100, MAE Score: 0.2058, Best Score\n",
      "Epoch 161 - avg_train_loss: 0.1641  avg_val_loss: 0.2244  time: 21s, lr: 0.00099, MAE Score: 0.2244, \n",
      "Epoch 162 - avg_train_loss: 0.1667  avg_val_loss: 0.2396  time: 20s, lr: 0.00098, MAE Score: 0.2396, \n",
      "Epoch 163 - avg_train_loss: 0.2108  avg_val_loss: 0.3058  time: 21s, lr: 0.00095, MAE Score: 0.3058, \n",
      "Epoch 164 - avg_train_loss: 0.2443  avg_val_loss: 0.3485  time: 21s, lr: 0.00091, MAE Score: 0.3485, \n",
      "Epoch 165 - avg_train_loss: 0.2731  avg_val_loss: 0.2863  time: 21s, lr: 0.00086, MAE Score: 0.2863, \n",
      "Epoch 166 - avg_train_loss: 0.2370  avg_val_loss: 0.2671  time: 21s, lr: 0.00080, MAE Score: 0.2671, \n",
      "Epoch 167 - avg_train_loss: 0.2172  avg_val_loss: 0.2814  time: 21s, lr: 0.00073, MAE Score: 0.2814, \n",
      "Epoch 168 - avg_train_loss: 0.2110  avg_val_loss: 0.2607  time: 21s, lr: 0.00066, MAE Score: 0.2607, \n",
      "Epoch 169 - avg_train_loss: 0.1922  avg_val_loss: 0.2534  time: 21s, lr: 0.00058, MAE Score: 0.2534, \n",
      "Epoch 170 - avg_train_loss: 0.1864  avg_val_loss: 0.2385  time: 21s, lr: 0.00051, MAE Score: 0.2385, \n",
      "Epoch 171 - avg_train_loss: 0.1761  avg_val_loss: 0.2254  time: 21s, lr: 0.00043, MAE Score: 0.2254, \n",
      "Epoch 172 - avg_train_loss: 0.1469  avg_val_loss: 0.2175  time: 21s, lr: 0.00035, MAE Score: 0.2175, \n",
      "Epoch 173 - avg_train_loss: 0.1411  avg_val_loss: 0.2153  time: 21s, lr: 0.00028, MAE Score: 0.2153, \n",
      "Epoch 174 - avg_train_loss: 0.1363  avg_val_loss: 0.2117  time: 21s, lr: 0.00021, MAE Score: 0.2117, \n",
      "Epoch 175 - avg_train_loss: 0.1325  avg_val_loss: 0.2079  time: 21s, lr: 0.00015, MAE Score: 0.2079, \n",
      "Epoch 176 - avg_train_loss: 0.1279  avg_val_loss: 0.2059  time: 21s, lr: 0.00010, MAE Score: 0.2059, \n",
      "Epoch 177 - avg_train_loss: 0.1246  avg_val_loss: 0.2051  time: 21s, lr: 0.00006, MAE Score: 0.2051, Best Score\n",
      "Epoch 178 - avg_train_loss: 0.1211  avg_val_loss: 0.2025  time: 21s, lr: 0.00003, MAE Score: 0.2025, Best Score\n",
      "Epoch 179 - avg_train_loss: 0.1187  avg_val_loss: 0.2030  time: 21s, lr: 0.00002, MAE Score: 0.2030, \n",
      "Epoch 180 - avg_train_loss: 0.1171  avg_val_loss: 0.2020  time: 21s, lr: 0.00100, MAE Score: 0.2020, Best Score\n",
      "Epoch 181 - avg_train_loss: 0.1432  avg_val_loss: 0.2214  time: 21s, lr: 0.00099, MAE Score: 0.2214, \n",
      "Epoch 182 - avg_train_loss: 0.1479  avg_val_loss: 0.2475  time: 21s, lr: 0.00098, MAE Score: 0.2475, \n",
      "Epoch 183 - avg_train_loss: 0.1838  avg_val_loss: 0.2614  time: 21s, lr: 0.00095, MAE Score: 0.2614, \n",
      "Epoch 184 - avg_train_loss: 0.1955  avg_val_loss: 0.2642  time: 21s, lr: 0.00091, MAE Score: 0.2642, \n",
      "Epoch 185 - avg_train_loss: 0.2380  avg_val_loss: 0.3359  time: 21s, lr: 0.00086, MAE Score: 0.3359, \n",
      "Epoch 186 - avg_train_loss: 0.2882  avg_val_loss: 0.4238  time: 21s, lr: 0.00080, MAE Score: 0.4238, \n",
      "Epoch 187 - avg_train_loss: 0.2716  avg_val_loss: 0.2954  time: 21s, lr: 0.00073, MAE Score: 0.2954, \n",
      "Epoch 188 - avg_train_loss: 0.2420  avg_val_loss: 0.2915  time: 21s, lr: 0.00066, MAE Score: 0.2915, \n",
      "Epoch 189 - avg_train_loss: 0.2089  avg_val_loss: 0.2677  time: 21s, lr: 0.00058, MAE Score: 0.2677, \n",
      "Epoch 190 - avg_train_loss: 0.1844  avg_val_loss: 0.2618  time: 21s, lr: 0.00051, MAE Score: 0.2618, \n",
      "Epoch 191 - avg_train_loss: 0.1735  avg_val_loss: 0.2439  time: 21s, lr: 0.00043, MAE Score: 0.2439, \n",
      "Epoch 192 - avg_train_loss: 0.1613  avg_val_loss: 0.2261  time: 21s, lr: 0.00035, MAE Score: 0.2261, \n",
      "Epoch 193 - avg_train_loss: 0.1505  avg_val_loss: 0.2148  time: 21s, lr: 0.00028, MAE Score: 0.2148, \n",
      "Epoch 194 - avg_train_loss: 0.1318  avg_val_loss: 0.2099  time: 21s, lr: 0.00021, MAE Score: 0.2099, \n",
      "Epoch 195 - avg_train_loss: 0.1265  avg_val_loss: 0.2073  time: 21s, lr: 0.00015, MAE Score: 0.2073, \n",
      "Epoch 196 - avg_train_loss: 0.1225  avg_val_loss: 0.2041  time: 21s, lr: 0.00010, MAE Score: 0.2041, \n",
      "Epoch 197 - avg_train_loss: 0.1192  avg_val_loss: 0.2027  time: 21s, lr: 0.00006, MAE Score: 0.2027, \n",
      "Epoch 198 - avg_train_loss: 0.1165  avg_val_loss: 0.2011  time: 21s, lr: 0.00003, MAE Score: 0.2011, Best Score\n",
      "Epoch 199 - avg_train_loss: 0.1142  avg_val_loss: 0.2009  time: 21s, lr: 0.00002, MAE Score: 0.2009, Best Score\n",
      "Epoch 200 - avg_train_loss: 0.1127  avg_val_loss: 0.2007  time: 21s, lr: 0.00100, MAE Score: 0.2007, Best Score\n",
      "Epoch 201 - avg_train_loss: 0.1601  avg_val_loss: 0.2390  time: 21s, lr: 0.00099, MAE Score: 0.2390, \n",
      "Epoch 202 - avg_train_loss: 0.1527  avg_val_loss: 0.2195  time: 21s, lr: 0.00098, MAE Score: 0.2195, \n",
      "Epoch 203 - avg_train_loss: 0.1421  avg_val_loss: 0.2148  time: 21s, lr: 0.00095, MAE Score: 0.2148, \n",
      "Epoch 204 - avg_train_loss: 0.1422  avg_val_loss: 0.2147  time: 21s, lr: 0.00091, MAE Score: 0.2147, \n",
      "Epoch 205 - avg_train_loss: 0.1487  avg_val_loss: 0.2462  time: 21s, lr: 0.00086, MAE Score: 0.2462, \n",
      "Epoch 206 - avg_train_loss: 0.1773  avg_val_loss: 0.2378  time: 21s, lr: 0.00080, MAE Score: 0.2378, \n",
      "Epoch 207 - avg_train_loss: 0.1772  avg_val_loss: 0.2559  time: 21s, lr: 0.00073, MAE Score: 0.2559, \n",
      "Epoch 208 - avg_train_loss: 0.1742  avg_val_loss: 0.2501  time: 21s, lr: 0.00066, MAE Score: 0.2501, \n",
      "Epoch 209 - avg_train_loss: 0.1644  avg_val_loss: 0.2291  time: 21s, lr: 0.00058, MAE Score: 0.2291, \n",
      "Epoch 210 - avg_train_loss: 0.1577  avg_val_loss: 0.2491  time: 21s, lr: 0.00051, MAE Score: 0.2491, \n",
      "Epoch 211 - avg_train_loss: 0.1483  avg_val_loss: 0.2184  time: 21s, lr: 0.00043, MAE Score: 0.2184, \n",
      "Epoch 212 - avg_train_loss: 0.1397  avg_val_loss: 0.2108  time: 21s, lr: 0.00035, MAE Score: 0.2108, \n",
      "Epoch 213 - avg_train_loss: 0.1300  avg_val_loss: 0.2093  time: 21s, lr: 0.00028, MAE Score: 0.2093, \n",
      "Epoch 214 - avg_train_loss: 0.1181  avg_val_loss: 0.2027  time: 21s, lr: 0.00021, MAE Score: 0.2027, \n",
      "Epoch 215 - avg_train_loss: 0.1135  avg_val_loss: 0.2015  time: 21s, lr: 0.00015, MAE Score: 0.2015, \n",
      "Epoch 216 - avg_train_loss: 0.1103  avg_val_loss: 0.1987  time: 21s, lr: 0.00010, MAE Score: 0.1987, Best Score\n",
      "Epoch 217 - avg_train_loss: 0.1069  avg_val_loss: 0.1983  time: 21s, lr: 0.00006, MAE Score: 0.1983, Best Score\n",
      "Epoch 218 - avg_train_loss: 0.1052  avg_val_loss: 0.1971  time: 21s, lr: 0.00003, MAE Score: 0.1971, Best Score\n",
      "Epoch 219 - avg_train_loss: 0.1033  avg_val_loss: 0.1966  time: 21s, lr: 0.00002, MAE Score: 0.1966, Best Score\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
