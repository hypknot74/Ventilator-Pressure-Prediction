{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016034,
     "end_time": "2021-10-05T20:56:45.034725",
     "exception": false,
     "start_time": "2021-10-05T20:56:45.018691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "CUDA=1\n",
    "\n",
    "NAME = '1024_tf_ver2'\n",
    "OUTPUT_DIR = f'./results/{NAME}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "DATA_DIR = '../input/ventilator-pressure-prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "3e5a0bd1-3e22-4b2c-a565-68985e55f95e",
    "_uuid": "e331dbcc-0346-4019-9ff6-b890154a878b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.267071,
     "end_time": "2021-10-05T20:56:51.316914",
     "exception": false,
     "start_time": "2021-10-05T20:56:45.049843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "#from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization, LayerNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Activation\n",
    "from tensorflow.keras.layers import Concatenate, LSTM, GRU\n",
    "from tensorflow.keras.layers import Bidirectional, Multiply\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015359,
     "end_time": "2021-10-05T20:56:51.348082",
     "exception": false,
     "start_time": "2021-10-05T20:56:51.332723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load source datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "89eb257e-0ed2-4f8b-94d6-462a5e995eb1",
    "_uuid": "ca71d87d-6594-4f31-906d-0b53cd4c1374",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 10.739701,
     "end_time": "2021-10-05T20:57:02.103774",
     "exception": false,
     "start_time": "2021-10-05T20:56:51.364073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (6036000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id   R   C  time_step       u_in  u_out   pressure\n",
       "0   1          1  20  50   0.000000   0.083334      0   5.837492\n",
       "1   2          1  20  50   0.033652  18.383041      0   5.907794\n",
       "2   3          1  20  50   0.067514  22.509278      0   7.876254\n",
       "3   4          1  20  50   0.101542  22.808822      0  11.742872\n",
       "4   5          1  20  50   0.135756  25.355850      0  12.234987"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "print(f\"train_df: {train_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 5.214126,
     "end_time": "2021-10-05T20:57:07.334119",
     "exception": false,
     "start_time": "2021-10-05T20:57:02.119993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df: (4024000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R   C  time_step       u_in  u_out\n",
       "0   1          0  5  20   0.000000   0.000000      0\n",
       "1   2          0  5  20   0.031904   7.515046      0\n",
       "2   3          0  5  20   0.063827  14.651675      0\n",
       "3   4          0  5  20   0.095751  21.230610      0\n",
       "4   5          0  5  20   0.127644  26.320956      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "print(f\"test_df: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017894,
     "end_time": "2021-10-05T20:57:07.369026",
     "exception": false,
     "start_time": "2021-10-05T20:57:07.351132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "13a36b46-7067-4b29-aad3-7e3b15e8415b",
    "_uuid": "dc41dbf2-f199-4b9d-bbd9-bf6084162b47",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 143.013489,
     "end_time": "2021-10-05T20:59:30.39949",
     "exception": false,
     "start_time": "2021-10-05T20:57:07.386001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data...\n",
      "\n",
      "Step-1...Completed\n",
      "Step-2...Completed\n",
      "Step-3...Completed\n",
      "Step-4...Completed\n",
      "Step-5...Completed\n",
      "Step-6...Completed\n",
      "Step-7...Completed\n",
      "Step-8...Completed\n",
      "\n",
      "Test data...\n",
      "\n",
      "Step-1...Completed\n",
      "Step-2...Completed\n",
      "Step-3...Completed\n",
      "Step-4...Completed\n",
      "Step-5...Completed\n",
      "Step-6...Completed\n",
      "Step-7...Completed\n",
      "Step-8...Completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    df['cross']= df['u_in'] * df['u_out']\n",
    "    df['cross2']= df['time_step'] * df['u_out']\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    print(\"Step-1...Completed\")\n",
    "    \n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "    print(\"Step-2...Completed\")\n",
    "    \n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    print(\"Step-3...Completed\")\n",
    "    \n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    print(\"Step-4...Completed\")\n",
    "    \n",
    "    df['one'] = 1\n",
    "    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n",
    "    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n",
    "    \n",
    "    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n",
    "    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n",
    "    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n",
    "    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n",
    "    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n",
    "    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n",
    "    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n",
    "    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n",
    "    print(\"Step-5...Completed\")\n",
    "    \n",
    "    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
    "    df['ewm_u_in_mean'] = (df\\\n",
    "                           .groupby('breath_id')['u_in']\\\n",
    "                           .ewm(halflife=9)\\\n",
    "                           .mean()\\\n",
    "                           .reset_index(level=0,drop=True))\n",
    "    df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (df\\\n",
    "                                                              .groupby('breath_id')['u_in']\\\n",
    "                                                              .rolling(window=15,min_periods=1)\\\n",
    "                                                              .agg({\"15_in_sum\":\"sum\",\n",
    "                                                                    \"15_in_min\":\"min\",\n",
    "                                                                    \"15_in_max\":\"max\",\n",
    "                                                                    \"15_in_mean\":\"mean\"})\\\n",
    "                                                               .reset_index(level=0,drop=True))\n",
    "    print(\"Step-6...Completed\")\n",
    "    \n",
    "    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n",
    "    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n",
    "    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n",
    "    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n",
    "    print(\"Step-7...Completed\")\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "    print(\"Step-8...Completed\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Train data...\\n\")\n",
    "train = add_features(train_df)\n",
    "\n",
    "print(\"\\nTest data...\\n\")\n",
    "test = add_features(test_df)\n",
    "\n",
    "del train_df\n",
    "del test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "01328860-fa2a-421c-9e5f-ea0048246f98",
    "_uuid": "346bf2c0-96d2-4da5-8837-c0f820294a85",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.913232,
     "end_time": "2021-10-05T20:59:35.334614",
     "exception": false,
     "start_time": "2021-10-05T20:59:30.421382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (6036000, 64) \n",
      "test: (4024000, 64)\n"
     ]
    }
   ],
   "source": [
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "\n",
    "train.drop(['pressure','id', 'breath_id','one','count',\n",
    "            'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n",
    "            'breath_id_lag2same'], axis=1, inplace=True)\n",
    "\n",
    "test = test.drop(['id', 'breath_id','one','count','breath_id_lag',\n",
    "                  'breath_id_lag2','breath_id_lagsame',\n",
    "                  'breath_id_lag2same'], axis=1)\n",
    "\n",
    "print(f\"train: {train.shape} \\ntest: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 13.174585,
     "end_time": "2021-10-05T20:59:48.53083",
     "exception": false,
     "start_time": "2021-10-05T20:59:35.356245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (75450, 80, 64) \n",
      "test: (50300, 80, 64) \n",
      "targets: (75450, 80)\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "train = train.reshape(-1, 80, train.shape[-1])\n",
    "test = test.reshape(-1, 80, train.shape[-1])\n",
    "\n",
    "print(f\"train: {train.shape} \\ntest: {test.shape} \\ntargets: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min pressure: -1.8957443237304688\n",
      "Max pressure: 64.82099151611328\n",
      "Pressure step: 0.07030248641967773\n",
      "Unique values:  950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pressure = targets.squeeze().reshape(-1,1).astype('float32')\n",
    "\n",
    "P_MIN = np.min(pressure)\n",
    "P_MAX = np.max(pressure)\n",
    "P_STEP = (pressure[1] - pressure[0])[0]\n",
    "print('Min pressure: {}'.format(P_MIN))\n",
    "print('Max pressure: {}'.format(P_MAX))\n",
    "print('Pressure step: {}'.format(P_STEP))\n",
    "print('Unique values:  {}'.format(np.unique(pressure).shape[0]))\n",
    "\n",
    "del pressure\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021616,
     "end_time": "2021-10-05T20:59:48.574409",
     "exception": false,
     "start_time": "2021-10-05T20:59:48.552793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hardware config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 5.519949,
     "end_time": "2021-10-05T20:59:54.116202",
     "exception": false,
     "start_time": "2021-10-05T20:59:48.596253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n",
      "Batch Size: 512\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n",
    "    print(\"Running on TPU:\", tpu.master())\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    \n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    BATCH_SIZE = 512\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022294,
     "end_time": "2021-10-05T20:59:54.161528",
     "exception": false,
     "start_time": "2021-10-05T20:59:54.139234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Keras DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.035112,
     "end_time": "2021-10-05T20:59:54.2192",
     "exception": false,
     "start_time": "2021-10-05T20:59:54.184088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dnn_model():\n",
    "    \n",
    "    x_input = Input(shape=(train.shape[-2:]))\n",
    "    \n",
    "    # x_emb = Dense(units=1024)(x_input)\n",
    "    # x_emb = LayerNormalization()(x_emb)\n",
    "    # x_emb = Activation('selu')(x_emb)\n",
    "    \n",
    "    x1 = Bidirectional(LSTM(units=1024, return_sequences=True))(x_input)\n",
    "    x2 = Bidirectional(LSTM(units=512, return_sequences=True))(x1)\n",
    "    x3 = Bidirectional(LSTM(units=384, return_sequences=True))(x2)\n",
    "    x4 = Bidirectional(LSTM(units=256, return_sequences=True))(x3)\n",
    "    x5 = Bidirectional(LSTM(units=128, return_sequences=True))(x4)\n",
    "    \n",
    "    z2 = Bidirectional(GRU(units=384, return_sequences=True))(x2)\n",
    "    \n",
    "    z31 = Multiply()([x3, z2])\n",
    "    z31 = BatchNormalization()(z31)\n",
    "    z3 = Bidirectional(GRU(units=256, return_sequences=True))(z31)\n",
    "    \n",
    "    z41 = Multiply()([x4, z3])\n",
    "    z41 = BatchNormalization()(z41)\n",
    "    z4 = Bidirectional(GRU(units=128, return_sequences=True))(z41)\n",
    "    \n",
    "    z51 = Multiply()([x5, z4])\n",
    "    z51 = BatchNormalization()(z51)\n",
    "    z5 = Bidirectional(GRU(units=64, return_sequences=True))(z51)\n",
    "    \n",
    "    x = Concatenate(axis=2)([x5, z2, z3, z4, z5])\n",
    "    \n",
    "    x = Dense(units=128, activation='selu')(x)\n",
    "    \n",
    "    x_output = Dense(units=1)(x)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=x_output, \n",
    "                  name='DNN_Model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 4.688219,
     "end_time": "2021-10-05T20:59:58.929952",
     "exception": false,
     "start_time": "2021-10-05T20:59:54.241733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DNN_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80, 64)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 80, 2048)     8921088     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 80, 1024)     10489856    bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 80, 768)      4328448     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 80, 768)      3248640     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 80, 768)      0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 80, 768)      3072        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 80, 512)      2099200     bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 80, 512)      1575936     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 80, 512)      0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 80, 512)      2048        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 80, 256)      656384      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 80, 256)      493056      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 80, 256)      0           bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 80, 256)      1024        multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 80, 128)      123648      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80, 1920)     0           bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 80, 128)      245888      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80, 1)        129         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 32,188,417\n",
      "Trainable params: 32,185,345\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(f'/device:GPU:{CUDA}'):\n",
    "    model = dnn_model()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 1.233882,
     "end_time": "2021-10-05T21:00:00.186822",
     "exception": false,
     "start_time": "2021-10-05T20:59:58.95294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(\n",
    "    model, \n",
    "    to_file=OUTPUT_DIR+'Google_Brain_Keras_Model.png', \n",
    "    show_shapes=True,\n",
    "    show_layer_names=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 14568.5637,
     "end_time": "2021-10-06T01:02:48.778341",
     "exception": false,
     "start_time": "2021-10-05T21:00:00.214641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhypknot\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public-tf/runs/1584iqab\" target=\"_blank\">fold_0</a></strong> to <a href=\"https://wandb.ai/hypknot/Ventilator-Pressure-Public-tf\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 1.6164\n",
      "Epoch 00001: val_loss improved from inf to 1.54157, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 32s 269ms/step - loss: 1.6164 - val_loss: 1.5416\n",
      "Epoch 2/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6528\n",
      "Epoch 00002: val_loss improved from 1.54157 to 1.19559, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.6528 - val_loss: 1.1956\n",
      "Epoch 3/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5702\n",
      "Epoch 00003: val_loss improved from 1.19559 to 0.75546, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.5702 - val_loss: 0.7555\n",
      "Epoch 4/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5073\n",
      "Epoch 00004: val_loss improved from 0.75546 to 0.60886, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.5073 - val_loss: 0.6089\n",
      "Epoch 5/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4783\n",
      "Epoch 00005: val_loss improved from 0.60886 to 0.50749, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.4783 - val_loss: 0.5075\n",
      "Epoch 6/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4360\n",
      "Epoch 00006: val_loss improved from 0.50749 to 0.46007, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.4360 - val_loss: 0.4601\n",
      "Epoch 7/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4148\n",
      "Epoch 00007: val_loss improved from 0.46007 to 0.42148, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.4148 - val_loss: 0.4215\n",
      "Epoch 8/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3919\n",
      "Epoch 00008: val_loss improved from 0.42148 to 0.34728, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.3919 - val_loss: 0.3473\n",
      "Epoch 9/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3788\n",
      "Epoch 00009: val_loss did not improve from 0.34728\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.3788 - val_loss: 0.3720\n",
      "Epoch 10/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3809\n",
      "Epoch 00010: val_loss did not improve from 0.34728\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.3809 - val_loss: 0.4222\n",
      "Epoch 11/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3557\n",
      "Epoch 00011: val_loss did not improve from 0.34728\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.3557 - val_loss: 0.3876\n",
      "Epoch 12/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3489\n",
      "Epoch 00012: val_loss improved from 0.34728 to 0.34245, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.3489 - val_loss: 0.3425\n",
      "Epoch 13/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3285\n",
      "Epoch 00013: val_loss improved from 0.34245 to 0.33656, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.3285 - val_loss: 0.3366\n",
      "Epoch 14/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3203\n",
      "Epoch 00014: val_loss improved from 0.33656 to 0.30329, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 0.3203 - val_loss: 0.3033\n",
      "Epoch 15/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3112\n",
      "Epoch 00015: val_loss did not improve from 0.30329\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.3112 - val_loss: 0.3377\n",
      "Epoch 16/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2968\n",
      "Epoch 00016: val_loss did not improve from 0.30329\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2968 - val_loss: 0.3088\n",
      "Epoch 17/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2934\n",
      "Epoch 00017: val_loss did not improve from 0.30329\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2934 - val_loss: 0.3195\n",
      "Epoch 18/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2871\n",
      "Epoch 00018: val_loss did not improve from 0.30329\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2871 - val_loss: 0.3315\n",
      "Epoch 19/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2782\n",
      "Epoch 00019: val_loss did not improve from 0.30329\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2782 - val_loss: 0.3424\n",
      "Epoch 20/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2894\n",
      "Epoch 00020: val_loss improved from 0.30329 to 0.29528, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2894 - val_loss: 0.2953\n",
      "Epoch 21/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2624\n",
      "Epoch 00021: val_loss improved from 0.29528 to 0.26819, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.2624 - val_loss: 0.2682\n",
      "Epoch 22/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2666\n",
      "Epoch 00022: val_loss did not improve from 0.26819\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2666 - val_loss: 0.2795\n",
      "Epoch 23/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2517\n",
      "Epoch 00023: val_loss improved from 0.26819 to 0.25247, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.2517 - val_loss: 0.2525\n",
      "Epoch 24/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2610\n",
      "Epoch 00024: val_loss did not improve from 0.25247\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2610 - val_loss: 0.2850\n",
      "Epoch 25/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2541\n",
      "Epoch 00025: val_loss did not improve from 0.25247\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2541 - val_loss: 0.2632\n",
      "Epoch 26/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2537\n",
      "Epoch 00026: val_loss improved from 0.25247 to 0.24781, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.2537 - val_loss: 0.2478\n",
      "Epoch 27/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2487\n",
      "Epoch 00027: val_loss improved from 0.24781 to 0.24064, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2487 - val_loss: 0.2406\n",
      "Epoch 28/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2387\n",
      "Epoch 00028: val_loss did not improve from 0.24064\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2387 - val_loss: 0.2548\n",
      "Epoch 29/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2490\n",
      "Epoch 00029: val_loss did not improve from 0.24064\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2490 - val_loss: 0.2503\n",
      "Epoch 30/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2380\n",
      "Epoch 00030: val_loss improved from 0.24064 to 0.23854, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2380 - val_loss: 0.2385\n",
      "Epoch 31/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2322\n",
      "Epoch 00031: val_loss did not improve from 0.23854\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2322 - val_loss: 0.2538\n",
      "Epoch 32/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2293\n",
      "Epoch 00032: val_loss improved from 0.23854 to 0.22644, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2293 - val_loss: 0.2264\n",
      "Epoch 33/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2334\n",
      "Epoch 00033: val_loss did not improve from 0.22644\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2334 - val_loss: 0.2419\n",
      "Epoch 34/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2359\n",
      "Epoch 00034: val_loss did not improve from 0.22644\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.2359 - val_loss: 0.2423\n",
      "Epoch 35/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2213\n",
      "Epoch 00035: val_loss improved from 0.22644 to 0.22552, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.2213 - val_loss: 0.2255\n",
      "Epoch 36/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2241\n",
      "Epoch 00036: val_loss did not improve from 0.22552\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.2241 - val_loss: 0.2451\n",
      "Epoch 37/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2256\n",
      "Epoch 00037: val_loss improved from 0.22552 to 0.22549, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2256 - val_loss: 0.2255\n",
      "Epoch 38/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2116\n",
      "Epoch 00038: val_loss did not improve from 0.22549\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.2116 - val_loss: 0.2327\n",
      "Epoch 39/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2138\n",
      "Epoch 00039: val_loss did not improve from 0.22549\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.2138 - val_loss: 0.2374\n",
      "Epoch 40/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2524\n",
      "Epoch 00040: val_loss did not improve from 0.22549\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2524 - val_loss: 0.2512\n",
      "Epoch 41/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2217\n",
      "Epoch 00041: val_loss did not improve from 0.22549\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.2217 - val_loss: 0.2403\n",
      "Epoch 42/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2177\n",
      "Epoch 00042: val_loss did not improve from 0.22549\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.2177 - val_loss: 0.2345\n",
      "Epoch 43/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2107\n",
      "Epoch 00043: val_loss did not improve from 0.22549\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.2107 - val_loss: 0.2414\n",
      "Epoch 44/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2117\n",
      "Epoch 00044: val_loss improved from 0.22549 to 0.21495, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2117 - val_loss: 0.2150\n",
      "Epoch 45/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2033\n",
      "Epoch 00045: val_loss did not improve from 0.21495\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 0.2033 - val_loss: 0.2165\n",
      "Epoch 46/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2050\n",
      "Epoch 00046: val_loss did not improve from 0.21495\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.2050 - val_loss: 0.2409\n",
      "Epoch 47/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2052\n",
      "Epoch 00047: val_loss improved from 0.21495 to 0.20901, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2052 - val_loss: 0.2090\n",
      "Epoch 48/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1998\n",
      "Epoch 00048: val_loss improved from 0.20901 to 0.20696, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.1998 - val_loss: 0.2070\n",
      "Epoch 49/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1941\n",
      "Epoch 00049: val_loss did not improve from 0.20696\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.1941 - val_loss: 0.2080\n",
      "Epoch 50/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1919\n",
      "Epoch 00050: val_loss did not improve from 0.20696\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.1919 - val_loss: 0.2203\n",
      "Epoch 51/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1897\n",
      "Epoch 00051: val_loss improved from 0.20696 to 0.20325, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.1897 - val_loss: 0.2033\n",
      "Epoch 52/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1840\n",
      "Epoch 00052: val_loss did not improve from 0.20325\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.1840 - val_loss: 0.2051\n",
      "Epoch 53/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00053: val_loss did not improve from 0.20325\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.1916 - val_loss: 0.2048\n",
      "Epoch 54/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1820\n",
      "Epoch 00054: val_loss did not improve from 0.20325\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.1820 - val_loss: 0.2066\n",
      "Epoch 55/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1849\n",
      "Epoch 00055: val_loss improved from 0.20325 to 0.20014, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.1849 - val_loss: 0.2001\n",
      "Epoch 56/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1808\n",
      "Epoch 00056: val_loss did not improve from 0.20014\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.1808 - val_loss: 0.2020\n",
      "Epoch 57/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 00057: val_loss did not improve from 0.20014\n",
      "118/118 [==============================] - 28s 237ms/step - loss: 0.1777 - val_loss: 0.2124\n",
      "Epoch 58/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 00058: val_loss improved from 0.20014 to 0.19617, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.1835 - val_loss: 0.1962\n",
      "Epoch 59/300\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1749\n",
      "Epoch 00059: val_loss improved from 0.19617 to 0.19616, saving model to ./results/1024_tf_ver2/./Bidirect_LSTM_model_2021_1C.h5\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.1749 - val_loss: 0.1962\n",
      "Epoch 60/300\n",
      " 83/118 [====================>.........] - ETA: 7s - loss: 0.1746"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(f'/device:GPU:{CUDA}'):\n",
    "    VERBOSE = 1\n",
    "    test_preds = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2021)\n",
    "\n",
    "    all_score = 0\n",
    "    count = 0\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
    "        run = wandb.init(project=\"Ventilator-Pressure-Public-tf\", \n",
    "                     name=f'fold_{fold}',\n",
    "                     config={\"hyper\": \"parameter\"},\n",
    "                     group=NAME,\n",
    "                    job_type='train')\n",
    "        \n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "\n",
    "        model = dnn_model()\n",
    "\n",
    "        #scheduler = CosineDecayRestarts(initial_learning_rate=1e-3, first_decay_steps=20, t_mul=1, alpha=1e-5)\n",
    "        #optimizer = Adam(learning_rate=scheduler)\n",
    "\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "\n",
    "        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.85, \n",
    "                               patience=10, verbose=VERBOSE)\n",
    "\n",
    "        # save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "        chk_point = ModelCheckpoint(OUTPUT_DIR+f'./Bidirect_LSTM_model_2021_{fold+1}C.h5', #options=save_locally, \n",
    "                                    monitor='val_loss', verbose=VERBOSE, \n",
    "                                    save_best_only=True, mode='min')\n",
    "\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=30, \n",
    "                           verbose=VERBOSE, mode=\"min\", \n",
    "                           restore_best_weights=True)\n",
    "\n",
    "        model.fit(X_train, y_train, \n",
    "                  validation_data=(X_valid, y_valid), \n",
    "                  epochs=300,\n",
    "                  verbose=VERBOSE,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  callbacks=[lr, chk_point, es, WandbCallback()])\n",
    "\n",
    "        # load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
    "        model = load_model(OUTPUT_DIR+f'./Bidirect_LSTM_model_2021_{fold+1}C.h5') #options=load_locally\n",
    "\n",
    "        y_true = y_valid.squeeze().reshape(-1, 1)\n",
    "        y_pred = model.predict(X_valid, batch_size=BATCH_SIZE).squeeze().reshape(-1, 1)\n",
    "        score = mean_absolute_error(y_true, y_pred)\n",
    "        print(f\"Fold-{fold+1} | OOF Score: {score}\")\n",
    "        count += 1\n",
    "        all_score += score\n",
    "\n",
    "        test_preds.append(model.predict(test, batch_size=BATCH_SIZE).squeeze().reshape(-1, 1).squeeze())\n",
    "        \n",
    "        run.finish()\n",
    "        \n",
    "    print(f'CV Score: {all_score/count:<.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031714,
     "end_time": "2021-10-06T01:02:48.842336",
     "exception": false,
     "start_time": "2021-10-06T01:02:48.810622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + 'train.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "\n",
    "unique_pressures = train[\"pressure\"].unique()\n",
    "sorted_pressures = np.sort(unique_pressures)\n",
    "total_pressures_len = len(sorted_pressures)\n",
    "\n",
    "def find_nearest(prediction):\n",
    "    '''\n",
    "    予測値は離散値であるため、学習データにある最も近い離散値に置き換える\n",
    "    '''\n",
    "    insert_idx = np.searchsorted(sorted_pressures, prediction)\n",
    "    if insert_idx == total_pressures_len:\n",
    "        # If the predicted value is bigger than the highest pressure in the train dataset,\n",
    "        # return the max value.\n",
    "        return sorted_pressures[-1]\n",
    "    elif insert_idx == 0:\n",
    "        # Same control but for the lower bound.\n",
    "        return sorted_pressures[0]\n",
    "    lower_val = sorted_pressures[insert_idx - 1]\n",
    "    upper_val = sorted_pressures[insert_idx]\n",
    "    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 13.206498,
     "end_time": "2021-10-06T01:03:02.080076",
     "exception": false,
     "start_time": "2021-10-06T01:02:48.873578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "submission[\"pressure\"] = sum(test_preds)/5\n",
    "submission.to_csv(OUTPUT_DIR+'mean_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.030658,
     "end_time": "2021-10-06T01:03:02.1421",
     "exception": false,
     "start_time": "2021-10-06T01:03:02.111442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n",
    "submission[\"pressure\"] = np.round((submission.pressure - P_MIN)/P_STEP) * P_STEP + P_MIN\n",
    "submission[\"pressure\"] = np.clip(submission.pressure, P_MIN, P_MAX)\n",
    "submission[\"pressure\"] = submission[\"pressure\"].apply(find_nearest)\n",
    "submission.to_csv(OUTPUT_DIR+'median_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
